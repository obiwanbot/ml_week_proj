{"cells":[{"cell_type":"markdown","metadata":{"id":"CoT4esNt1BU7"},"source":["# Includes"]},{"cell_type":"code","execution_count":78,"metadata":{"executionInfo":{"elapsed":1122,"status":"ok","timestamp":1667226825246,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"wLf0VAKx1D3K"},"outputs":[],"source":["import os\n","import sys\n","import time\n","import glob\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.utils\n","import torch.nn.functional as F\n","import torchvision.datasets as dset\n","import torch.backends.cudnn as cudnn\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from timeit import default_timer as timer\n","from tqdm import tqdm\n","from collections import defaultdict,Counter\n","\n","import scipy.io"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3272,"status":"ok","timestamp":1667226828513,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"TXPj4fXIkNLY","outputId":"7e9ab506-c7a7-4d4b-cb1a-7abdccf0eb2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (3.0.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n","Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n","Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.7.0)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.42)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n","Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (1.2.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3.post0)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.11.0)\n","Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n","Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n","Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.2)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n","Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"]}],"source":["!pip install optuna\n","import optuna"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3950,"status":"ok","timestamp":1667226832450,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"IGK9bOe7gHzy","outputId":"3b2c4f49-20d0-4aa5-bce7-b5b4ec32f1dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd drive/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WcQT4lq4O8be","executionInfo":{"status":"ok","timestamp":1667226832451,"user_tz":-180,"elapsed":28,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"}},"outputId":"b53aee98-0748-48b3-c7f3-82be91ddb95b"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/'\n","/content/drive/MyDrive/Colab Notebooks/huawei\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Colab Notebooks/huawei"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDvSQYg2PLRs","executionInfo":{"status":"ok","timestamp":1667226832453,"user_tz":-180,"elapsed":26,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"}},"outputId":"95b86c64-6fe8-4486-a6f3-be6bdabb7e12"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/huawei\n"]}]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1667226832453,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"UxHbQ7L8f8hT"},"outputs":[],"source":["from DPDBlocks.blocks import AFIR,ABS,Polynomial,Delay,Prod_cmp"]},{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1667226832454,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"Nx7iinZ0yOlS"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","import matplotlib.mlab as mlab\n","import matplotlib.gridspec as gridspec"]},{"cell_type":"markdown","metadata":{"id":"OJNBQw7yvZPh"},"source":["# Operations"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1667226832455,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"SwOErQU3jLZ7"},"outputs":[],"source":["def NMSE(X, E):\n","    return 10*torch.log10((E.norm(dim=1)**2).sum()/(X.norm(dim=1)**2).sum())"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1667226832459,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"Kqaq62i5f8iw"},"outputs":[],"source":["def update_history(hist,iter_num, val_acc, val_loss, time):\n","    hist['iter'].append(iter_num)\n","    hist['time'].append(time)\n","    hist['train_loss'].append(val_loss.item())\n","        # self.hist['norm_coeffs'].append(train_loss.item())\n","    hist['train_loss_db'].append(val_acc.item())"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1667226832460,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"pVuT0wQzVlgq"},"outputs":[],"source":["def draw_spectrum(input_batch,desired,out):\n","  plt.psd(input_batch.detach().cpu()[0,0,:]+\n","                1j*input_batch.detach().cpu()[0,1,:],NFFT=2048)\n","  plt.psd(desired.detach().cpu()[0,0,:]+\n","                1j*desired.detach().cpu()[0,1,:],NFFT=2048)\n","        # plt.psd(desired.permute(2,1,0).detach().cpu().reshape(-1,),NFFT=2048)\n","  plt.psd((out-desired).detach().cpu()[0,0,:]+\n","                1j*(out-desired).detach().cpu()[0,1,:],NFFT=2048)\n","        # plt.psd((out-desired).permute(2,1,0).detach().cpu().reshape(-1,),NFFT=2048)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ekZgZN6Fz9PT"},"source":["## Train Function"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1667226832461,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"kv9Ta7XbVzIQ"},"outputs":[],"source":["def eval_model(valid_queue, model, criterion):\n","    for step, (valid) in enumerate(valid_queue):\n","        model.eval()\n","        input_batch = Variable(valid[:,:,:1],requires_grad=False).permute(2,1,0).cpu()\n","        desired = Variable(valid[:,:,1:],requires_grad=False).permute(2,1,0).cpu()\n","        out = model.forward(input_batch)\n","        #out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\n","        #out = sum(list(map( lambda n: n(out_0),  model[1])))\n","\n","        loss=criterion(out,desired)\n","\n","\n","        #draw_spectrum(input_batch,desired,out)\n","        accuracy = NMSE(input_batch, out - desired)\n","\n","    return loss,accuracy"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1667226832461,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"8la_NvkOf8jT"},"outputs":[],"source":["from numpy import gradient\n","\n","\n","def train_of_epoch(train_queue, model, criterion, optimizer):\n","    for step, (train) in enumerate(train_queue):\n","\n","        input_batch = Variable(train[:,:,:1],requires_grad=False).permute(2,1,0).cpu()\n","        desired = Variable(train[:,:,1:],requires_grad=False).permute(2,1,0).cpu()\n","        optimizer.zero_grad()\n","        out = model.forward(input_batch)\n","        #out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\n","        #out = sum(list(map( lambda n: n(out_0),  model[1])))\n","\n","        loss = criterion(out, desired)\n","    \n","        loss.backward()\n","        #print(loss.grad_fn)\n","        \n","        optimizer.step()\n"]},{"cell_type":"code","execution_count":90,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1667226832463,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"Y6jSRaD9f8j8"},"outputs":[],"source":["def train(train_queue, valid_queue, model, criterion, optimizer,n_epoch,\n","          scheduler,log_every=1,save_flag=True,path_to_experiment=''):\n","    min_loss=0\n","    hist=defaultdict(list)\n","    t0=timer()\n","    for it in tqdm(range(n_epoch)):\n","        model.train(True)\n","        train_of_epoch(train_queue, model, criterion, optimizer)\n","        scheduler.step()\n","\n","    #     if return_history and it % log_every == 0:\n","    #         model.init_for_batch(train)\n","    #         train_loss = complex_mse(model.forward(train.x), train.y)\n","        if it%log_every==0:\n","            loss_v,accuracy_v=eval_model(valid_queue, model, loss_fn)\n","            update_history(hist,it, accuracy_v, loss_v, timer() - t0,)\n","            print('Loss = ',loss_v.cpu().detach().numpy(), 'Accuracy = ', accuracy_v.cpu().detach().numpy(), 'dbs')\n","            \n","            if save_flag:\n","                with open(path_to_experiment + '/hist.pkl', 'wb') as output:\n","                    pickle.dump(hist, output)\n","\n","                    torch.save(model.state_dict(), path_to_experiment + '/model.pt')\n","                if hist['train_loss_db'][-1] < min_loss:\n","                            min_loss = hist['train_loss_db'][-1]\n","                            torch.save(model.state_dict(), path_to_experiment + '/best_model.pth')"]},{"cell_type":"markdown","metadata":{"id":"-Tn0UO280EiC"},"source":["\n","\n","# Data preprocess"]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1667226832463,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"CTQfi0y214Jv"},"outputs":[],"source":["np.random.seed()\n","# torch.cpu.set_device()\n","torch\n","cudnn.benchmark = True\n","torch.manual_seed(10)\n","# was fixed\n","cudnn.enabled=False\n","#torch.cpu.manual_seed(10)"]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1667226832464,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"cSFfPUmzf8ks"},"outputs":[],"source":["Batch_size=1000"]},{"cell_type":"code","execution_count":93,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1667226832464,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"jywxMPFH0pIk"},"outputs":[],"source":["serg_data=np.load('AdaptiveFilteringData/gsm_4c_in.npy').reshape(-1,1)\n","x_real, x_imag = torch.from_numpy(np.real(serg_data)), torch.from_numpy(np.imag(serg_data))\n","X = torch.DoubleTensor(torch.cat((x_real, x_imag), dim=1)).reshape(-1,2,1)"]},{"cell_type":"code","execution_count":94,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1667226832464,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"_KU0McmY8b5q"},"outputs":[],"source":["name = 'BlackBoxData/BlackBoxData_80'\n","# name = 'BlackBoxData'\n","# name = '../BlackBoxData/data1'\n","mat = scipy.io.loadmat(name)\n","x = np.array(mat['x']).reshape(-1,1)/2**15\n","d = np.array(mat['y']).reshape(-1,1)/2**15\n","# x = np.array(mat['xE']).reshape(-1,1)/2**15\n","# d = np.array(mat['d']).reshape(-1,1)/2**15\n","# x, d = mat['xE'], mat['d']\n","x_real, x_imag = torch.from_numpy(np.real(x)), torch.from_numpy(np.imag(x))\n","d_real, d_imag = torch.from_numpy(np.real(d)), torch.from_numpy(np.imag(d))\n","X = torch.DoubleTensor(torch.cat((x_real, x_imag), dim=1)).reshape(-1,2,1)\n","D = torch.DoubleTensor(torch.cat((d_real, d_imag), dim=1)).reshape(-1,2,1)\n","\n","train_queue = torch.utils.data.DataLoader(\n","    torch.cat((X,D),dim=-1), batch_size=Batch_size)#, pin_memory=True)\n","\n","valid_queue = torch.utils.data.DataLoader(\n","    torch.cat((X,D),dim=-1), batch_size=X.shape[0])#,pin_memory=True)"]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1667226832465,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"6IefLkxef8lU"},"outputs":[],"source":["gamma=0.95\n","step_size=5"]},{"cell_type":"code","execution_count":96,"metadata":{"executionInfo":{"elapsed":833,"status":"ok","timestamp":1667226833273,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"BHV0dgWTyRoU","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":279},"outputId":"ad51cd0c-93b2-4dc2-8789-c3401e191a89"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.psd(X.detach().cpu()[:,0,0]+1j*X.detach().cpu()[:,1,0],NFFT=2048, label = \"X\")\n","plt.psd(d.reshape(-1,),NFFT=2048, label = \"Y\")\n","plt.psd(x.reshape(-1,),NFFT=2048, label = \"x_small\")\n","plt.legend()\n","# plt.psd(x.reshape(-1,)*x.reshape(-1,),NFFT=2048)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"b20jyT09f8mH"},"source":["## Loss function"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1667226833274,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"},"user_tz":-180},"id":"V_dHc4pZf8mL"},"outputs":[],"source":["loss_fn = nn.MSELoss()\n"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"PJxrulfzJP44","executionInfo":{"status":"ok","timestamp":1667227223920,"user_tz":-180,"elapsed":572,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"}}},"outputs":[],"source":["from statistics import mode\n","\n","class Layerr(torch.nn.ModuleList):\n","    def __init__(self):\n","        super(Layerr,self).__init__()\n","        self.L = nn.ModuleList()\n","\n","    def ap_elem(self, elem : nn.Module):\n","        self.L.append(elem)\n","\n","    def forward(self, x):\n","        #summ = 0\n","        #for modul in self.L:\n","        #    summ = summ + modul(x)\n","        return sum(list(map( lambda m: m(x),  self.L)))\n","        #return summ\n","\n","\n","# 2 layer NN\n","class NN_2_layer(nn.Module):\n","    def __init__(self, l1, l2):\n","        super(NN_2_layer, self).__init__()\n","        self.layer_1 = l1\n","        self.layer_2 = l2\n","        #self.model = nn.Sequential(self.layer_1, self.layer_2)\n","    def forward(self, x):\n","        return self.layer_2.forward(self.layer_1.forward(x))\n","        #return self.model(x)\n","\n","class NN_simple_1(nn.Module):\n","    def __init__(self):\n","        super(NN_simple_1, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1)\n","    def forward(self, x):\n","        #return self.layer_2.forward(self.layer_1.forward(x))\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = double(self.conv2(x))\n","        return x\n","\n","class NN_simple_2(nn.Module):\n","    def __init__(self, l1, l2):\n","        super(NN_simple_2, self).__init__()\n","        self.layer_1 = l1\n","        self.layer_2 = l2\n","        self.model = nn.Sequential(self.layer_1, self.layer_2)\n","    def forward(self, x):\n","        #return self.layer_2.forward(self.layer_1.forward(x))\n","        return self.model(x)\n","\n","class Cell_try_2(nn.Module):\n","    def __init__(self,M=15,D=0,Poly_order=8,Passthrough=False):\n","        super(Cell_try_2,self).__init__()\n","        self.f = AFIR(M,0)\n","        self.f1 = AFIR(M,0)\n","        self.pol = Polynomial(Poly_order,Passthrough)\n","        self.prod = Prod_cmp()\n","        self.delay = Delay(D)\n","    def forward(self,x):\n","        return self.prod( self.f1(self.delay(x)), self.f(self.pol(self.delay(x))) )\n","\n","\n","class NN_2_row(nn.Module):\n","    def __init__(self, l1, l2):\n","        super(NN_2_row, self).__init__()\n","        self.conv_block1 = l1\n","        \n","        self.conv_block2 = l2\n","\n","        \n","    def forward(self, x):\n","        x0 = self.conv_block1(x)\n","        x1 = self.conv_block2((x0+x)/2) + x0\n","        \n","        return x1\n","\n","\n","    def forward_q(self, x):\n","        x0 = self.conv_block1(x)\n","\n","        return x0\n","\n","class Layerr_2(torch.nn.ModuleList):\n","    def __init__(self, n_row):\n","        super(Layerr_2,self).__init__()\n","        self.L = nn.ModuleList(2)\n","\n","\n","    def ap_elem(self, i_row, elem : nn.Module):\n","        self.L[i_row].append(elem)\n","\n","\n","    def forward(self, x):\n","        x0 = sum(list(map( lambda m: m(x),  self.L[0])))\n","        x1 = sum(list(map( lambda m: m(x0),  self.L[1])))\n","\n","        return x1\n","    \n","\n","\n","class Layerr_3(torch.nn.ModuleList):\n","    def __init__(self, n_row):\n","        super(Layerr_3, self).__init__()\n","        self.L = nn.ModuleList()\n","        for i in range(n_row):\n","            self.L.append(nn.ModuleList())\n","        \n","    def append_L(self,M=15,D=0,Poly_order=8,Passthrough=False):\n","        self.f = AFIR(M,0)\n","        self.pol = Polynomial(Poly_order,Passthrough)\n","        self.prod = Prod_cmp()\n","        self.delay = Delay(D)\n","    def forward(self,x):\n","        return self.prod( self.f(self.delay(x)), self.f(self.pol(self.delay(x))) )\n","        \n","class Layerr_4(torch.nn.Module):\n","    def __init__(self, NN):\n","        super(Layerr_4,self).__init__()\n","        self.L = nn.ModuleList()\n","        self.NN = NN\n","\n","    def forward(self, x):\n","        #summ = 0\n","        #for modul in self.L:\n","        #    summ = summ + modul(x)\n","        return sum(list(map( lambda m: m(x),  sum(list(map( lambda n: n(x),  self.NN))))))\n","        #return summ\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"hYbrMvEXJP44","executionInfo":{"status":"ok","timestamp":1667227447953,"user_tz":-180,"elapsed":766,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"}}},"outputs":[],"source":["l0 = Layerr()\n","#l1 = Layerr()\n","for i in range(5):\n","# det hyperparams \n","    l0.ap_elem(Cell_try_2(M=9, D=(-2 + 1*i), Poly_order=9))\n","    #l1.ap_elem(Cell_try_2(M=9, D=(-2 + 1*i), Poly_order=9))\n","  \n","#NN_raww = NN_2_row(l0,l1)\n","NN_raww = l0"]},{"cell_type":"code","source":["\n","\n","NN_raww = NN_raww.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raww.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, 20, scheduler, save_flag=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUZGwU7ON8vS","executionInfo":{"status":"ok","timestamp":1667227522213,"user_tz":-180,"elapsed":71513,"user":{"displayName":"Олег Суменков","userId":"14641319921952937605"}},"outputId":"a32ad88c-3eb0-4978-9cea-ce411aeff65a"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stderr","text":["  5%|▌         | 1/20 [00:03<01:02,  3.28s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  4.536398051858188e-05 Accuracy =  -28.478288578751982 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 2/20 [00:06<00:59,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  3.065657882854544e-05 Accuracy =  -30.180163257247653 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 3/20 [00:09<00:56,  3.33s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  2.361255052463771e-05 Accuracy =  -31.313971129318826 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 4/20 [00:13<00:52,  3.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  2.0146006687221618e-05 Accuracy =  -32.003510393649165 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 5/20 [00:16<00:50,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.77280572298378e-05 Accuracy =  -32.5587886809548 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 6/20 [00:20<00:46,  3.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.5928110723117182e-05 Accuracy =  -33.02375747141818 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 7/20 [00:23<00:43,  3.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.4810819465453108e-05 Accuracy =  -33.33960924942881 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 8/20 [00:26<00:40,  3.36s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.3959550181508599e-05 Accuracy =  -33.59668588894105 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 9/20 [00:30<00:38,  3.46s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.2923422210882992e-05 Accuracy =  -33.931624800908786 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 10/20 [00:35<00:39,  3.93s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.2404446919419263e-05 Accuracy =  -34.10962608109451 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 11/20 [00:38<00:33,  3.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.198835267189561e-05 Accuracy =  -34.257805026549576 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 12/20 [00:42<00:29,  3.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.1722691553753489e-05 Accuracy =  -34.35512675113591 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 13/20 [00:45<00:25,  3.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.1525648394283623e-05 Accuracy =  -34.428746464401115 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 14/20 [00:50<00:23,  3.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.138699365683649e-05 Accuracy =  -34.481309344137806 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 15/20 [00:54<00:19,  3.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.1271354261192939e-05 Accuracy =  -34.525639131679945 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 16/20 [00:57<00:15,  3.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.1164249268484734e-05 Accuracy =  -34.56710488553872 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 17/20 [01:01<00:10,  3.64s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.109050491966876e-05 Accuracy =  -34.59588694326253 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 18/20 [01:04<00:07,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.10366485938441e-05 Accuracy =  -34.617027982749924 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 19/20 [01:07<00:03,  3.51s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.0990387558820175e-05 Accuracy =  -34.6352700572968 dbs\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [01:11<00:00,  3.55s/it]"]},{"output_type":"stream","name":"stdout","text":["Loss =  1.0929479988656695e-05 Accuracy =  -34.659405138996775 dbs\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYb1dsenJP45"},"outputs":[],"source":["l1 = Layerr()\n","l2 = Layerr()\n","\n","l1.ap_elem(Cell_try_2())\n","l1.ap_elem(Cell_try_2())\n","\n","\n","l2.ap_elem(Cell_try_2())\n","l2.ap_elem(Cell_try_2())\n","l2.ap_elem(Cell_try_2())\n","l2.ap_elem(Cell_try_2())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["1b4a08e2e05e4319a5ae363f288804c3"]},"id":"mIpJs9XCJP45","outputId":"67493be2-60f9-4d14-fb45-87bfacb4758e"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b4a08e2e05e4319a5ae363f288804c3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [176], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raww\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m      4\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 5\u001b[0m train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [149], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39mrange\u001b[39m(n_epoch)):\n\u001b[0;32m      7\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m     train_of_epoch(train_queue, model, criterion, optimizer)\n\u001b[0;32m      9\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n","Cell \u001b[1;32mIn [167], line 7\u001b[0m, in \u001b[0;36mtrain_of_epoch\u001b[1;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m desired \u001b[39m=\u001b[39m Variable(train[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(input_batch)\n\u001b[0;32m      8\u001b[0m \u001b[39m#out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#out = sum(list(map( lambda n: n(out_0),  model[1])))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, desired)\n","Cell \u001b[1;32mIn [169], line 70\u001b[0m, in \u001b[0;36mNN_2_row.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     69\u001b[0m     x0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_block1(x)\n\u001b[1;32m---> 70\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_block2(x0)\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m x1\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [169], line 12\u001b[0m, in \u001b[0;36mLayerr.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m( \u001b[39mlambda\u001b[39;49;00m m: m(x),  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL)))\n","Cell \u001b[1;32mIn [169], line 12\u001b[0m, in \u001b[0;36mLayerr.forward.<locals>.<lambda>\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m( \u001b[39mlambda\u001b[39;00m m: m(x),  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)))\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [169], line 57\u001b[0m, in \u001b[0;36mCell_try_2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprod( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay(x)), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpol(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelay(x))) )\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32m~\\Desktop\\NNForDPD\\huawei\\DPDBlocks\\blocks.py:78\u001b[0m, in \u001b[0;36mPolynomial.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morder):\n\u001b[0;32m     77\u001b[0m     out[:, \u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m0\u001b[39m, i]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mpow(x,i)\n\u001b[1;32m---> 78\u001b[0m     out[:, \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[\u001b[39m1\u001b[39m, i]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mpow(x,i)\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m out\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1252\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_is_full_backward_hook\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m   1250\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_full_backward_hook \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m   1254\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","NN_raww = NN_2_row(l1,l2)\n","NN_raww = NN_raww.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raww.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, 20, scheduler, save_flag=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["efffc4410c584559882f22335cdc69c4"]},"id":"vh-rU-UlJP45","outputId":"02dcc0b5-2f9e-4a31-e1d6-fcfb3c2e88a5"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_16292\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efffc4410c584559882f22335cdc69c4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss =  0.00010456197910466027 Accuracy =  -24.8516621834706 dbs\n","Loss =  9.448935912035815e-05 Accuracy =  -25.291571097669873 dbs\n","Loss =  9.048510806713103e-05 Accuracy =  -25.479629037283303 dbs\n","Loss =  8.90595216537008e-05 Accuracy =  -25.548596549698445 dbs\n","Loss =  8.820588354641237e-05 Accuracy =  -25.590424585450478 dbs\n","Loss =  8.757277312330857e-05 Accuracy =  -25.621709106264696 dbs\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(l1\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m      3\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 4\u001b[0m train(train_queue, valid_queue, l1, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [12], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m it\u001b[39m%\u001b[39mlog_every\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m         loss_v,accuracy_v\u001b[39m=\u001b[39meval_model(valid_queue, model, loss_fn)\n\u001b[0;32m     16\u001b[0m         update_history(hist,it, accuracy_v, loss_v, timer() \u001b[39m-\u001b[39m t0,)\n\u001b[0;32m     17\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoss = \u001b[39m\u001b[39m'\u001b[39m,loss_v\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39mAccuracy = \u001b[39m\u001b[39m'\u001b[39m, accuracy_v\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39mdbs\u001b[39m\u001b[39m'\u001b[39m)\n","Cell \u001b[1;32mIn [10], line 2\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m(valid_queue, model, criterion)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_model\u001b[39m(valid_queue, model, criterion):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mfor\u001b[39;00m step, (valid) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(valid_queue):\n\u001b[0;32m      3\u001b[0m         model\u001b[39m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m         input_batch \u001b[39m=\u001b[39m Variable(valid[:,:,:\u001b[39m1\u001b[39m],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","l1 = l1.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(l1.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, l1, loss_fn, optimizer, 20, scheduler, save_flag=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jusVPTmdJP45"},"outputs":[],"source":["D = {'p': [4, 5, 6, 7, 8, 9], 'k' : [3, 5, 7, 9], 'z' : [-2, -1, 0, 1, 2]}\n","ex_D = {} # extremum vals of D\n","\n","for key in D.keys():\n","  ex_D[key] = [ min(D[key]), max(D[key])]\n","\n","\n","def objective(trial):\n","  # create and train NN\n","  net = torch.nn.ModuleList()\n","\n","  complex_cur = 0\n","  l0 = Layerr()\n","  l1 = Layerr()\n","  for i in range(5):\n","    # det hyperparams \n","    poly_ord0 = trial.suggest_int('p0'+str(i), ex_D['p'][0], ex_D['p'][1])\n","    conv_ord0 = trial.suggest_int('k0'+str(i), ex_D['k'][0], ex_D['k'][1], step=2)\n","    l0.ap_elem(Cell_try_2(M=conv_ord0, D=(ex_D['z'][0] + 1*i), Poly_order=poly_ord0))\n","    poly_ord1 = trial.suggest_int('p1'+str(i), ex_D['p'][0], ex_D['p'][1])\n","    conv_ord1 = trial.suggest_int('k1'+str(i), ex_D['k'][0], ex_D['k'][1], step=2)\n","    l1.ap_elem(Cell_try_2(M=conv_ord1, D=(ex_D['z'][0] + 1*i), Poly_order=poly_ord1))\n","  \n","\n","\n","  NN_raww = NN_2_row(l0,l1)\n","  NN_raww = NN_raww.to(torch.device('cpu'))\n","  optimizer = torch.optim.Adam(NN_raww.parameters(), lr=1e-2)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","  train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","  loss_cur, accuracy_cur = eval_model(valid_queue, NN_raww, loss_fn)\n","  score_cur = accuracy_cur.item()\n","\n","  return score_cur"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["fbfd6478bfd84a18981df40d1799b7d3"]},"id":"NohaN3eXJP45","outputId":"9003f3c4-ce20-4bf9-c1e7-397c25066e3a"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-10-31 13:58:19,767]\u001b[0m A new study created in memory with name: no-name-bc422455-2045-4891-a1cf-07a63e89eb14\u001b[0m\n","C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbfd6478bfd84a18981df40d1799b7d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n","Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n","Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[33m[W 2022-10-31 13:58:47,728]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n","Traceback (most recent call last):\n","  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n","    value_or_values = func(trial)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\737231000.py\", line 30, in objective\n","    train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py\", line 15, in train\n","    loss_v,accuracy_v=eval_model(valid_queue, model, loss_fn)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\2749143958.py\", line 6, in eval_model\n","    out = model.forward(input_batch)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\4164055926.py\", line 69, in forward\n","    x0 = self.conv_block1(x)\n","  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\4164055926.py\", line 12, in forward\n","    return sum(list(map( lambda m: m(x),  self.L)))\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\4164055926.py\", line 12, in <lambda>\n","    return sum(list(map( lambda m: m(x),  self.L)))\n","  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\4164055926.py\", line 57, in forward\n","    return self.prod( self.f(self.delay(x)), self.f(self.pol(self.delay(x))) )\n","  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"C:\\Users\\Student\\Desktop\\NNForDPD\\huawei\\DPDBlocks\\blocks.py\", line 18, in forward\n","    return torch.cat((r1-r2, i1+i2), dim=1)\n","KeyboardInterrupt\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [163], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(study\u001b[39m.\u001b[39mbest_params)\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","Cell \u001b[1;32mIn [162], line 30\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raww\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m     29\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m---> 30\u001b[0m train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     32\u001b[0m loss_cur, accuracy_cur \u001b[39m=\u001b[39m eval_model(valid_queue, NN_raww, loss_fn)\n\u001b[0;32m     33\u001b[0m score_cur \u001b[39m=\u001b[39m accuracy_cur\u001b[39m.\u001b[39mitem()\n","Cell \u001b[1;32mIn [149], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m it\u001b[39m%\u001b[39mlog_every\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m         loss_v,accuracy_v\u001b[39m=\u001b[39meval_model(valid_queue, model, loss_fn)\n\u001b[0;32m     16\u001b[0m         update_history(hist,it, accuracy_v, loss_v, timer() \u001b[39m-\u001b[39m t0,)\n\u001b[0;32m     17\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoss = \u001b[39m\u001b[39m'\u001b[39m,loss_v\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39mAccuracy = \u001b[39m\u001b[39m'\u001b[39m, accuracy_v\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39mdbs\u001b[39m\u001b[39m'\u001b[39m)\n","Cell \u001b[1;32mIn [147], line 6\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m(valid_queue, model, criterion)\u001b[0m\n\u001b[0;32m      4\u001b[0m input_batch \u001b[39m=\u001b[39m Variable(valid[:,:,:\u001b[39m1\u001b[39m],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      5\u001b[0m desired \u001b[39m=\u001b[39m Variable(valid[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m----> 6\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(input_batch)\n\u001b[0;32m      7\u001b[0m \u001b[39m#out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m#out = sum(list(map( lambda n: n(out_0),  model[1])))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m loss\u001b[39m=\u001b[39mcriterion(out,desired)\n","Cell \u001b[1;32mIn [161], line 69\u001b[0m, in \u001b[0;36mNN_2_row.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 69\u001b[0m     x0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_block1(x)\n\u001b[0;32m     70\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_block2(x0)\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m x1\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [161], line 12\u001b[0m, in \u001b[0;36mLayerr.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m( \u001b[39mlambda\u001b[39;49;00m m: m(x),  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL)))\n","Cell \u001b[1;32mIn [161], line 12\u001b[0m, in \u001b[0;36mLayerr.forward.<locals>.<lambda>\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m( \u001b[39mlambda\u001b[39;00m m: m(x),  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)))\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [161], line 57\u001b[0m, in \u001b[0;36mCell_try_2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprod( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay(x)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpol(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelay(x))) )\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32m~\\Desktop\\NNForDPD\\huawei\\DPDBlocks\\blocks.py:18\u001b[0m, in \u001b[0;36mAFIR.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m i1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreal(x[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     17\u001b[0m i2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimag(x[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m---> 18\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mcat((r1\u001b[39m-\u001b[39;49mr2, i1\u001b[39m+\u001b[39;49mi2), dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=200)\n","print(study.best_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["625270286b994bf4b82a94d4aacdc46d"]},"id":"NR6OGDmyJP46","outputId":"5d6695c8-516c-4fcb-fbcb-14ff0ffde821"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"625270286b994bf4b82a94d4aacdc46d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n","Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [171], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raw\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m      4\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 5\u001b[0m train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [149], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39mrange\u001b[39m(n_epoch)):\n\u001b[0;32m      7\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m     train_of_epoch(train_queue, model, criterion, optimizer)\n\u001b[0;32m      9\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n","Cell \u001b[1;32mIn [167], line 7\u001b[0m, in \u001b[0;36mtrain_of_epoch\u001b[1;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m desired \u001b[39m=\u001b[39m Variable(train[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(input_batch)\n\u001b[0;32m      8\u001b[0m \u001b[39m#out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#out = sum(list(map( lambda n: n(out_0),  model[1])))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, desired)\n","Cell \u001b[1;32mIn [169], line 23\u001b[0m, in \u001b[0;36mNN_2_layer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_2\u001b[39m.\u001b[39mforward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer_1\u001b[39m.\u001b[39;49mforward(x))\n","Cell \u001b[1;32mIn [169], line 12\u001b[0m, in \u001b[0;36mLayerr.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m( \u001b[39mlambda\u001b[39;49;00m m: m(x),  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL)))\n","Cell \u001b[1;32mIn [169], line 12\u001b[0m, in \u001b[0;36mLayerr.forward.<locals>.<lambda>\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m( \u001b[39mlambda\u001b[39;00m m: m(x),  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)))\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [169], line 57\u001b[0m, in \u001b[0;36mCell_try_2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprod( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay(x)), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpol(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelay(x))) )\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32m~\\Desktop\\NNForDPD\\huawei\\DPDBlocks\\blocks.py:77\u001b[0m, in \u001b[0;36mPolynomial.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     75\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mAbs(x)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morder):\n\u001b[1;32m---> 77\u001b[0m     out[:, \u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m0\u001b[39m, i]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39;49mpow(x,i)\n\u001b[0;32m     78\u001b[0m     out[:, \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m1\u001b[39m, i]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mpow(x,i)\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m out\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","NN_raw = NN_2_layer(l2, l1)\n","NN_raw = NN_raw.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raw.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["736939e79ecf419aa7d748b35f313345"]},"id":"zpVgJQV5JP46","outputId":"3f46cd9e-9425-4ce7-ad28-4544d299598a"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"736939e79ecf419aa7d748b35f313345","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"Input type (double) and bias type (float) should be the same","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn [172], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raw\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m      4\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 5\u001b[0m train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [149], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39mrange\u001b[39m(n_epoch)):\n\u001b[0;32m      7\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m     train_of_epoch(train_queue, model, criterion, optimizer)\n\u001b[0;32m      9\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n","Cell \u001b[1;32mIn [167], line 7\u001b[0m, in \u001b[0;36mtrain_of_epoch\u001b[1;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m desired \u001b[39m=\u001b[39m Variable(train[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(input_batch)\n\u001b[0;32m      8\u001b[0m \u001b[39m#out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#out = sum(list(map( lambda n: n(out_0),  model[1])))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, desired)\n","Cell \u001b[1;32mIn [169], line 34\u001b[0m, in \u001b[0;36mNN_simple_1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     33\u001b[0m     \u001b[39m#return self.layer_2.forward(self.layer_1.forward(x))\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m     35\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[0;32m     36\u001b[0m     x \u001b[39m=\u001b[39m double(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n","\u001b[1;31mRuntimeError\u001b[0m: Input type (double) and bias type (float) should be the same"]}],"source":["NN_raw = NN_simple_1()\n","NN_raw = NN_raw.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raw.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, 20, scheduler, save_flag=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LLkVgW0UJP46"},"outputs":[],"source":["\n","NN_raw = NN_2_layer(l2, l1)\n","NN_raw = NN_raw.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raw.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Q-cZr6YFf8mg"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"vAcOp02dx4uY"},"source":["# Ensemble of small NN\n","(as nn.ModuleList with Optuna)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":684,"referenced_widgets":["3b30b65099f64b1ab763a6ac7cb7a187","2b45d052f23a410fa5484c50ac9d752c","0f41361be62b4f2e906ef07f2f692121","1d21f747016e410fbf6d01091beaebb7","3e576a7f44e84632b4b988639109bd40","a271e473b164475f9fb1f62fef16955a","eff2cbbc8395491881be7fe6dce6e160","16cf283945ce45b1a9c6560656cb01d0","cf878e3f1497456e9883a8bf623b5517","cbfa16e6d0cd4794a004299a87add101","7b0dd06176cc4413bde50d2d6ecfd330"]},"executionInfo":{"elapsed":8,"status":"error","timestamp":1666969869488,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"zV0Fah_yydzY","outputId":"016e5a4a-807e-490d-c88a-8a2689ff40d2"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-10-28 14:59:03,427]\u001b[0m A new study created in memory with name: no-name-bbdcbe0b-1894-4c03-8e91-7b73169ad285\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b30b65099f64b1ab763a6ac7cb7a187","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[33m[W 2022-10-28 14:59:03,504]\u001b[0m Trial 0 failed because of the following error: TypeError(\"'Cell_try_2' object is not iterable\")\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n","    value_or_values = func(trial)\n","  File \"<ipython-input-21-fe34253913b2>\", line 46, in objective\n","    train(train_queue, valid_queue, net, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","  File \"<ipython-input-13-2112ca6e0cf5>\", line 8, in train\n","    train_of_epoch(train_queue, model, criterion, optimizer)\n","  File \"<ipython-input-12-6294c9575d39>\", line 8, in train_of_epoch\n","    out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\n","TypeError: 'Cell_try_2' object is not iterable\n"]},{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-fe34253913b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-fe34253913b2>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mloss_cur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-2112ca6e0cf5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_of_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-6294c9575d39>\u001b[0m in \u001b[0;36mtrain_of_epoch\u001b[0;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#out = model.forward(input_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mout_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'Cell_try_2' object is not iterable"]}],"source":["class Cell_try_2(nn.Module):\n","    def __init__(self,M=15,D=0,Poly_order=8,Passthrough=False):\n","        super(Cell_try_2,self).__init__()\n","        self.f = AFIR(M,0)\n","        self.pol = Polynomial(Poly_order,Passthrough)\n","        self.prod = Prod_cmp()\n","        self.delay = Delay(D)\n","    def forward(self,x):\n","        #return self.prod(self.f(self.delay(x)), self.pol(self.delay(x)))\n","        return self.prod( self.f(self.delay(x)), self.f(self.pol(self.delay(x))) )\n","\n","D = {'p': [4, 5, 6, 7, 8, 9], 'k' : [3, 5, 7, 9], 'z' : [-2, -1, 0, 1, 2]}\n","ex_D = {} # extremum vals of D\n","\n","for key in D.keys():\n","  ex_D[key] = [ min(D[key]), max(D[key])]\n","\n","# complex reference model\n","ref_model = {'k': [9,5,9,7,9],'p': [9,8,6,9,6]}\n","\n","### params of the functional\n","score_huge = -37\n","score_min = -20.0\n","complex_huge = 2 * ( sum(ref_model['k']) + sum(ref_model['p']) )\n","complex_min = 2 * (4 * 5 + 3 * 5)\n","trtr_coef = 0.4\n","\n","\n","\n","def objective(trial):\n","  # create and train NN\n","  net = torch.nn.ModuleList()\n","\n","  complex_cur = 0\n","\n","  for i in range(2):\n","    # det hyperparams \n","    poly_ord = trial.suggest_int('p'+str(i), ex_D['p'][0], ex_D['p'][1])\n","    conv_ord = trial.suggest_int('k'+str(i), ex_D['k'][0], ex_D['k'][1], step=2)\n","    net.append(Cell_try_2(M=conv_ord, D=(ex_D['z'][0] + 1*i), Poly_order=poly_ord))\n","    complex_cur = complex_cur + poly_ord + conv_ord\n","\n","  net = net.to(torch.device('cpu'))\n","  optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","  train(train_queue, valid_queue, net, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","  loss_cur, accuracy_cur = eval_model(valid_queue, net, loss_fn)\n","  score_cur = accuracy_cur.item()\n","\n","  return score_cur\n","  #return  (complex_cur - complex_min) / (complex_huge - complex_min) + trtr_coef * (score_huge - score_cur) / (score_huge - score_min)\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=200)\n","print(study.best_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJrBEkE65qC1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9FrpFBtO5OlW"},"outputs":[],"source":["print(study.best_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-ziMOPR1L2r"},"outputs":[],"source":["\n","D = {'p': [3, 4, 5, 6, 7, 8, 9], 'k' : [1, 3, 5, 9], 'z' : [-2, -1, 0, 1, 2]}\n","ex_D = {} # extremum vals of D\n","\n","for key in D.keys():\n","  ex_D[key] = [ min(D[key]), max(D[key])]\n","\n","# huge model\n","huge_model = Cell_try_2(M=ex_D['k'][1], Poly_order=ex_D['p'][1])\n","huge_model = huge_model.to(\"cpu\")\n","#huge_model = huge_model.to(\"cuda:0\")\n","optimizer = torch.optim.Adam(huge_model.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, huge_model, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","\n","loss_huge, accuracy_huge = eval_model(valid_queue, huge_model, loss_fn)\n","score_huge = accuracy_huge.item()\n","complex_huge = ex_D['k'][1] + ex_D['p'][1]\n","\n","\n","# small model\n","small_model = Cell_try_2(M=ex_D['k'][0], Poly_order=ex_D['p'][0])\n","#small_model = small_model.to(\"cuda:0\")\n","small_model = small_model.to(\"cpu\")\n","optimizer = torch.optim.Adam(small_model.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, small_model, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","\n","loss_small, accuracy_small = eval_model(valid_queue, small_model, loss_fn)\n","score_small = -13\n","complex_small = ex_D['k'][0] + ex_D['p'][0]\n","trtr_coef = 0.1\n","def objective(trial):\n","  # det hyperparams \n","  poly_ord = trial.suggest_int('p', ex_D['p'][0], ex_D['p'][1])\n","  del_val = trial.suggest_int('z', ex_D['z'][0], ex_D['z'][1])\n","  conv_ord = trial.suggest_int('k', ex_D['k'][0], ex_D['k'][1], step=2)\n","\n","  # create and train NN\n","  net = Cell_try_2(M=conv_ord, D=del_val, Poly_order=poly_ord)\n","  net = net.to(\"cpu\")\n","  optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","  train(train_queue, valid_queue, net, loss_fn, optimizer,20,scheduler,save_flag=False)\n","\n","  loss_cur, accuracy_cur = eval_model(valid_queue, net, loss_fn)\n","  score_cur = accuracy_cur.item()\n","  complex_cur = poly_ord + conv_ord\n","\n","  # check if val of score is positive or not and then fix it\n","  #return (score_huge - score_cur) / score_huge + (complex_cur - complex_huge) / complex_huge\n","  return trtr_coef * (complex_cur - complex_small) / (complex_huge - complex_small) - (score_cur - score_small) / (score_huge - score_small)\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gtsor6JFBpPo"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1hDGDFmI3y1A8BSQRa_1APBSrxUVOazku","timestamp":1666965206798},{"file_id":"1HcKoksGhyK1Sbo1XJGFUh0llgniyCtvU","timestamp":1666941560441}]},"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"5c96f01ceb864e4f314488f796d7ad3ed3c5d7e2e6828b71e2c816343e6bed5e"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0f41361be62b4f2e906ef07f2f692121":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_16cf283945ce45b1a9c6560656cb01d0","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf878e3f1497456e9883a8bf623b5517","value":0}},"16cf283945ce45b1a9c6560656cb01d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d21f747016e410fbf6d01091beaebb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbfa16e6d0cd4794a004299a87add101","placeholder":"​","style":"IPY_MODEL_7b0dd06176cc4413bde50d2d6ecfd330","value":" 0/20 [00:00&lt;?, ?it/s]"}},"2b45d052f23a410fa5484c50ac9d752c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a271e473b164475f9fb1f62fef16955a","placeholder":"​","style":"IPY_MODEL_eff2cbbc8395491881be7fe6dce6e160","value":"  0%"}},"3b30b65099f64b1ab763a6ac7cb7a187":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b45d052f23a410fa5484c50ac9d752c","IPY_MODEL_0f41361be62b4f2e906ef07f2f692121","IPY_MODEL_1d21f747016e410fbf6d01091beaebb7"],"layout":"IPY_MODEL_3e576a7f44e84632b4b988639109bd40"}},"3e576a7f44e84632b4b988639109bd40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b0dd06176cc4413bde50d2d6ecfd330":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a271e473b164475f9fb1f62fef16955a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbfa16e6d0cd4794a004299a87add101":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf878e3f1497456e9883a8bf623b5517":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eff2cbbc8395491881be7fe6dce6e160":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}