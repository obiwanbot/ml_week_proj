{"cells":[{"cell_type":"markdown","metadata":{"id":"CoT4esNt1BU7"},"source":["# Includes"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1994,"status":"ok","timestamp":1666969859475,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"wLf0VAKx1D3K"},"outputs":[],"source":["import os\n","import sys\n","import time\n","import glob\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.utils\n","import torch.nn.functional as F\n","import torchvision.datasets as dset\n","import torch.backends.cudnn as cudnn\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from timeit import default_timer as timer\n","from tqdm import tqdm\n","from collections import defaultdict,Counter\n","\n","import scipy.io"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4582,"status":"ok","timestamp":1666969864056,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"TXPj4fXIkNLY","outputId":"2d2d3524-db3c-42e8-db5e-123ad7ba8f53"},"outputs":[],"source":["import optuna"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666969864057,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"IGK9bOe7gHzy","outputId":"e0a375f7-f694-4668-fe99-931f8822c0be"},"outputs":[{"data":{"text/plain":["ModuleList()"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.nn.ModuleList()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666969868794,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"Rt4Yx29bgut5","outputId":"3ae9a6ef-598b-4216-9515-43d46ee2d3ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\Student\\Desktop\\NNForDPD\\huawei\n"]}],"source":["#$cd /content/drive/My Drive/Colab Notebooks/huawei\n","%cd C:\\Users\\Student\\Desktop\\NNForDPD\\huawei"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666969868794,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"UxHbQ7L8f8hT"},"outputs":[],"source":["from DPDBlocks.blocks import AFIR,ABS,Polynomial,Delay,Prod_cmp"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1666969868794,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"Nx7iinZ0yOlS"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","import matplotlib.mlab as mlab\n","import matplotlib.gridspec as gridspec"]},{"cell_type":"markdown","metadata":{"id":"OJNBQw7yvZPh"},"source":["# Operations"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666969868795,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"SwOErQU3jLZ7"},"outputs":[],"source":["def NMSE(X, E):\n","    return 10*torch.log10((E.norm(dim=1)**2).sum()/(X.norm(dim=1)**2).sum())"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666969868795,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"Kqaq62i5f8iw"},"outputs":[],"source":["def update_history(hist,iter_num, val_acc, val_loss, time):\n","    hist['iter'].append(iter_num)\n","    hist['time'].append(time)\n","    hist['train_loss'].append(val_loss.item())\n","        # self.hist['norm_coeffs'].append(train_loss.item())\n","    hist['train_loss_db'].append(val_acc.item())"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666969868796,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"pVuT0wQzVlgq"},"outputs":[],"source":["def draw_spectrum(input_batch,desired,out):\n","  plt.psd(input_batch.detach().cpu()[0,0,:]+\n","                1j*input_batch.detach().cpu()[0,1,:],NFFT=2048)\n","  plt.psd(desired.detach().cpu()[0,0,:]+\n","                1j*desired.detach().cpu()[0,1,:],NFFT=2048)\n","        # plt.psd(desired.permute(2,1,0).detach().cpu().reshape(-1,),NFFT=2048)\n","  plt.psd((out-desired).detach().cpu()[0,0,:]+\n","                1j*(out-desired).detach().cpu()[0,1,:],NFFT=2048)\n","        # plt.psd((out-desired).permute(2,1,0).detach().cpu().reshape(-1,),NFFT=2048)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ekZgZN6Fz9PT"},"source":["## Train Function"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666969868796,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"kv9Ta7XbVzIQ"},"outputs":[],"source":["def eval_model(valid_queue, model, criterion):\n","    for step, (valid) in enumerate(valid_queue):\n","        model.eval()\n","        input_batch = Variable(valid[:,:,:1],requires_grad=False).permute(2,1,0).cpu()\n","        desired = Variable(valid[:,:,1:],requires_grad=False).permute(2,1,0).cpu()\n","        out = model.forward(input_batch)\n","        #out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\n","        #out = sum(list(map( lambda n: n(out_0),  model[1])))\n","\n","        loss=criterion(out,desired)\n","\n","\n","        #draw_spectrum(input_batch,desired,out)\n","        accuracy = NMSE(input_batch, out - desired)\n","\n","    return loss,accuracy"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666969868797,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"8la_NvkOf8jT"},"outputs":[],"source":["from numpy import gradient\n","\n","\n","def train_of_epoch(train_queue, model, criterion, optimizer):\n","    for step, (train) in enumerate(train_queue):\n","\n","        input_batch = Variable(train[:,:,:1],requires_grad=False).permute(2,1,0).cpu()\n","        desired = Variable(train[:,:,1:],requires_grad=False).permute(2,1,0).cpu()\n","        optimizer.zero_grad()\n","        out = model.forward(input_batch)\n","        #out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\n","        #out = sum(list(map( lambda n: n(out_0),  model[1])))\n","\n","        loss = criterion(out, desired)\n","    \n","        loss.backward()\n","        \n","        optimizer.step()\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666969868797,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"Y6jSRaD9f8j8"},"outputs":[],"source":["def train(train_queue, valid_queue, model, criterion, optimizer,n_epoch,\n","          scheduler,log_every=1,save_flag=True,path_to_experiment=''):\n","    min_loss=0\n","    hist=defaultdict(list)\n","    t0=timer()\n","    for it in tqdm(range(n_epoch)):\n","        model.train(True)\n","        train_of_epoch(train_queue, model, criterion, optimizer)\n","        scheduler.step()\n","\n","    #     if return_history and it % log_every == 0:\n","    #         model.init_for_batch(train)\n","    #         train_loss = complex_mse(model.forward(train.x), train.y)\n","        if it%log_every==0:\n","            loss_v,accuracy_v=eval_model(valid_queue, model, loss_fn)\n","            update_history(hist,it, accuracy_v, loss_v, timer() - t0,)\n","            print('Loss = ',loss_v.cpu().detach().numpy(), 'Accuracy = ', accuracy_v.cpu().detach().numpy(), 'dbs')\n","            \n","            if save_flag:\n","                with open(path_to_experiment + '/hist.pkl', 'wb') as output:\n","                    pickle.dump(hist, output)\n","\n","                    torch.save(model.state_dict(), path_to_experiment + '/model.pt')\n","                if hist['train_loss_db'][-1] < min_loss:\n","                            min_loss = hist['train_loss_db'][-1]\n","                            torch.save(model.state_dict(), path_to_experiment + '/best_model.pth')"]},{"cell_type":"markdown","metadata":{"id":"-Tn0UO280EiC"},"source":["\n","\n","# Data preprocess"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666969868797,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"CTQfi0y214Jv"},"outputs":[],"source":["np.random.seed()\n","# torch.cpu.set_device()\n","torch\n","cudnn.benchmark = True\n","torch.manual_seed(10)\n","# was fixed\n","cudnn.enabled=False\n","#torch.cpu.manual_seed(10)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666969868798,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"cSFfPUmzf8ks"},"outputs":[],"source":["Batch_size=1000"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666969868798,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"jywxMPFH0pIk"},"outputs":[],"source":["serg_data=np.load('C:/Users/Student/Desktop/NNForDPD/huawei/AdaptiveFilteringData/gsm_4c_in.npy').reshape(-1,1)\n","x_real, x_imag = torch.from_numpy(np.real(serg_data)), torch.from_numpy(np.imag(serg_data))\n","X = torch.DoubleTensor(torch.cat((x_real, x_imag), dim=1)).reshape(-1,2,1)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666969868798,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"_KU0McmY8b5q"},"outputs":[],"source":["name = 'C:/Users/Student/Desktop/NNForDPD/huawei/BlackBoxData/BlackBoxData_80'\n","# name = 'BlackBoxData'\n","# name = '../BlackBoxData/data1'\n","mat = scipy.io.loadmat(name)\n","x = np.array(mat['x']).reshape(-1,1)/2**15\n","d = np.array(mat['y']).reshape(-1,1)/2**15\n","# x = np.array(mat['xE']).reshape(-1,1)/2**15\n","# d = np.array(mat['d']).reshape(-1,1)/2**15\n","# x, d = mat['xE'], mat['d']\n","x_real, x_imag = torch.from_numpy(np.real(x)), torch.from_numpy(np.imag(x))\n","d_real, d_imag = torch.from_numpy(np.real(d)), torch.from_numpy(np.imag(d))\n","X = torch.DoubleTensor(torch.cat((x_real, x_imag), dim=1)).reshape(-1,2,1)\n","D = torch.DoubleTensor(torch.cat((d_real, d_imag), dim=1)).reshape(-1,2,1)\n","\n","train_queue = torch.utils.data.DataLoader(\n","    torch.cat((X,D),dim=-1), batch_size=Batch_size)#, pin_memory=True)\n","\n","valid_queue = torch.utils.data.DataLoader(\n","    torch.cat((X,D),dim=-1), batch_size=X.shape[0])#,pin_memory=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666969868798,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"6IefLkxef8lU"},"outputs":[],"source":["gamma=0.95\n","step_size=5"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":698,"status":"ok","timestamp":1666969869487,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"BHV0dgWTyRoU","outputId":"70f38c6c-f0e8-44ac-9e7d-3ffbbbe6469f","scrolled":true},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkcAAAGwCAYAAACjPMHLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACmpklEQVR4nOzdd3gUVRfA4d+WVEgIJaH3jlRFkQ4C0gQVLICFCKLYFRsIn2IHsfdKEUUUREBBAQUEBZHeFZASWuikkJBkd+f7Y7Itu0l2k5ndZDnv8/CwOzM7cydlc/bec881KIqiIIQQQgghADAGuwFCCCGEECWJBEdCCCGEEC4kOBJCCCGEcCHBkRBCCCGECwmOhBBCCCFcSHAkhBBCCOFCgiMhhBBCCBfmYDegtLHZbBw7doyYmBgMBkOwmyOEEEIIHyiKQlpaGtWqVcNoLLhvSIIjPx07doyaNWsGuxlCCCGEKILDhw9To0aNAo+R4MhPMTExgPrFjY2N1fTcOTk5LF26lGuvvZawsDBNz10ShPr9Qejfo9xf6Rfq9xjq9wehf4963V9qaio1a9Z0/B0viARHfrIPpcXGxuoSHEVHRxMbGxuyP/ChfH8Q+vco91f6hfo9hvr9Qejfo97350tKjCRkCyGEEEK4kOBICCGEEMLFJRscZWVl0bp1awwGA1u2bAl2c4QQQghRQlyyOUdPPfUU1apVY+vWrcFuihBCiFLMarWSk5MTsOvl5ORgNpu5ePEiVqs1YNcNlOLcX3h4eKHT9H1xSQZHP//8M0uXLuX777/n559/LvDYrKwssrKyHM9TU1MB9Zun9S+D/XyB/CULpFC/Pwj9e5T7K/1C/R4DeX+KonDy5EnH34VAURSFKlWqkJSUFJL19opzf0ajkVq1anlN5PbnZ8KgKIri15VLuRMnTnDFFVcwf/58KlWqRN26ddm8eTOtW7f2evzEiRN5/vnnPbbPmjWL6OhonVsrhBCipIqJiaF8+fJUqlSJ8PDwkAxUShNFUTh16hTnzp3j7NmzHvszMjIYNmwYKSkphc42v6SCI0VR6NevHx07dmTChAkcPHiw0ODIW89RzZo1OX36tC5T+ZctW0avXr1CdnpmKN8fhP49yv2VfqF+j4G6P6vVyv79+4mPj6dixYq6Xccbe6XnUF2poTj3l5qayrFjx6hbty5ms9ljX6VKlXwKjkJiWG3s2LFMnjy5wGN2797N0qVLSUtLY9y4cT6fOyIigoiICI/tYWFhuv3i6XnukiDU7w9C/x7l/kq/UL9Hve/ParViMBgoW7asJjku/rDZbIBaryfQ1w6E4txfREQEBoMBg8Hg8f335+chJIKjxx9/nMTExAKPqVevHsuXL2ft2rUewU7btm257bbbmDFjho6tFEIIEWpCseemNNPq+xESwVF8fDzx8fGFHvfuu+/y0ksvOZ4fO3aM3r178+2339KuXTs9myiEEEKIUiIkgiNf1apVy+152bJlAahfv36hi9AJIYQQ4tIQeoOVQgghhBDFcEkHR3Xq1EFRlHxnqgkhhJ6S086RlpUZ7GaIS4jVaqVDhw4MGjTIbXtKSgo1a9Zk/PjxQWpZyXJJB0dCiNJv0b8beOKXjx0zXFzZbDbWHPoHi5cqu0dSznLV1EGM+fkDXdv29JLPvLbtTEYaPef2otNXfXW7vhB5mUwmpk+fzi+//MLXX3/t2P7QQw9RoUIFnnvuuSC2ruS4pHKOhBCBkZaVyV9J/9Kjfku3qbhnMtL4+O8fubttfyqXLZfv6y1WK1M3LaVfo3bUKFeBMxlpVIyOcTum18x7ybSmk2LYBkDlPyvyZOebuZCVxZQ/v2VIi2t4duVH7M5YyLWV7+eNPve5vf6JpW+RadrLspN7gQc82jBl9VwyLRd5tvvtALzy+zcAPNN1qE9fg4s52Yz96y4ArtzZjHY1m1A9trzj67Hiv20YjFnYjFmcSk8lvmzR66btPX2cmuUqEhkWXuRziOJTFIXMHP2X87DZbGRmWzFnWzAajUSFmfyapdWoUSMmTZrEQw89xDXXXMPff//N7NmzWb9+PeHh8jMEEhwJIXTQf/a9nGMzQ46OY3y3YY7t9y2axO6Mhcw+9CovXfk51zfzPkv06WWfsvTEh3y6vS5Nyl3BlrTv6VLxLj4c8BgA5zLSSbatAZe/BxuTt2GzDea6b+/jtLKe7w9Pcez77ej3LNvbnlk7FvNm74f5bMNidmbMd+y32WxuQdyFrCy+3K9Wxr8huROVomP55uArAFzXuD0tq9TJ9973nj7Ol1uWcHurax3b3t30Cec2baZFmcHMummietzZI479O04eonvZFm7n+XH331SIjuG9v2cxofMomldxn1Bit3L/Dh5aPRSssTzW8jlGtL3W63FCf5k5Vpo9uyTg1931Qm+iw/37c/7QQw/xww8/cMcdd7B9+3aeffZZWrVqpVMLSx8JjoQQmjvHZgBmH3qV8TiDo91pv4FJfTxh/d0s2ncn7au35q4rerm9/rejc8EMWaYDbE0/gMEAq89OBdTg6HRGmsc1bdh4aumnnFbWe+yzmk8wZs0dANy18Bz/Zf3itr/VzFbcXOtpxnW6FYD950449t22+GZqRDiDuNuWDACgbngvpl3/PBWjYziTkUb5yDIs+ncjz/w9AoD5R9/w+Hpsv/A9MBGL1cqsg86yIg+vHsbgg0/yZMdbmbT6GxYcmoZidi5/cP+SJFYNV+uw2Ww2LDYbnb68GQtZhBui1QQJUypv7XycBhVn06XuZR5fAyFcGQwGPvroI5o2bUqLFi0YO3ZssJtUokhwJITQ1LSNyzy2nc+8wPnMCxiVaGxccGxfe+5L1p77kjtab8FsMvHJ34vJyMnyeL2rSau+5esDL3ls352xkN0Zhbcvb2BkNydpMuNQg6Nvd/7q3GG6yBHL7x7HH8hexk1zz3FHs6G8tfPxwi/sYsE/6zy2fX94Ct/Pzu3tyvPOfI5NXDfrUQ7l/ObSLvW/vEtpPrDiLrbX/duv9ghtRIWZ2PVCb92vY7PZSEtNIyY2xjGsVhRTp04lOjqaAwcOcOTIEerUqaNtQ0sxCY6EEJrJtlh4c8cYt23vrlnAZ3snqE/yece5fPo1RBoqkmnaW+BxgNfASCupF9XoavGJ9306/rSygbd2bvD7OhM33Ov3a9wCo4KYZPZbsBgMBr+Ht4rCZrNhCTcRHW4u8vIha9as4a233mLp0qW89NJLjBw5kl9//VUqfueS2WpCCM0kp5/z2OYIjAqgmM86A6MCfLttdZHa5av+c+/GZtN3Le731i7Q9fyKYvA6O08Iu4yMDBITE7nvvvvo3r07X3zxBX///Tcff/xxsJtWYkhwJITQzIn0FF3P/+WOuZqeL8Ja1+35BeM/nLXo2/Py2a7XPbYZrPnP3POZNVo9l0Eh22Yp/vlEyBo3bhyKojBp0iRArfn3+uuv89RTT3Hw4MHgNq6EkOBICKGZ5DTPniMtRZqiPLZFWRtSK6y7+sQa47HfVVlbUwBMlgSeavkO393wmccxx7NTHY8rcDkPNp1MrNKcBhF9Pc7jKrH+RCa2/YQIa2237Y9e5h4MRRkTMFuqOp63ibmVKENCge32JtJan5eu/NzRllFNnnHsy5GeI5GP33//nQ8++IBp06YRHR3t2H7vvffSoUMHRo4ciaLo23taGkjOkRBCMylZ6Y7HRkslbObTAERY65BlOuj1NR3KD2fNuRmO550rjMidmebJptiIsNYly3TAse3vEfOwWK3M3LKcK6o3dMwmK6e0JMWwjShrfTJN/wHwSd/XSChTjiox5QG8Vqc+mHUaTGC2VOH3kWq77r2qHwCP/lyblcfm8VavFxn1651gyqBZ9PVkWjJ46OrrCTebGXzZTxw8e5KEmHJEh0WQbbHw0Tbn/cdH1CQpU5291q/Kw7zccwSJ819ia7r7sGKUtQGZpn1evw41zF1ZdMe7GI1GejWcyc4Th6lXoTKf5Z7CYpPgSHjXtWtXLBbvPYtLlgS+DEFJJcGREEIzOVb1TddsqcLaOxfx8frF9G/UjoaVqpJtsTBg9sPUL9eQx9oPYc+Zo8RFlqFj7aa0mKEGIYotjNFX3sjqJe7BUdvYoWxI/YaL1gyMLh3eQ2qPU69nMjnKAVxV7jbOXDzDdze9yrmLFygfWYZHf36P9JwLHvWJYiI8e6LOWFPABOFGz16ot/s+gL1g5PYRnjPO7OpUcPYEhZvN/J24gJELJrEh9RsUbGBQg5dOtVphNpl4v98TvLyqCuHGMBYnfUuvGoNpkdCAT7dOJd16Aos52XG+y2OGMGOQc4mH6LAIrqzRgJSLzql6WZa8c9iEEP6Q4EgIoZkcR66LiciwcB7tcINjX7jZzJLbP3Q8b1jJObSk2CIwGLOIVKrRskodbqs7gVl7P0Axq8N0ZcPLApBlvYgN9RqjGr7Ewx2u92jDFzc467XYq3Dbi0d607FCIsfTj/HfxeUYjBasqIGLgaJNj/bGaDRiNKjnsyk2NUDK3Q4QF1WGKb3VGWwvM8LxujvaXMPOE4e5/adRWMxHAdwCI1cRJufbufQcCVE8knMkhNCM/Y+yweDfW8tbnT6nirEj7/dUCyeO7XIr97XIDXKsUZiMamChYHUEFqYiTmHO6+MBj7Ng6BvYy23bFPUejBq/Pdrba1NsgJrTYTYWHoBdVrkmf965gE4V7mJK+xn5HhfuEhxJzpEQxSM9R0IIzdinkPsbWPRq2JpeDd2nEd/btg+xEdFcXaMJH67/AbD3uvgeWPhHbbMlN/jyN8ArjMml58geHJl8vEZ0WAQfDRhT4DFGoxFFMWAwKC49eEKIopDgSAihGUfPkQZDUkajkdtadVMf5wYRCgqKogYvWgdHBsW958igcc+R/R5sWHEERxr1fjkZAAWL1abxeYW4tMiwmhBCM5bcHgutAwt7D4saGOXm62jcs2N/O7Tq3HOkFKHnyGeKer4cyTkSolgkOBJCaMaiFC3nqDDOniNnMrP2w2qG3Gvo03Nkdsk5Ugza5k05qefLzmeqthDCNxIcCSE0Yx9WM2o40wtc8nXUgTVAv+DIPltN64Rsx2w1XBKyDdpmNtgDOosiwZEQxSHBkRBCM1bHbDWNgyN7D4vLsJpJp4Rsm07Ddo5hNZfgyGTUeJHP3Lwpma0mRPFIcCSE0Ix9lpQRbf/oO5OZbZpP5bcz2Kfyo8/QoL29iuKakK3TjDvJORJeKIpCz5496d27t8e+Dz/8kLi4OI4cORKElpU8EhwJITRjtdmTmbUeVnPmHGGwD0lpHFgorrPJdKhz5DI0aL8HzXuOJDgSBTAYDEybNo1169bxySefOLYfOHCAp556ivfee48aNWoEsYUlhwRHQgjN2HNdtC+gaJ/ppTgTsk06J2Rr3HMUlluk0bXnKMyoT86RDKuJ/NSsWZN33nmHJ554ggMHDqAoCiNHjuTaa6/ljjvuCHbzSgypcySE0IxVsefr6NNzpOYb6VTnCCMKLjlHOpUjsGHFYNCpHEFu75dVkeAoKBQFcjIKP664bDb1OtkmMBohLBoMvvdCDh8+nB9++IERI0YwaNAgduzYwc6dO3VscOkjwZEQQjOW3IVntQ+OXGd65eYcaV7nSN+eI2fvl7NAo1nzvCk1wMu2ymy1oMjJgFeq6X4ZIxDnuuGZYxBexq9zfPrpp1x22WWsWrWK77//nvj4eA1bWPrJsJoQQjNWRZ+p/Eaja8+RPlP57UNSNp16dZwBntVlm06FLCXnSBQiISGBe++9l6ZNm3LDDTcEuzkljvQcCSE0Y1PsCdnaJhqbHQvPOpOZwzTOOTLk6TnSOjhy3oOzV0fr2WrOGXeKpucVPgqLVntxdGaz2UhNSyM2Jkb94BAWXaTzmM1mzGYJA7yRr4oQQjM2Rf2jbNB8Kn9u4JJbXdqAfr0uik45R/aAUXEJXMJM+nTe22yytlpQGAx+D28Vic0GYVb1WppXWRcgw2pCCA3ZAwutgyO3niO9ErId5QJ0WgIFZ4BnZ9K6HIG950iRniMhikOCIyGEZux/k7UeVnObrWavc2TSuuM7N3gxWHOvqXXwpf5vDyBBj4RsewAmwZEQxSHBkRBCQ/Y/yloHR649R/YaQfokZOuVc2TM0zMFronmWrH3HMmwmijcxIkT2bJlS7CbUSJJcCSE0Iw9n0brus8ml9lqBseK9tpexTEUaLAPq2l8fsf5nIGL1knlznIE0nMkRHFIcCSE0Ix9OEe/2WrOXhe9qkvrl5Dtfn7QYQmU3ODIKj1HQhSLBEdCCM0oOg2rOYeknD0imvfsONqsz4w7k729Bh1zjgyScySEFiQ4EkJoxpGQrfVsNfvwk8ElX0fzwbvct0ODvVaTtmfP2zMF+uUcSc+REMUjwZEQQjN65boYvOTSaF5A0REM2a+hdUK2/ZEa4CmK1sGds79Oeo6EKB4JjoQQmlEUfZbeMBrch7xA+2E18g6raXx659dEn6HH3Ku4XUEIUTQSHAkhNKPolK+TNx8IXHtitKX7PRj0C44c8+GkQrYQxSLBkRBCM/pPIXfJ19ErIdugU3CUd/kQXb5UuYvnSt+REMUiwZEQQjPOCtmBGFbTJ5lZt0KWLrWa9Di/K+k5EqJ4JDgSQmhIrz/KXobVdB66068IpH69Ot4S14UQ/pPgSAihGb2m8huN9nXPFI9t2tNnWM0YkJwjWT5EhJaVK1diMBg4f/48ANOnTycuLk7360pwJITQTCATsk0aD6t55BxpXecoAD1HjuVDZCq/EMUiwZEQQjOKTkNSQZnKr1OVb4NBv5wj+9dEErKFKB4JjoQQmtGrx8Jbr4vWs9Uw6Jtz5JkjpcewoAyrBZOiKGTkZATkX6Yl0/HYn9+7U6dOUaVKFV555RXHtjVr1hAeHs5vv/1W4Gu3bt1K9+7diYmJITY2liuuuIINGzYAzuGun376icaNGxMdHc1NN91ERkYGM2bMoE6dOpQvX56HH34Yq9VZ6X7mzJm0bduWmJgYqlSpwrBhwzh58qSfX3ntabtyoxDikqZXz5GDa86Rbp/tdBoa1C1HypMMqwVHpiWTdrPaBfy664atIzos2qdj4+PjmTp1KjfccAPXXnstjRs35o477uDBBx+kR48eBb72tttuo02bNnz00UeYTCa2bNlCWFiYY39GRgbvvvsus2fPJi0tjUGDBnHjjTcSFxfH4sWL2b9/P4MHD6Zjx47ceuutAOTk5PDiiy/SuHFjTp48yZgxY7jrrrv45ptviv4F0YAER0IIzdiDI60DF6OXnCOtZ/I7QhedEqa1zpHyxr5+m6ytJgrSr18/Ro0axW233Ubbtm0pU6YMr776aqGvS0pK4sknn6RJkyYANGzY0G1/Tk4OH330EfXr1wfgpptuYubMmZw4cYKyZcvSrFkzunfvzooVKxzB0YgRIxyvr1evHu+++y5XXnkl6enpxMbGanXLfpPgSAihGcU5XU1TXofVNB+W0nf5kLw9UVr3TOl1TuG7KHMU64at0/06NpuNtLQ0YmJiMBqNRJmj/D7H66+/TvPmzZkzZw4bN24kIiKi0NeMGTOGu+++m5kzZ9KzZ09uvvlmRyAEEB0d7fa8cuXK1KlTh7Jly7ptcx0227hxIxMnTmTr1q2cO3fOUaPryJEjVKtWze/70orkHAkhNKd9MrN6PoPLsJpZ64Vn7f87KmTrVcgylw4jXzKVP7gMBgPRYdEB+RdljnI8Lsow9n///cexY8ew2WwcPHjQp9dMnDiRnTt30r9/f5YvX06zZs344YcfHPtdh9jsXw9v2+wB0IULF+jduzexsbF8/fXXrF+/3nG+nJwcv+9JS9JzJITQjL3nSK+lN1xpnpCdt2dH64VnjXmDLf0SsiXnSBQkOzub22+/nVtvvZXGjRtz9913s337dhISEgp9baNGjWjUqBGPPfYYQ4cOZdq0adx4441Fasc///zDmTNnmDRpEjVr1gRwJHgHm/QcCSE0o3+dIyfPYEPbawTiHrTmmMovwZEowPjx40lJSeHdd9/l6aefplGjRm65P95kZmby4IMPsnLlSg4dOsSff/7J+vXradq0aZHbUatWLcLDw3nvvffYv38/Cxcu5MUXXyzy+bQkwZEQQjOKTvk62vcSeaHzNTzvQabyi8BbuXIlb7/9NjNnziQ2Nhaj0cjMmTNZvXo1H330Ub6vM5lMnDlzhjvvvJNGjRpxyy230LdvX55//vkityU+Pp7p06czZ84cmjVrxqRJk3j99deLfD4tybCaEEIziuOPsr6fuxQlcL0wWgnMbDWVrK0m8tOtWzePfJ46deqQkpJS4OvCw8MLnF6fmJhIYmKi27aJEycyceJEt23Tp093ez506FCGDh3qts1qtZKamupor+swsbfr6EF6joQQmtN7ppcedB9WC0DPkT2JXHqOhCgeCY6EEJrRK+fIc5FZ/YaknM/0WgLF+/U0YbAnZGt/ahH6LrvsMsqWLev139dffx3s5gWUDKsJIbSjqMsCtD/8BST1gVr5VAv+8RFIOwFDvgYfpuR7Bip69LroS7eq4a7XsOccIT1Hwn+LFy/Odwp95cqVA9ya4JLgSAihmWjLeQCMKDD1WhgyC5r0dz9IUWDjdPXxgVVQv3uh5w1kjSDHc91zjmQqfygIpa917dq1g92EYtPq+yHDakIIzRgUi/uG2cPgYgqc+c+5zXLR+TjliG/n9Xir8jGw2LMEfrgPstJ9uor7s1I4lT/3f5nKrz97ccOMjIwgt0S4ys7OBtTZdcUhPUdCCM0Ycodz3MKASbXU/2+fBw16QE6mc58tTzCVD8+cIx/NukX9v1wNaNATzh2AVkO8Hmow4NYjlW/PUc5FmHmDurjbHfPBHO5TU4qUN2XNgaOboFobn67jDCJlWE1vJpOJuLg4x1IY0dFFq1RdFDabjezsbC5evKh5va+SoKj3Z7PZOHXqFNHR0ZjNxQtvJDgSQmjGoNjAkM+f/QUPwDUT4LDL2lOWrPxPtvZDqNQQGvYCj9lXBfwRstkg7xvq+SR1mA8goRlUbak+vnBa7V267EaPc8ZdOAin98Gfb0O9brDnF/WYnT+ALTcv4/0r4J7fIbqCZztyLsL+FVCnE0TEeAyree1J2rsMYqpAlRbq85Wvwuo34Kp7od9r+d/zvz/D1tlEKNlgkNAoUKpUqQLgtlZYICiKQmZmJlFRUQELyAKpOPdnNBqpVatWsb8uEhwJITSjKNbcP85e3lrSjqsBkqtfnoaIGGhzm/v2Q2thyTj18bA5VFj7Qf4XzTwHEbFqYveeJTB3BFw5Ero94zwmK835eO0HcP0HkHEa3misbju+xSNYaXr4W3j/C/XJ5pner30+CV6rCyN/hZpXuu/7dSKs+wga9YVhs/Nfq+3QWihfB7JS4eub1G0Tc2vOrH5D/f/vTwoOjr5Re8MSqrfmWDiOtauEvgwGA1WrViUhISGga4Hl5OSwatUqunTp4rF2WSgozv2Fh4dr0psmwZEQQjP2YbXMiErAWd9etOB+aDoAImPVYOPCKZg/2rl/1s1EmU1Qs7rLi3Lf/M7uh/fagtEMD210DqP9+Y7a62OXfsL5eNts9Z+rvz+DeoPz3IsfvuipBkH1ukK70eoY3brcasN7foaUo96HBpPWwbQ+avtvmubc7q33y5UlGy6eh5TD6vBerirZhyG8jBSBDDCTyVTsHBd/r2exWIiMjAzJ4Kgk3F/IDFYePHiQkSNHUrduXaKioqhfvz7PPfecIzkrr3379hETE0NcXFxgGypEKMsd/rIawuHGT3x/XcZpNb/mky7w2TVw7qDbboO3v/UpR2HmILV8gDUL3m7uvv/fRc7HBQ3fqQ2n9sV/3a/pc+Nz7fkZfhkLPz4Mix533/dWM8pteM9tk1FRYNMM9YnNkjtslyvLS7XiTV+CTS2VwIIH4PWG6tfq024ebZYikEIUT8gER//88w82m41PPvmEnTt38tZbb/Hxxx/zzDPPeBybk5PD0KFD6dy5cxBaKkTosvccYTCqic/dJ0B8k8Jf+G4bSN6mDpF5Pa+X5281UxOsfXFie6GHxOccK/CaPtv0Jaz/3GNzzHb3obkKnIctLoX1XB97+zosfAheqAA75sH277xe2rF8iMxWE6JY/BpW2717N7Nnz2b16tUcOnSIjIwM4uPjadOmDb1792bw4MFERETo1dYC9enThz59+jie16tXj3///ZePPvrIYyG7CRMm0KRJE3r06MGaNWsC3VQhQpfiEhwBdH1S/TexXOGv/ewany8TnrdkgA60TnPNez5zQWnTh9erydnezL2r0GvIsJoQxeNTcLRp0yaeeuop/vjjDzp27Ei7du248cYbiYqK4uzZs+zYsYPx48fz0EMP8dRTT/Hoo48GLUhylZKSQoUK7rNIli9fzpw5c9iyZQvz5s0r9BxZWVlkZTm75O2L4eXk5GiegGc/XyAT+wIp1O8PQv8eC72/3ArZYHI7xlTzaoyH/yrydfMGFhFo//XVvUJ23ucFxS8/3FOkaxhzz2m1WvP9Hl3yP6MhINTvUa/78+d8PgVHgwcP5sknn2Tu3LkF5uisXbuWd955hzfeeMPrcFYg7du3j/fee8+t1+jMmTMkJiby1VdfERsb69N5Xn31VZ5//nmP7UuXLiU6Olqz9rpatiyfT4whItTvD0L/HvO7v5ycLAiDi1nZLF682Lmj4mhiygzkYlg5+m1/wOtrC+I5rFb0npEd1YdSLiMJo5JDamQNmibPy/caexP60vDkz27bc0zRhFnVwn9JFTpT6+zqAq93vFwbqqZsDsACKM6vy7kTR9y//l5cqj+joSTU71Hr+/OnYKdPwdGePXt8yhhv37497du31zTaGzt2LJMnTy7wmN27d9OkiTOv4ejRo/Tp04ebb76ZUaNGObaPGjWKYcOG0aVLF5+vP27cOMaMGeN4npqaSs2aNbn22mt9DrB8lZOTw7Jly+jVq1dIzkAI9fuD0L/Hwu5v7gx1yn1EVBn69evn/SS5wZESXRFDxpl8r2UZPAOlaisIL4tlWi/A6tiXN7CwdngM4+75cO5goYFT40RnYnTC8S0wNb/gCOr2eQDLxTswfzdMbdOQ7yCuFtZt32Brdz9VoyuifNYNw8kdWDs8imnN2+73cNcyKlVqCFPqFCug88bWcghGl1l3lsRfsC4aDkCV8hH5fv0v9Z/RUBDq96jX/dlHfnzhU3Dk2rikpCQqV67sMWxms9k4cuQItWrV0vRmHn/8cRITEws8pl69eo7Hx44do3v37nTo0IFPP/3U7bjly5ezcOFCR2+SoijYbDbMZjOffvopI0aM8Dh3RESE1yHCsLAw3X4o9Tx3SRDq9wel/B4zzsLBP6BRn3yrMud/f7kVsg2mQu/f0LC3mni8J7dnpnZHMEfAf8sBMIdHQKW6AGRdNhSOfuV4bd6ZJKZ6neHaieq6bX++A78+59zZ5Dp1e+7sNbd2RTlzofIOcxkUMMc3VIsy5tYdcrxhVnkBx8TtITPhfBKmul1h5zxISVJzrp7Yh7lMRfWYdqMxrHd/P3ILlto/CGUrq0np2+fk8xVzZ6zTSV2KZdd8MEVgrtNenSUImG1ZhGWnQHTF3NLfnkr1z6gPQv3+IPTvUev78+dcftc5qlOnDk2bNmXhwoXUr1/fsf3UqVPUrVsXq9VawKv9Fx8fT3x8vE/HHj16lO7du3PFFVcwbdo0j0JQa9eudWvfggULmDx5MmvWrKF69ep5TyfEpWnmDXB8K3QbB93G+vVSQ25CtuKxyKqLmlfD4b/g8jvAHKn+ge/xP6h+hbr/uzsheYdaldouPMr9OnnPWb5O7g4DdHoUOjykJoef2KnOlks7Bkc3Qvs8Q3rhzqHxvD07BlADo8JUqKf+A3h0mxqs1LgS7IERQN/JZITHwZFZnvdw1y9Qu736eL6XIUdzFHR7Wi0qadf/DWg1FC67QQ2qWubWd8IIKJS/sA+m1FeDrt4vq7vST8HZ/6DqFYXfkxCXuCIVgWzatClXXXUV3333HT169HBsD+b00aNHj9KtWzdq167N66+/zqlTpxz77CXemzZt6vaaDRs2YDQaad48T30UIS5lx7eq/2/7Lt/gyHBsM5zaCZffqVamdsh9DzAU8NZy61dqocfKzdTnd85333/Llx5FEA1m9+DI4b41kJYMFeu7bzeaABNUa60+r1APHv/HsxclvEy+zTxdvk3+95AfgyF3KRIvu0zuvXAGgLFJEOkyk8+1py6qvNqzdt+fUDZBLXjZuL9aaDIs9+thinGvnJ27QFyV1G3q87XvQ2w1uOoe+LgTpCdjuO0H/+9LiEuM38GRwWDgww8/5Ouvv6Z///689tprPPzww459wbJs2TL27dvHvn37qFGjhts+qfkhRBEY8397MP30MJzarS7L0fFhx/ayVnt9ngJ6jsrGq/8KvHaedcjC8vQc2X+lK1+m/vOFt/enMGdwlHevzejbgrK+Mprch+cNoPYKuargTBHg4S3q2m/2wG+gexFJbxSMgA2b680seUb9Z7/unl+Ajn60XIhLj99FIO2BxmOPPcYPP/zAs88+y6hRo/KtRB0oiYmJKIri9V9Brzl//nzgGilESXN8G6x4BbK9zOIoIDgynNqtPlj2P/j1eXX4at9vRFvVhEfFqPFSCmYvw2r+VODO97zOAMgjdDJqm8thyJO/ZVAAU55rXDkKWt+m9p5FxUGlBv5dI3c4s6CPg4acC84nlmw4sArWvAcfXA2px/26nhChqlhrq/Xt25c1a9YwcOBA/v77b63aJIQIlE9yq8RvmQVt74LOLsteeAtw0o5jtOX5IPTHm+o/QIlX82y8rjhfDIYw97IZVnIrcGuh4yNw9gDp53YBznvLCYvR5vy58vYc2QxGz96ssEi44cPiXKXwQ84dBHv5t9+eV4fe7H57AW78qBjXFyI0+B0cde3alfBw5yegZs2asW7dOgYNGiTDV0KURL9OVHN8Br7v/GNsyXbvGUo5rP5hjHIpmmo0qWt5/bNI7eHYMJWwvUu5KqZFvpdScs9vVLSdmKGERebZomHw1esF9Ywfuycq54SX1+4aAHmCo5MG3yaa+EcNjmwFfH0MWbnTmRWbe2AEcGwz7Pgemt1Y8MK3QoQ4v4OjFStWeGyrWLEiv//+uyYNEkJoKCcT/nhLfdxpjJq/kn1BXck+vrHn8T896nx8bDPMvBEOuP9uV04rfJ0ys8bBkWdCtvZ/uE15liTJidA2ODK6lA0AyEHbnCZwzhIs8GNq5nnKXjyOacF9nvtO7Ya5I+Bmk7oY7pr34ObpUKGu57FLxkP6CbjxUwmkRMjxOTjytXiS1oURhRB+WDkZNkyFe39Xp6GnHHXuO7oR1n8BJ3aoU9vTjuV/HrsD/n3osa8Wpvm6ZGH5zFbTUJgtG9e3xOzISpqeX6ncUtPzeWPM7b13S8huch3885PjqSEliR4pTxd8okNr4O/cnK4fH4GmA6BRb4irpW5TFGevU7vRUKOtRncgRMngc3AUFxdX4Gw0RVEwGAya1zkSQvhh5Svq/280hgmnwLUC9bxR3l9THBHlICvF8dTeY5ES00jTy3jmHGmc8A2khcUD5xzPbSZtlwcyRrjnMOkxt7eMNQW3t/X+b8Chtf6f6G+XZPcDv6v/Fj/hfl67lCPO4CjliJrg3240VC0kGPz3Z3UYt1Y7/9snhM58Do5ch9MURaFfv358/vnnUjxRiJLi8Hr35+eTwHVmkh66j4NfcmshXXUPu5P/A/aSHlO/wJf5LU/PUSba9yQdLnMZWP5wPNe6NInZY+hJ+/DIbLMAZrUH7/51kNAEMs9rfh0WuSTuH9+qFqMEmHMXHPkbdv8I4w7n//pzh+Cb3IT6iSn5HydEkPgcHHXt2tXtuclk4uqrr3ZbukMIoTNFgeTtaj2ciLLqNpsVVrwMq99wP/b9AFRCbjUU1rwPdbtAvylkTr8dAIPGOUHGPMGRpXgTbb2yGDyXCdKSZ7ClfXC0L64j2DZyOKa1GhiBWhXcchEa94PPumt+Tf54U611tfgpNTACyCokDSPNpWRAdoZbpXIhSgLt32GEEPrZ9yt8fRNUaQGjVoLJDC9UKPRlfnv6kDrN/3wS6h/xfFJ8o+Lg0e2OhFwl9zhTQcuHFEHepYC0LhXg9Zoa30MgiuSmhleBi3CkrEvV/7AouGaCvheeO8KxJp7DgVVQpzOs/xz2r8yttm6A/SugamvncTvmqpXWhShBJDgSoqTKuaguxOr6R/Xrm9T/k7fDa/Vg8GfaXzcsWg16HtqsLqBqNMKFMxBZjpz0M4S9lSefyCVwsQdHwayWX1R526z1HZgNefOktP8a2QM6W34H3P49fDWYM2UaUvHCXi/758FXg/y/cN7ACGDGALh8OGyaoT7/5yf1ZysnA8rVdB638CH34CjlKETGgjUHonMD/+Qd6oy5ApZ7EUJLxQqOSuMboBClQvIOmNYPmg2E63NnBeWtYp2VArNu8XytP7o9A7FV1WnZQ2apU7Mr5QY/Jpe3B/siqtEF91LZgyPte13ynk/7qeN5e6O0fn/Lewt6vH/a70HJr6evQU9yxh7jj1+WMSBnAcad89z3178GqrVRyzh4U64WpCT53iB7YGSXk/sznJInH2ndJ9B2BKSfhLeaObe3vBW2fas+rnEl3P2r79cWohh8Do4GDXL/NHHx4kVGjx5NmTLukfy8eXl+2YQQ/vt9shr8bJ7pDI52FmPB0CvuUv+35UDl5mDJggY91UDIHA6tb/e5Vs2uqjfR7PhcdTHTvBQbGMCkcd0bY97ARYdeF4/gSOu8qbxt1qNmbu4lCizIawoHgwFr79c8gyODAUatgDXvqj8neXuRWg9TS0VcOAlDZ8OmmfDvouK3++en1JpceXuG7IERwJH1sHISNO4LVVsV/5pCFMDn4Cg2Ntbtk87tt9+uS4OEELgv3bH2A3WF9gX3F/66pgNh90LP7VVbqcuD5Hs93wOBvZUH0PC6hwmr2txjn149R0Zj3mBI/6KDWnfseHxNdOg5MuZ+XXxarSAqDup2dday6vWis10dH1EfP7xZnQTw3uXqc8UK961RZ6g16AHVLtcmOAK1MnfjvgUfs/JVNUCaeF6bawqRD5+Do+nTp+vYDCEEoP4hyslw7yVyWVG9QL1ehA4Pwb7f4OvBec6rYf0xgwESmnlde03JzXbRPDgKRM9RnjZ79PQUU96p/HokJdi/Lrb8s47c3blAne1oyudPQYXc2ciVGsHpPdDseigbDw17qtujKxazxS5sFji734cDZZkqoT+fg6NatWoxcOBArr/+erp3747ZLLncQhTb+cNq8BNdATZOV7c1v8n/8/R+Fdrn9izV7uC532P5DX04ErI1Pm8gpsEXfs3iyTvjTo978MzNKvQF+QdGru75Xc1Hy7uMiMkMt8xUF7NtNxq+udV7crYvTu5S/wlRAvgc4cycOZOFCxdy//33c+rUKXr37s3AgQPp378/cXFxOjZRiBD289OewxI75vr22uhK6hRty0W42mWdrPBoeGKf2rOzcbo6bNJ8cL6n0ZZ9WE3bCtYeM8k07pkCb71RegdgegRH6v+K4mPPka/Co72vrwbqpAG72+ep+UPbvoOL57Vtg6uts9WZb67XFkJDfhWB7Nq1K2+88QY7d+5k4cKFvPfee4wcOZIOHTowcOBABg4cKEUhhfDH2f+K9rrG/eDmGWoytTdlc1d87zxG/Rcg9lwXk9a9LgHoOcobHHles/gUxYDBoE/vmnrOQmar6c1ggH5T1H9HN8Jn16jb71yozoCLKJtbwDQWPu9R+PkSmkG5GrB3qfv2H+5V/292A1z7olqx+/xhuGcFUqFGaKFIH78uu+wyxo0bx19//cWBAwcYOnQov/32G82bN6d58+YsWqRRgp4QoSb1mLrW1bEtMLEcnPqnCCcxwNBv8g+MgshZ50jfhGl9co7yBkd63IMhn8dand29GGdQVbvc5YkCnR6FK+9WywXUaAu3fV/4OUb/Add/mP/+XfNhWn81eDq1W62ZJIQGih1iV61alVGjRjFq1CgyMjJYsmQJERH6luEXotR66zJ1unt8k6K9vt190KbkzhS1J2RrXiGbvMnM+uccaX0PgWAP8HyaraY312DT2897w55w72q1Erur+/9SC0CawtWh4UJqa7nVXdo+B/q9VfQ2C5GrWMGRoiisWLGCzMxMOnToQPny5bnxxhu1apsQpZuiqPWEwiLV579PUQMjKLzH6P6/1KGCQ3+qzyu3UGvMtPdhOn9Q5eYcaVznyDNO0SHnKG/Pkcb3AIBicOkw0qNCdpCH1fIa84+6zlpMFe/7q7ZUe4e2z1Grvl//oVqU1JXrrMhql8OxTQVf88Lp4rVZCPwIjs6fP88jjzzCpk2buPrqq3njjTfo168fa9asASAhIYGlS5fSsmVL3RorRKky61a1Hsyo3yD7Aqx4ybfXPbgRKjWAIV/D/t+hUR9ngFXCOddW0zjnKAhFIPXIOdI7yduRc6R1QnZRxVYFqhZ8TJUW6r+CDHxPLQLpQ3Bk3PUDzY/8BamtoGIdv5orhJ3PH42eeOIJ1q5dy5AhQ9i+fTt9+vTBarWydu1a1q1bR9OmTRk/fryebRWidNm7BNKT1SKOa97z/XWVGqj/R5WHy24oNYGRSv2jrHXOUd78n0AER3oPq+lxD/avUwnpN9LO5XeqAZIPa6uZlj9P/VNLCHuvFbxUBd5to+b6ndilfkgRwgc+9xz9/PPPzJo1i65du5KYmEjNmjVZvnw57dq1A2Dy5MkMHCjTKoUA1MJ6dn/lk1BatgrU6QiH//Zca6qUsv9R1rrXxfN8ARhW07gcQe5V8nms9flDLjxSNbsB5o1y3xYWDX0ne0/GtmSqhSXfbKo+vyIRBryjdytFCPD5HebEiRM0aqQuSFm9enUiIyOpWdO5snKtWrU4deqU9i0UojTK7xPqlXc7H7e/H26aCv3fdG67/y9926U7+7Ca1j1H+i4KC55J31oPDaoMXh5pePbck9pKyrCa1szhMHKZ+7bxx9WeJV/YC60KUQif38FsNhsmk/OTlMlkcnuD0uPNSohSxWbFkLQGkzULstO8H1O7o/NxWLT6f5lKzm0JTfVrXwDYc1306XVx0mVIKk8Cdmmcyq9Pm0uYmldBVCEz2IQoJr9mq33++eeULVsWAIvFwvTp06lUSX1jT0vL54+BEJeKvz7CvHQ83cMrYWjwmvdjmlznfGzM/fWr1kZdEy22hv5t1J1OCdke65JpHwR49BzpMFvNNajTs8p3iUnI1svN02H2bdD/dee2Gz+FH+4p/LU75qmFJWtepVvzROnn19pqn332meN5lSpVmDlzpscxQlyycpOuy2SfhnkjPPcP/kIdFihXU80xanitut1ggGt9nMlWwimO5UNKYzKze2+XPlP5nQ8lIbsY6nWFsUng+j1qdStcdgPW5a/C2vcxKTneXzv3LvX/pw4UXkNJXLJ8Do4OHjyoYzOECAHpyfnv6/yEuqI5wKjlak5SueqBaVdA5RaB1CGwcF16w0vho2LL22Z9Zqu55hzp2HNEiPccgXtgZGeOwNZ9PL+fq0LP3U8X/PqPO8Oj29zrKAmR6xIYoBZCRyf/Ubv39/7qfX/HR+G589Djf2AKU7eVTch/Ec9Szrl8SGDq+Wh7zkDkHOV/PS2VmCKQQXIhsiqWu5ZC71fyPyj1CKx+E7IkJUR48qnn6N133/X5hA8//HCRGyNEqTPjOrhwCv75yfv+hKbuyyiEPH1mq6kMjvPrERzl7TnKW3hSG/pOYrkkErJ9pFS7HBRLwQeteAn++RGaDlQ/yJhk0Vqh8ukn4a233NeqOXXqFBkZGcTFxQFq9ezo6GgSEhIkOBKXhv+Ww5xEuJjisWt3lUE0TZ6nPoksF9h2BZ2OOUeKEQz6FJkEzzbrknOk97Ca4RJJyPZVzaugSksoXwd2L1S3GcOg5S2w5Wv1+fGt6j9rDnQfF7SmipLFp9/OAwcOOP69/PLLtG7dmt27d3P27FnOnj3L7t27ufzyy3nxxRf1bq8QwbfoCZh5o9fACOBQpW7OJ+VCYQaa7xTde47sjwJR50jne9AxwLvUh9UcTGFw7yq4dSYM+gyqtoKHNkLtDp7H/j4J/lkU+DaKEsnv387//e9/vPfeezRu3NixrXHjxrz11ltMmDBB08YJUaIoCqz7BNZ/lu8h1h4TyTKXw1b9SqjcHOJLd90i/+mz8KzKeU49Z3rl91wb+gZ4zp4jCY4c7MOXLW9RA6XytaFCPe/Hzh4WuHaJEs3v3/7jx49jsXiO41qtVk6cOKFJo4QokVIOw89PFXiI7eoHwWDAOnwx3Lv60sthMOjXc2RQ9B2SMuWZtaTHjDtXeXuqtDznJTFbrTiqts5/n9UC5w4FrCmiZPL7t7NHjx7ce++9bNrkXBl548aN3HffffTs2VPTxglRIlhz4POe8O3t+R9TJkGtm2JnMHifahzy9Kxz5NJzpEMys8kQiOBI34Rse5tlWK0Q4dFw1y/e982/D95pCZu/CmybRIni92//1KlTqVKlCm3btiUiIoKIiAiuuuoqKleuzOeff65HG4UIrsPr4Mh6NWkzr5pXw7Pn4Ik9UlAOZ4+FPoGF67CaHvk67sGKLr1fOidkO3uOJDgqVI0rvW/f/p36/4oCygCIkOd3n398fDyLFy9m79697N69G4AmTZo4FqUVIuRYs/PfN+zbS7SHKD/2nqPSNw0+8D1HOgwN2hOyZbZa4Qob8k49Cqf2QLz8bbsUFTkhomHDhjRs2FDLtghR8mSlqTPT8hMVF7CmlCb69LoYHf0heuTr5G2zLrPVXDp09LgHR0K25Bz5ptcL8Oe7kHHa+/5FYyAxnxpmIqT59Ns5adIkMjMzfTrhunXrWLRIpkOKEJG7XppX964KXDtKDR2H1RSdp/LnXT5E76FBHYIvc25SucxW81HHR+Dxf9VaSN4cXA2n9wa2TaJE8Om3c9euXdSqVYv777+fn3/+mVOnTjn2WSwWtm3bxocffkiHDh249dZbiYmJ0a3BQgRUQW+MVVsFrh2lRqASsktpz5ELfReelZ4jn5nM6gedOp2973+/bWDbI0oEn377v/zyS3799VdycnIYNmwYVapUITw8nJiYGCIiImjTpg1Tp07lzjvv5J9//qFLly56t1uIwMhO9779wY2BbUepoeNUfp3rHHlO5dd+QVLXdusRQDqH1aTnyC8Gg7qEiBC5fM45atWqFZ999hmffPIJ27Zt49ChQ2RmZlKpUiVat25NpUqV9GynEMGRnk/trkoNAtuOUkIxKBjQZ0jKEOCeI32Syp3X0CM4MknPUdFdORLMEbBvGRjNsPOHYLdIBJHfCdlGo5HWrVvTunVrHZojRAlizfE+rNbuvsC3pdSw9xxp3+uCW6+LHkNSge050rOQpeQcFYHRBFcMV/8B7P4JbDnq49TjEFs1eG0TASdzkIXwxpINm2ZATob79qGzoe+k4LSpVLAvH6LD0hg61zky5+ntMuu+tpoe5QjsbZaeo2K7Z6Xz8dc3Ba0ZIjgusbUNhPDR8hfcZ6p1eAiueRbM4cFrU6mgZ50jfStk5x3m0uMabjlHuhSylCKQmikT73x8Ykfw2iGCQoIjIVwpCpw76DmF/9qXgtKc0id3WE2PISmX4EWXOkceCdl6B3gSHJVoETLr+lImwZEQdjaruobasU2FHyu8y114Vo8hKYPu1aXzLh+ib96UHueXYTUNhUW5P7fZpBr+JcTv7/S0adPIyMgo/EAhSpuz+yUwKjZ7z1Hpn8ofpndCtq4Lz0pwVGx5vz8ftoOci8Fpiwg4v9/Bxo4dS5UqVRg5ciRr1qzRo01CBMfFFO/bB74f2HaUYgaDfkUgDTpPgzfnCYbMha29VQSuAZEuOUcyW01bo/9wPj69B9YWUDFfhBS/fzuPHj3KjBkzOH36NN26daNJkyZMnjyZ5ORkPdonROCcO+h9e72uAW1GaWWzOXsr8s780oJB54TsvHWOwkx69BzpXedIikBqqkoL9+fHtgSlGSLw/P7tNJvN3HjjjSxYsIDDhw8zatQovv76a2rVqsXAgQNZsGCB25ukEKXGxum5D1z+8NZsB3G1gtGaUsfi8nuvy0wvvROy8+QAheswrOZeBFLPAE+CI820vt352BwZvHaIgCrWO0zlypXp1KkT7du3x2g0sn37doYPH079+vVZuXKlRk0UQmdZafBBO3WRSYBu42DAO9BqKCQuDm7bShGLYnU81qfnKDD5OnZmXXqO9E4qt7dZPqBqpuXNzsf5LSckQk6RfjtPnDjB66+/zmWXXUa3bt1ITU3lp59+4sCBAxw9epRbbrmF4cOHa91WIfTx18dw6h/n8+pXwBWJcOPH6qKUwieKy9/jvNWmteA2JKVLEcjAJmQb0WG2miRka8+a43y855fgtUMElN/vMAMGDKBmzZpMnz6dUaNGcfToUb755ht69uwJQJkyZXj88cc5fPiw5o0VQhfbvnV/nncKr/CJe8+RHsNqJpfH+tUIsgvXJTDWN+fI6AiOZFhNM6Yw9+epx4PTDhFQfv/2JyQk8Pvvv9O+fft8j4mPj+fAgQPFapgQAZF9Ac7kWT9NgqMicc011KOGj1HntdVch9EUxeAINLTkOhyoR7kDyTnSQZ0u0LA37F2iPn+zCQybA42uDW67hK78/u3s2rUrl19+ucf27OxsvvzyS0B9A6hdu3bxWyeE3hY86LktLDrw7QgBlkDOVtNjWM0toNOjOrb+C88aJTjSntEIt32nTs6wm3UzXDgTvDYJ3fn923nXXXeRkuJZDyYtLY277rpLk0YJETA753lui4oLeDNCgdVlWE2fXhedh6Rcz6noUwk5ULWaZFhNBzWvcn/+TsvgtEMEhN+/nYqieJ0pcuTIEcqVK6dJo4TQnaLAiV3u2/pMghs/gZgqwWlTKWexOf8gm3UZVtN3Grx7XSO9eo6c96DrsJpBErI117i/+3OZuRbSfM45atOmDQaDAYPBQI8ePTCbnS+1Wq0cOHCAPn366NJIITT3z0/w7e3u29rcLotNFoPNpedIh04RtecoN/7Sp4Ci6zl16jnSu0K2DKvpp9bVntusOZ4J2yIk+Bwc3XDDDQBs2bKF3r17U7ZsWce+8PBw6tSpw+DBgzVvoBC6+OE+z20SGBWLTe+eI4PJ8TdfjzpHrgnZBt2G1WRttVLLYIBHtsI7rZzbMs9D2figNUnox+fg6LnnngOgTp063HrrrURGSqVQUUqd3gvZae7buk8ITltCiFXROyHbdbaa3j1HARhW0yGAdNZmkp4jXZSvA1c/AH99oD7PPCvBUYjy+x1m+PDhEhiJ0u30Xs9tXZ8MfDtCjOtsNT0Sso0BSma2X00XrsNqeuQcGWVYTXc9nnU+zjgbvHYIXfn021mhQgVOnz4NQPny5alQoUK+/0qCrKwsWrdujcFgYMuWLV6P2bdvHzExMcTFxQW0baIEuJhntmXnJ4LTjhBjy+05UhSdel10XlstzK3oo/49R/rmHMmwmm7CItUq+qD2HImQ5NOw2ltvvUVMTIzjsR5j5Vp66qmnqFatGlu3bvW6Pycnh6FDh9K5c2fWrFkT4NaJoMrJhPmj3bc1vS44bQkxVkfPkT7vD0a3CtnaX8N1BpweNYjAvZClFIEsxaLKq///twKa9C/4WFEq+RQcua6TlpiYqFdbNPHzzz+zdOlSvv/+e37++Wevx0yYMIEmTZrQo0cPCY4uNQsecD6OLAft7oOqrYPWnFBisecc6dRz5Bq86DGs5jaVX6+EbNcZdzoEYI6EbIMER7o6skH9f/1n0OdVmbEWgvxePmTTpk2EhYXRokULABYsWMC0adNo1qwZEydOJDw8XPNG+urEiROMGjWK+fPnEx3tvcrx8uXLmTNnDlu2bGHePC8FAPPIysoiKyvL8Tw1NRVQe59ycnLye1mR2M+n9XlLipJwf+adPzg+u1s7PIKt/cNgsWh2/pJwj3oq6P6yc7JzHxl0uX/XGWQGRfuvsWJ1HYrS6R7cKmRrfw2DYg+KlHzPfSn/jGrFHFMFw8XzAFi2fIvS8lbdruWNfA+Ld15f+B0c3XvvvYwdO5YWLVqwf/9+br31VgYNGsScOXPIyMjg7bff9veUmlAUhcTEREaPHk3btm05ePCgxzFnzpwhMTGRr776itjYWJ/O++qrr/L88897bF+6dGm+AVhxLVu2TJfzlhTBur+4C/vpmtu7capsMzaerETW4sW6XOtS/B7uzziX+8jAYh2+rhfSL0DuXJDk5GTNr3E8y1nUT1HQ5R4yMy867uHokSOaX+Ngpv17oBR67kvxZ1QrsRVup/spdYar+ccHWHAkOGVA5Hvon4yMDJ+P9Ts42rNnD61btwZgzpw5dO3alVmzZvHnn38yZMgQzYOjsWPHMnny5AKP2b17N0uXLiUtLY1x48ble9yoUaMYNmwYXbp08fn648aNY8yYMY7nqamp1KxZk2uvvdbnAMtXOTk5LFu2jF69ehEWFnrdtEG9P5sV8wfqmoBKwmXEjfqdHjpc5lL+Hv59ZC9TVwEY6Nevn+bXnjZ3NadzO6eqV6tOv17aXmPfmeN8sGQSoOY36XEP732ziPTczp06tWrTr5u219iWfIjPl78B2PJt/6X8M6qpl53lP/r17es2E1Fv8j0sGvvIjy/8Do4URXGsvv3rr79y3XVqMmvNmjUdM9q09Pjjjxea51SvXj2WL1/O2rVriYiIcNvXtm1bbrvtNmbMmMHy5ctZuHAhr7/+utu9mM1mPv30U0aMGOFx7oiICI9zAoSFhen2Q6nnuUuCoNzfnhWQehQAQ+M+ul//UvweGhwJxgZd7t01IdtsMmt+jYhw5++5Qbd7cOYchZm1/xmJCMtNazAohZ77UvwZ1VT1tnBUzT0K++1Z6DtJv2vlQ76H/p/PV34HR23btuWll16iZ8+e/P7773z00UcAHDhwgMqVK/t7ukLFx8cTH194ka13332Xl156yfH82LFj9O7dm2+//ZZ27dTVlNeuXYvV6lziYMGCBUyePJk1a9ZQvXp1zdsuSpDdC52P7TNNhKbss9UMeiVkG/WdBu9auFKvhVv1XjzXbJLZagFz2xx4ra76eN1H0PERiK0a3DYJzfgdHL399tvcdtttzJ8/n/Hjx9OgQQMA5s6dS4cOHTRvoK9q1arl9ty+vEn9+vWpUaMGAE2bNnU7ZsOGDRiNRpo3bx6YRorg2PYdbJ7pfG4K3qSBUOaskK1TcORWXVqPGkHaV6zOy73Ktw7Lh+Teg0Fmq+kvuoL6XmLNHes9sVOCoxDid3DUsmVLtm/f7rF9ypQpmEz6v7kI4bd597g/D4sKTjtCnE3v4MglINJlbTWj/jkjrj1Heqw/51o7yWaz6VKFW7gYsQQ+664+Pvsf0DOozRHaKfJvTnZ2NkeOHCEpKYmkpCROnjzJ8ePHtWxbsdSpUwdFURzJ494kJiZy/vz5gLVJBIGi4DbEUL4uXDYoaM0JZfoXgdR7bTX9P9y5B3j6Dg1mW7UrUSHyUf1y6PKU+vjwuuC2RWiqSLPVRo4c6VE8UVEUDAaDW06PEEHnmNqc65EtQWnGpUDvYTXXYEKP6tLGQPQcuXxt3Ndy04br0KDVJkNrAVGpofr/ju9h8BcBnbUm9ON3cHTXXXdhNpv56aefqFq1aolfSkRc4lw/zQ2ZFbx2XAJsjgKE+ucc6dNz5NKrE4ChQT3yplyrfFsU+aAaEK4TPE7sgCotgtcWoRm/g6MtW7awceNGmjRpokd7hNCWfbmQBr1kDSSdOWar6bQumd4zvUyBmK3mmpCtQ++XOU/OkQiA+tc4H3/cCW6aCs0HB689QhN+/3Y2a9ZMl3pGQmjOZoOMM+rjM3uD25ZLgP4J2TrP9ApA8rL70KAOCdku57dIcBQYeb+Pc13q5cn3oNTy+91g8uTJPPXUU6xcuZIzZ86Qmprq9k+IoDr8N+ycrz7OueDcLm9SurPqvvCszjWCApGQ7VaOQN8AL8cmCdlBk50BKUfh9Yaw9H/Bbo0oAr+H1Xr2VKcq9ujhvviCJGSLEuGLXur/lTdAmMvad31eCU57LiE23Wer6ZuvYw5Iz5Hza6NLzpFRErKDomJD997pV6pCpcaQcRrWvAvXvhi8toki8Ts4WrFihR7tEKL4sl16itKSYfePzudNBwS+PZcYe89RIJKZ9eg5CkRNINdyAXqUDjC7BUfyQTVg7l4Gk+u4bzv9b1CaIrThd3DUtWtXPdohRPGlHnM+nnGd83F4cFbMvtQEsgikHsFRILj1HOlRjsDl/M7SCkJ3hS1JZMkGs1TmL02K9Nu5evVqbr/9djp06MDRo+pinjNnzuSPP/7QtHFC+CXZs3I7AB0eCmw7LlE2AjeVX48hqUBwK0egS60mI0puzpfkHJUglovBboHwk9+/nd9//z29e/cmKiqKTZs2kZWVBUBKSgqvvCJ5HSKI7DPT8rrshoA241Jls+k7rOba61Jal8XQe/mQ3KsAknNUoliygt0C4Se/32FeeuklPv74Yz777DPCwsIc2zt27MimTZs0bZwQfnHNObJrNxriGwe+LZcg5/Ih+gQu7sNqpbP4rFHnhGzAMVswR3KOSo6LKcFugfCT37+d//77L126dPHYXq5cOVmnTARX0l+e28LLBr4dlyhbABOyS+uwmmuBTLNuC3WrX39FkZ6jgLp5BtRsB3f84Lnv/SsgJzPwbRJF5vc7TJUqVdi3b5/H9j/++IN69epp0igh/JaTCXt+9rI9I/BtuURZdV4+xHV2lzEANYn0EJgAT/362yQhO7AuuwFGLoXK+SwfcmiN9+2iRPL7t3PUqFE88sgjrFu3DoPBwLFjx/j666954oknuO+++/RooxCFS0v2vj1LCpMGii13LS89VpuHvENSpX9YTe+8KZv0HAVHmUpQuxPU7eLec/3VIPh9SvDaJfzi91T+sWPHYrPZ6NGjBxkZGXTp0oWIiAieeOIJHnpIZgWJANo2BzZ/CanH818exFsektCFs0K2PucPhan8rj1eZh2WD8m9CgA2ScgODoMB7lqkPn61pvu+FS9B+/shvEzg2yX84ndwZDAYGD9+PE8++ST79u0jPT2dZs2aUbas5HaIALLZYN7d3ve1fxCMZlj3MXR5MrDtuoTZc1wMOvXqGHWuERQIgRhWs+d8WRVJyA66yHKevdcHVkPjPsFpj/CZ38ERqG+CqampVK5cmWbNmmndJiEK98+P+e+r1w0a9oLuz4A5ImBNutQ5c1wCMFut1AZHAQjwcjuMrLKeYPB5e//JSlOn9st7U4nm129ncnIyd955J+XLl6dy5cokJCRQvnx5RowYwYkTJ/RqoxCeTu/xvr3GlWpgBPLmE2D2hGyZrZY/YwDrHCl6jW8K33n7Hs+7G15KgInlIPNc4NskfOJzz1FqaiodOnQgPT2du+66iyZNmqAoCrt27eKbb77hjz/+YNOmTTK8JgIjK91zW3QluP7DwLdFAPovPGsKgZwj18BRv6FB+7Ca9BwFXXSFgvcveBCGfB2Ytgi/+BwcvfPOO5hMJnbu3El8fLzbvgkTJtCxY0feffddnnnmGc0bKYSHjdPcn3d+Anr8LzhtEYDrwrP6D6uFQs5RmKlIWQ0+sFfIluAo6Aa8Ax9clf/+49sC1xbhF5/fYRYtWsQzzzzjERgBJCQkMG7cOH78sYA8EFHybZgG34+Ci6lqwrP9zXXvrzDzRjh/OLjtc5W34mzt9sFph3BQdC4CaTK6rmhf+oMj/ap8SxHIEiO+MTx7Dhr0yn+/KJF8fofZs2cPHTp0yHd/hw4d+PfffzVplAiCnEz46VHY/h1MqgkvlIdPu6oB09eD4b/l8MtYSN4BGWcD376fHoOpfeDsAXjbpcjagHfh9u+hQc/At0m40bsIZECW3tCZayK5Sbep/DKsVqIYjXD7XOjwsOe+fctg0ROBb5MolM/vMKmpqcTFxeW7Py4ujtRUKbhX6liy4Mx/3nN4krepAZPdP4vg447wWl3YPhcunIGUo3B6H8wdCSd2Qc5F2Dob0k9p18aMs7BhKiSthXdbw/kk574rhktgVEI4i0Dqn5BdWmeruQZ1YRIcXVq6Pg0th3huX/9ZYJcWURTP6+2Yp37wFQ4+D3orilLgG5LBYJBu3NJEUWDGADi4Wn3ebZwvL3I+/H6k5+4jf0PzwfDHWxDfBIbOBpsVKjUoejst2fBpN+/7Lr+z6OcVmnP2G+mfkF1qe47c8qb0+ToZMKAgRSBLnIiyMOgTaHETfH2T+74Tu6DGFYFpx7xR8O8v8NAGiKmi1l2ae5e676FN6jInp/+FXi+qBS3tFAV2/wjVWkNcrcC0NYj8Co4aNWqU76dCCYxKmb1LnYERwMpXi3/O80mwa4H6+NQ/ai8PwJBZ0KR/0c655xc4f8j7vm6S/F+S2AKZkF1KgyO32Wo6T+WXtdVKqIa94Im98HpD57Yj6wMTHGWche1z1MdvNIa+r7kXqXzvcufjY1sgpir0eVVt3+m9sOx/gAEmnte/rUHmc3A0bdq0wg8SJV92Bliz4NCf2p+7XC04u99z++xh0LA33Pi5/+fM9jLcZ1fGc3KACB6bzgnZoTBbzfVro9uwmiJ1jkq8vO9dxzbpc53Mc2q+6H/LodUw+ONN9/0/P5X/a+0fnrd/l2dH7s+VzQqKDUxhmjW3JPE5OBo+fLie7RCBMuM6dfpolXxWji6OlKT89+1dguHfRUC09/2n96lvEM1ugA1fqHlElRrCqtfzP6duU6FFUTimjuvUqxMKdY5cAxZJyL6E5R2B2fatWjDyxo+0vc6sIXD4L/Xx5q+0O+/069Rc1bBIuH+dui0nA6LitLtGkJXOdxjhH5tVzd1JPwVHN4ItR79PKgUwbv6SMEu6mgQO6syz/5arj2dcp46Ff9xJnRX3fls4ugnO/hfwdoqi0bvnyLW3qLQOq7kKM+m8tprUOSrZej7v/nzrLG3Ou32uOoEFnIGR1g6uhrRj6kjBuYPw2TUwpUFwZjLrpPS/w4j8ZZyFXQvVKfnvXZ5/7k5Bbv3Ksyeg1VD1FzuqkOqveRiT1tB7xyOYZt+iBmvvtlbrJ53cDWnH1YNOu5SD+Kx7/icblrerVwSbY+FZnc5vdK1zVEqH1VzpnXMkeaAlXMdH4M4F7tuKO2vNZlMny/z0mBokBULmWTixXf3QfWhNYK4ZAKX/HUa4y0qHXyfC8a0w/z747g5I3g4ph+Hfn304gQGuya003eUpaDoAnvwPYqqp2y4bBL1fgU6PwtMHYJB/eUQmJQfjoT/h8Drnxg+v9uscPLQJGvX27zVCd3pXyDYZApHMHDhmnZcPkYTsEs5ggCot3bdlni/6+XYtUMud2HmbUVyQSo2Kdt3VLnlM1gJKw5QykrQRan6fBGveU6fT57W6gPwdgEGfqbk+UeWh1RCIra5uj64AY3Z5jpMDNB+kznZYNMZ9e9VWaoCWnxnXFdyWvG6eAZfdoH4yCoFeg1DkyKfRqc6RKQDT4APJbNInwDNIzlHpEVXe/fmbTeC+NVD5Mv/Oc3QjfOdjaZPWt8GxzXByl/v2y26EVVPUJGt/7F3ifDx3hPNxhfpwxzwoX8e/85UQ8lcm1BzbUrTXjTsKLW9RAyGDAcrVcP8jl98fPKMJWg9z39bpMbh3lVq5Oroi1O1atDY5rm1SAyOQwKgEC+hUft2SmQNH74VnZVitFPD2vvpRB1j3qW8v3/cr/PaCWifJV/W6w/1roeG17ttjq8FTB9RJMXbFKbB79j9Y9mzRXx9kPvUcjRkzpvCDcr355puFHyT04zpclZ/ydeG2uWpRsq8GqwUbI8oW/ZphUfDEPkjeCknroEtuOfwGPeGp3Kn9LyaoXa5FcZ8OZQeE5my5f4yNAZnKXzp7jlxnq5l1zjmShOxSYvhPnj3pPz8JqUfVtdfq94CYym67DVu+4qr/ZmDevFndULEhPrPXU+r/hpqbdHqP+vyyGyGyHPR/U71uqyFQoR5MLKfuj6ulflA9d8D3a10svatm+BQcbbZ/Awqh17IBohC7f1TX5+n4CFizCz/+yrudVatH/6HNMEjZeDUYyu+TRliU/8FRnc5w+XBIaFr89gnd2cjtOdJrWM1ttlrp7znSK+fIPqwmdY5Kibqd1Q+seYOOP99W/6/YUK1m7cK86FGqum44szf/89fqAEm5idJlEtRrgRrs3P69+lhRnH8HylSE7l4K7FZqrK4Rd2yLOsknrAzkXCj43nKXFCqNfAqOVqxYoXc7RFEpCnx7u/p4iS9LgKAGR3aBCmhthfyS1OsO+/P8nLUaAi1v1q9NQlM2m77Dama32Wql84OY61CXfuvDSUJ2qTNiifr+98O9nvsKCnwK0u91MJqh5a3wSm4odfev3t/zC/o70HSA+gG8w4Pq82qt1dpGcTXV5yf/gc0zYaOXQtEHVqkzk83hRbuHIJKE7NIu85x/xz+8WS3cFWjePkGYo+CGD6BiA/VTzOQ6YIpQA6IjG9VuXlFqOHKOdKpBFJilN0KBJGSXOjGV1Q+Daz9QF/zOT+Y5WDnZt3NeNcr5+LGdkHEGytf2v203z4C0ZChX3bktoYnzcY0r1OfegiOAlxJg+EKo28X/awdRkYKjDRs28N1335GUlER2tvswzrx58zRpmPDRhVOFH2MfQ44sp44hB0PenqPmg9V1fcpUcm57/F91+C2yXGDbJjShd0+F63BdKNQ50otBErJLr3tXwZLx8NcH7tu3z4Vlz0HqkYJfXyZe/Zsw4F337eVqqP+KwmhyD4y8CS8D9brB/pVeduYucj4xpWjXDxK/32Fmz55Nhw4d2L17Nz/88AM5OTns3LmT5cuXU66c/FELiIupsO9XyEqDL68v+NiwMuonkjqd9FkyxFeRsY6Htha3qF2+roERqCtES2BU6hkDMAlWvxpBpZ89iJSeo1LIYIA+r3hu/35k4YERqDXgnjsPVwRhua/CCljabJB9QQ30SkEdJL97jl555RXeeustHnjgAWJiYnjnnXeoW7cu9957L1WrVi38BKL45t6lBkcF6fwEdBunJkGHlwlMuwpyy0yU70eyvuIg2gx8DmNYaC5WeClzJGTrViPbySjDagWw5xxJz9ElJ7xM4PJI/fWCS02nXi9Cx4eD1xYf+P3x67///qN///4AhIeHc+HCBQwGA4899hiffupbbQZRTPkFRj1ya0p0fAR6/E9dmLUkBEYAtdtjeWgrx+OuDHZLhE70zjlyZS6lCdmB4BxWk56jULan8gDnk1u+hDt+UIfAgsVe784UDm1HOldV8GbH94FpUzH43XNUvnx50tLSAKhevTo7duygRYsWnD9/noyMDM0bKFyc3K0OpXlTriZ0fEydSp/gZ3VVITSg98KzrkprQnZgpterwalVeo5Kr7BodZX7AuyudjP1Lu+GOSwcmhWSXhEIbe5UV1WofoVaTPjMPnVxWm/yVgYvgfz+iNelSxeWLVsGwM0338wjjzzCqFGjGDp0KD169NC8gSLXoTXqGmRf9PK+f8jXavXoqq3UHiMhAsyx8GxAeo4k56gwNikCWXrdv1btfcmHrYH6d0C5fDhc7uOyIXozGqFhLzUwAnXCjSnC+7HmSDixU81DAji6CT7pAh91ghQfcqsCwO93mPfff58hQ4YAMH78eMaMGcOJEycYPHgwX3zxheYNvOSd2gMH/4AtXxd8nCQyiyCz9xwZdcp5cK28rde6ZKHAXmdKikCWYuXrwHVvwiPe16e09p4U2PYURUIT+N9JGPad5749P6vLpGyaoT7/rLu6FueJ7bB0QmDbmQ+/uhgsFgs//fQTvXurK6IbjUbGjh2rS8MEaoHHDwrI0en3urrIrDWn4PFdIQLAmQCsT3Bkc/ljX1qn8gdipMv+1ZcikCGgfB0Ysxs2TlcXcv3hHnV7ZMkflnJo1FstJ5N3cXKAnx71LEez8weMMdUx2VoFpHn58Ss4MpvNjB49mt27d+vVHqHYMBxZDxVqQfKOgo9tO1LtUrXmlMoKpCK02HsqApFzpN+6ZKEgt+dIco5CQ2w153IeBiPYLG6lUUqFqq3z37fiZY9Npr/ep1aN24HgFQL2OznlqquuYsuWLdSuXYRKmyJ/VguG/Su4fksibPHxNUYjGCPAnM+4rhABpDiG1STnKJicdY4kOAo59uWUcnKC2w5/hUU5H1/7kk9DZ5E55/Vrjw/8Do7uv/9+xowZw+HDh7niiisoU8Z9qnjLli01a9wlZfcCzHNH+H780Nn6tUWIIghonaNSGhyVcf0joTNbKV70U4SY8nXU5GxzBLR/UJ1dt2Ea/PFmvi9pdOInghkC+h0c2ZOxH37YWcDJYDCgKAoGgwGrVX4hiyS/1ey96TMJGvfVry1CFIESwDpHpdXYzkNZ8c0yLqvQRrdrOBOyhSghwqNhzC61BpLBoK6l2fO5AoOjYPM7ODpw4IAe7RD+zDazlrIuVXFJsCdk67V8SGlNwnZVJiKCPxILmXlaTAZHhWxJyBYlSN7lokBdA+5H75WyT5VtSpy+LSqQ3+82hw4donr16tSuXdvtX/Xq1Tl06JAebbw0dXwkzwaXoYoy8QFtihC+cAyr6TSVf0Djq4iw1qWSoa0u5w8VEhyJUuOK4XDzDK+71td9KMCNced3z1H37t05fvw4CQkJbttTUlLo3r27DKsVg63ZDRh3zVeftBoGf76jPu70GHR+HPYsUYtBtrg5aG0UIj/OIpD6BEfhZjN/J84vtflGAWOQ2WqiFLnsBrgsBdKSoUwC/PUhlgoNyfn3YlCb5XdwZM8tyuvMmTMeydnCP9YbP2drWgVatOuGOaEJXDNBTRzo+qR6QIub1H9ClECOIpA6DatB6U3EDiT7u7NVeo5EaRJTRf2/w4MoOTnw7+KgNsfn4GjQoEGA+qkwMTGRiAjn9HGr1cq2bdvo0KGD9i28xCRV6kbzxv3UJ12eDG5jhCgCvXqOhG9kWE2I4vM5OCpXTk0YVhSFmJgYoqKcU1LDw8O5+uqrGTVqlPYtFEKUCoHoORKFs89Wk+lqQhSdz8HRtGnTAKhTpw5PPvkk0dHRujVKCFH6OCpkl+Kp/NHWRmSY9nBVpT7BbkrROYpASs+REEXl97vYnXfeydGjRz227927l4MHD2rRJiFEKaTovPBsICwY/Bl9DXfz9rXBnSlTHPZhNVl4Voii8zs4SkxMZM2aNR7b161bR2JiohZtEkKUQs4K2aW356hidAwdy9Uh3Oz3XJUSQ3KOhCg+v9/FNm/eTMeOHT22X3311WzZskWLNgkhSiH71PFArK0m8ucMjqTnSIii8vtdzGAwkJaW5rE9JSVFahwJcQlTHEUgg9yQS5xztqD0HAlRVH4HR126dOHVV191C4SsViuvvvoqnTp10rRxQojSQ3qOSgb7sKZVeo6EKDK/B9YnT55Mly5daNy4MZ07dwZg9erVpKamsnz5cs0bKIQoHRyz1UpxzlFokJwjIYrL73exZs2asW3bNm655RZOnjxJWload955J//88w/NmzfXo41CiFLAUedIeo6Cyj6sJsuHCFF0RZqSUa1aNV555RWt26KJRYsW8cILL7Bt2zYiIyPp2rUr8+fP9zjuzJkztGrViqNHj3Lu3Dni4uIC3lYhQom956g0T+UPBTJbTYjiK9JHvNWrV3P77bfToUMHR82jmTNn8scff2jaOH99//333HHHHdx1111s3bqVP//8k2HDhnk9duTIkbRs2TLALRQidEnOUckgw5pCFJ/fPUf2AOS2225j06ZNZGVlAepstVdeeYXFi4OzWJzFYuGRRx5hypQpjBw50rG9WbNmHsd+9NFHnD9/nmeffZaff/65wPNmZWU57hEgNTUVgJycHHJycjRqPY5zuv4fakL9/iD077Gg+7MpuZM0lNJ7/6Hw/bP321lsFq/3EQr3WJBQvz8I/XvU6/78OZ9B8XNguk2bNjz22GPceeedxMTEsHXrVurVq8fmzZvp27cvycnJfjdYC3///Tft2rVj6tSpvPvuuyQnJ9O6dWumTJnilgu1a9cuevTowbp169i/fz/du3cvcFht4sSJPP/88x7bZ82aJUuoCOFiUvJ3pEduo1F2P+5MkEWog2VK8jxSIjdRL7s3IxI6B7s5QpQYGRkZDBs2jJSUFGJjYws81u+eo3///ZcuXbp4bC9Xrhznz5/393Sa2b9/P6AGM2+++SZ16tThjTfeoFu3buzZs4cKFSqQlZXF0KFDmTJlCrVq1XK8piDjxo1jzJgxjuepqanUrFmTa6+9ttAvrr9ycnJYtmwZvXr1IiwsTNNzlwShfn8Q+vdY0P29881C0hWoWqUq/fr0C1ILiycUvn8ffruEFCvEV4qnXz/P70Mo3GNBQv3+IPTvUa/7s4/8+MLv4KhKlSrs27ePOnXquG3/448/qFevnr+nK9TYsWOZPHlygcfs3r0bm01NPhw/fjyDBw8G1MVya9SowZw5c7j33nsZN24cTZs25fbbb/f5+hEREURERHhsDwsL0+2HUs9zlwShfn8Q+vfo7f7sCdkmk7nU33tp/v4ZDSYAFAMF3kNpvkdfhPr9Qejfo9b358+5/A6ORo0axSOPPMLUqVMxGAwcO3aMtWvX8sQTT/C///3P39MV6vHHHy90zbZ69epx/PhxwD3HKCIignr16pGUlATA8uXL2b59O3PnzgWcCaSVKlVi/PjxXofPhBC+sf8+mWS2WlDZv/qKVMgWosj8Do7Gjh2LzWajR48eZGRk0KVLFyIiInjiiSd46CHtV7KOj48nPj6+0OOuuOIKIiIi+Pfffx2VunNycjh48CC1a9cG1GTyzMxMx2vWr1/PiBEjWL16NfXr19e87UJcSpzLh8hsqWCyf/2lzpEQRed3cGQwGBg/fjxPPvkk+/btIz09nWbNmlG2bFk92uez2NhYRo8ezXPPPUfNmjWpXbs2U6ZMAeDmm28G8AiATp8+DUDTpk2lzpEQxeSscyTBUTDJwrNCFF+RikAChIeHExMTQ0xMTNADI7spU6ZgNpu54447yMzMpF27dixfvpzy5csHu2lChDxHcCR1doLKXiFbikAKUXR+v4tZLBb+97//Ua5cOerUqUOdOnUoV64cEyZMCHrNhbCwMF5//XVOnDhBamoqy5Yt47LLLsv3+G7duqEoivQaCaEBRbEPqwW5IZc4Z3AqPUdCFJXfPUcPPfQQ8+bN47XXXqN9+/YArF27lokTJ3LmzBk++ugjzRsphCj5ZFitZLFJQrYQReZ3cDRr1ixmz55N3759HdtatmxJzZo1GTp0qARHQlyyJDgqCZwJ2UFuiBClmN/vYhERER41jgDq1q1LeHi4Fm0SQpRCzqn8EhwFk31YTZGcIyGKzO93sQcffJAXX3zRbb2xrKwsXn75ZR588EFNGyeEKD3sU/ml5yi4HAnZMqwmRJH5Pay2efNmfvvtN2rUqEGrVq0A2Lp1K9nZ2fTo0YNBgwY5jp03b552LRVClGj2nCODZGQHlf3rr0hCthBF5ndwFBcX51iew65mzZqaNUgIUTrZe45kWC24nMNqEhwJUVR+B0fTpk3Tox1CiFLPnpBtCnI7Lm1S50iI4ityEUi733//nQsXLtC+fXsptijEJczeUyGjasFlNqpv61bFGuSWCFF6+RwcTZ48mfT0dF588UVAfSPs27cvS5cuBSAhIYHffvutwKKLQohQJrPVSgKzQV153GILblFeIUozn9/Fvv32W5o3b+54PnfuXFatWsXq1as5ffo0bdu2lVXthbiESRHIkiHMZO85sgS5JUKUXj6/ix04cICWLVs6ni9evJibbrqJjh07UqFCBSZMmMDatWt1aaQQouRTUIdxJDgKrjCjvedIgiMhisrndzGLxUJERITj+dq1a+nQoYPjebVq1Ryr3AshLj223ByXyLCIQo4UerIHR1ZFhtWEKCqfg6P69euzatUqAJKSktizZw9dunRx7D9y5AgVK1bUvoVCiFJBQe2piDSFBbkll7Zwkz04kp4jIYrK54TsBx54gAcffJDVq1fz119/0b59e5o1a+bYv3z5ctq0aaNLI4UQJZ8td1gt0izLCAVTuFGCIyGKy+fgaNSoUZhMJn788Ue6dOnCc88957b/2LFjjBgxQvMGCiFKB3vPUbhZeo6Cyf71t8lUfiGKzK86RyNGjMg3APrwww81aZAQonRSDNJzVBKE2escITlHQhSVTCsRQmhE7TmKkuAoqMJN6tdfeo6EKDoJjoQQmpCeo5IhMndYzT7MKYTwnwRHQgiNqMFRlEzlDyr7bDV7grwQwn8SHAkhtOHoOZKE7GCKcAyrSc+REEXlV3CUk5OD2Wxmx44derVHCFEKZVssGAzq8iGScxRckWHq11+RniMhisyv4CgsLIxatWphtcovnRDCKSMny/E4KlyG1YLJPqwmOUdCFJ3fw2rjx4/nmWee4ezZs3q0RwhRCrkGR9Fh0nMUTPaEeHuCvBDCf37VOQJ4//332bdvH9WqVaN27dqUKVPGbf+mTZs0a5wQonTIzMl2PJZhteBy5nxJz5EQReV3cHTDDTfo0AwhRGlmD44UxYjZZApyay5t0nMkRPH5HRzlXTZECCEuWnJ7jhQJjILNWUpBgiMhiqpIU/nPnz/P559/zrhx4xy5R5s2beLo0aOaNk4IUTrYe44MEhwFnWNYTXqOhCgyv3uOtm3bRs+ePSlXrhwHDx5k1KhRVKhQgXnz5pGUlMSXX36pRzuFECWYo+fI/7cUoTF7zpfBoJBtsRBulu+JEP7yu+dozJgxJCYmsnfvXiIjIx3b+/Xrx6pVqzRtnBCidLAHRwak5yjYXEspZFqyCzhSCJEfv4Oj9evXc++993psr169OsnJyZo0SghRutj/CBsU6aUINtcK5ZkuJRaEEL7zOziKiIggNTXVY/uePXuIj4/XpFFCiNIl25oDSM9RSeBaSuFiTk4QWyJE6eV3cDRw4EBeeOEFcnJ/6QwGA0lJSTz99NMMHjxY8wYKIUq+LMewmvQcBVu42YyiGAAZVhOiqPwOjt544w3S09NJSEggMzOTrl270qBBA2JiYnj55Zf1aKMQooSz5xwZDdJzVCLkzhrMkGE1IYrE74955cqVY9myZfzxxx9s27aN9PR0Lr/8cnr27KlH+4QQpUCWxT6sJj1HJYH6fbA4vi9CCP/4/U528eJFIiMj6dSpE506ddKjTUKIUibbpv4RNhkkOCoRFHVQ4KIMqwlRJH6/k8XFxXHVVVfRtWtXunfvTvv27YmKitKjbUKIUsKekG2UnqMSQv0+SM6REEXjd87Rr7/+Sp8+fVi3bh0DBw6kfPnydOrUifHjx7Ns2TI92iiEKOGyHDlHEhyVBPaSCtJzJETR+B0cderUiWeeeYalS5dy/vx5VqxYQYMGDXjttdfo06ePHm0UQpRwMqxWsth78KTOkRBFU6R3sj179rBy5UrHv6ysLK677jq6deumcfOEEKWBfVhNgqOSweAIjqTnSIii8PudrHr16mRmZtKtWze6devG008/TcuWLTEYDHq0TwhRCmRb1T/CZkN4IUeKQDAa1CrZFy0Xg9wSIUonv4fV4uPjycjIIDk5meTkZE6cOEFmZqYebRNClBJp2WkARJvLBLklAsCEGhzJsJoQReN3cLRlyxaSk5MZO3YsWVlZPPPMM1SqVIkOHTowfvx4PdoohCjh0nPSASgTJsFRSWCy9xxZZVhNiKIoUoJAXFwcAwcOpGPHjnTo0IEFCxbwzTffsG7dOqmSLcQlKCNH7TmKCY8NcksEuARH0nMkRJH4HRzNmzfPkYi9a9cuKlSoQKdOnXjjjTfo2rWrHm0UQpRw2Tb1j3CZMKl5VhKYpedIiGLxOzgaPXo0Xbp04Z577qFr1660aNFCj3YJIUoRq5IDBgg3SUJ2SWAyhoENsqzScyREUfgdHJ08eVKPdgghSjGrYgEDREhwVCKE5c4alOBIiKIpUs6R1Wpl/vz57N69G4BmzZpx/fXXYzLJitxCXIqsqHWOIswSHJUEZmMYWJ31p4QQ/vE7ONq3bx/9+vXj6NGjNG7cGIBXX32VmjVrsmjRIurXr695I4UQJZtVyQ2OpOeoRAg3RgCQLT1HQhSJ31P5H374YerXr8/hw4fZtGkTmzZtIikpibp16/Lwww/r0UYhRAmnYAEgUnqOSoQwk5qQnWOTniMhisLvnqPff/+dv/76iwoVKji2VaxYkUmTJtGxY0dNGyeEKB1sihocRZkjgtwSAS49RzbpORKiKPzuOYqIiCAtLc1je3p6OuHh8qlRiEuRLbfnKCJM3gNKAvuswSyLrF4gRFH4HRxdd9113HPPPaxbtw5FUVAUhb/++ovRo0czcOBAPdoohCjhlNyEbOk5KhnsuV/HLOuC3BIhSie/g6N3332X+vXr0759eyIjI4mMjKRjx440aNCAd955R482CiFKOMWgDt+Ujyob5JYIgBqxVQAwKrKcixBF4XfOUVxcHAsWLGDfvn2OqfxNmzalQYMGmjdOCFHy2Ww2FGMWBqBidEywmyOADjVb8M1BUJAK2UIUhc/Bkc1mY8qUKSxcuJDs7Gx69OjBc889R1SULBcgxKUsNSsTg8EGQEKZckFujQCIiVDflxWDzFYToih8HlZ7+eWXeeaZZyhbtizVq1fnnXfe4YEHHtCzbUKIUuDUhVTH40rRsvBsSRAXqQ6nGYwWLFZrkFsjROnjc3D05Zdf8uGHH7JkyRLmz5/Pjz/+yNdff43NZtOzfUKIEu7UhRQAFFsEZqmSXyLERkQ7HqdlyYw1Ifzlc3CUlJREv379HM979uyJwWDg2LFjujRMCFE62IMjoxIZ5JYIu3KRzuDo3MULQWyJEKWTz8GRxWIhMtL9zS8sLIycHBnTFuJSdiZDDY5MiuQflhThZjOKTe3FS5WeIyH85nNCtqIoJCYmEhHhrGNy8eJFRo8eTZkyzumi8+bN07aFQogS7UymmnNkNkQXcqQIJIMSBlhJu5gR7KYIUer4HBwNHz7cY9vtt9+uaWOEEKXP+YtqcBRmlOCoZAkDLpKaLcGREP7yOTiaNm2anu3QxJ49e3jyySf5888/yc7OpmXLlrz44ot0797d49gzZ87QqlUrjh49yrlz54iLiwt8g4UIASlZ6nJCkRIclShGJRwbkC7DakL4ze8K2SXZddddh8ViYfny5WzcuJFWrVpx3XXXkZyc7HHsyJEjadmyZRBaKURoSc9JByDKLNWYSxIj6hIiF7IlOBLCX35XyC6pTp8+zd69e/niiy8cQc+kSZP48MMP2bFjB1WqVHEc+9FHH3H+/HmeffZZfv755wLPm5WVRVaWc2Xr1FR1CCEnJ0fzZHT7+UI1yT3U7w9C/x693d+ZzNMARJvKlvr7DqXvn9EQBsCh88lu9xNK9+hNqN8fhP496nV//pzPoCiKounVg0RRFJo2bUrnzp15++23iYiI4O2332bKlCn8888/lC9fHoBdu3bRo0cP1q1bx/79++nevXuBw2oTJ07k+eef99g+a9YsoqNlGEGICecnANA853qGxF8Z5NYIu0nJ35EeuY2qF7vwQJVrg90cIYIuIyODYcOGkZKSQmxswQVrQ6bnyGAw8Ouvv3LDDTcQExOD0WgkISGBX375xREYZWVlMXToUKZMmUKtWrXYv39/oecdN24cY8aMcTxPTU2lZs2aXHvttYV+cf2Vk5PDsmXL6NWrF2FhYZqeuyQI9fuD0L/HvPeXmZMNc9Tg6I6O19OrQevgNrCYQun7980PG9iZuY3o2Ci3GnWhdI/ehPr9Qejfo173Zx/58UWJD47Gjh3L5MmTCzxm9+7dNG7cmAceeICEhARWr15NVFQUn3/+OQMGDGD9+vVUrVqVcePG0bRpU79m2UVERLiVL7ALCwvT7YdSz3OXBKF+fxD692i/v8NpZx3brmnQKmTuORS+f6bcauX/ZS8hLOx1j/2hcI8FCfX7g9C/R63vz59zlfjg6PHHHycxMbHAY+rVq8fy5cv56aefOHfunKNH58MPP2TZsmXMmDGDsWPHsnz5crZv387cuXMBdSgOoFKlSowfP97r8JkQIn8n088DoNjCiQwLD25jhJvkjKOOx+cy0ikfXTaIrRGidCnxwVF8fDzx8fGFHpeRodbyMBrdJ+AZjUbH+m/ff/89mZnOmRvr169nxIgRrF69mvr162vYaiEuDc6lQ6Q6dkkTboyA3KUvd5xIonPdZsU+523fT2TX+b/48aZZ1ChXodjnE6KkCpmp/O3bt6d8+fIMHz6crVu3OmoeHThwgP79+wNQv359mjdv7vhXt25dAJo2bUpCQkIwmy9EqTHr1N8Mmfc/bDYbpzMkOCqpbIpzUfD7V93KjuSkYp9zW/r3WMxHeWlVya97J0RxhExwVKlSJX755RfS09O55ppraNu2LX/88QcLFiygVatWwW6eEEF18OxJVu7fQbbFwr+nir5YtMVqZVfYQvZcXMQPu//irGPpEAmOShrX4Ahg6OIhpBRjKRGL1ep4nJpb+FOIUFXih9X80bZtW5YsWeLz8d26dSNEKhkIUaDrFvTDYHTW60qsP5HHOw32+zx7zjgDqw82fsGZnP/ADOFGKQBZ0tiwum8wpdHp23YMr/scDck/MTXp/ClqxFb0SFFISjnteHwu6zQ2m83jGCFChfxkC3EJcA2MAKb/N5E3/5hHcto5AN5ds4Bf9mwi5WIG65L2km2xOHL1XO04ecjx+JTyNzbzGQDMBknGLmmqRFf3un3GgfwnnszbuZb+C66h76wHPfbtP+tcaeCI5Xeumn495zMvFL+hQpRAIdVzJITwdCEry+v2af89x6w90xjXbhyf7Z0Ae4G16r5wa22yTYcoz+WsGj4DgGyLhe0n//N6rrO2bXo0XRTDu30f54Y5/3GeLYUe+8+pI1htCs9tuAeAY9bV3P/jW1zXqAtT1n1A1eha9KjT3u01WaaDjP5pErNvflGP5gsRVBIcCRHiDqeeyndflukgEzfc67E926T2EJ1jE9M2LuOuK3rRdeYw0o278zmTQYumCg1VjI5hxoDXuf7Hnh77DmaeZ8X+HVzbuA27Tx7h5sXXgWLC4DKWsPrsVFb/NRWA0xfWU/V0ZY/z7E79U7f2CxFMEhwJEeKOpJwp1uvf3DGGmPCPCwiMwKhIzlFJVC7S+xJHn2e9Dn/BS9bPeXP9hxgMVjBYvR5rt/TEhx7bjAXkLglRmklwJESIO55WvOAI4PlNowvcP6DmXcW+htBeuYhosEaBKdPr/gnr7y7W+cuH1SjW64UoqSQhW4gQd/LCOd2v8WKPRN2vIfxnNpl48ep3dTt/jpKt27mFCCYJjoQIcRdy1F6DSGt9sMa47asT7pmPUhQypbvkuqHZ1ZgtVX0+3mzxPsvNm3RL/vlsQpRm8o4mRIi7mKPOVoswRrN66DK3fVdWuaLA11Y1dvS6vVWZm6hIW20aKHRnNfhe/HHRzbN8PtZiKP6QrRAlkQRHQoS4i1Z16MNkCCMuypk4rdhMJLbpjcFaLt/XfnnDq3SrNAqDJc5t+6vX3E+YMUKX9grtXVnhOgDCrN5zhLpUHInBWo7yXE61WD/WTDNd5FjqWS2aKESJIsGRECEuy6r2HJmNaqHGJ1q8jcmSQO+q91IrLp4Nd65k3bANjuMVxTktP6FMOd7r/zANynRwO2eVmDhGthoGQLStkd63IIrpg/5jeLz5W/w2ZI7HvoYR/fjgukfZNuIPR02rckrLQs+p2NT5PMfT9M9pEyLQZLaaECEu25oDgNmgTrsefnkPhl/ew7E/3GwmHDP3NHqJtUc3kpxxjFPKOsCZS/Rh/7H0/W4zFvNxLrfcDMCQll1oWHE+TSrJjKWSLjIsnMQr1PyyEfWf59udc/io/8vM+2cVYzrc5HH8r7dN43DKGUxGIykXM7hz2UCPYwxKGGAhLcv7TDghSjMJjoQIcdm5w2phxoKX+Hio/fU8xPXcu/B1Tp1bh8HiHF6pElOezSOXkpWVxS+//OLYfkX1+vo0WujmwXYDqHfGRPPKNWlTI9HrMZFh4TSs5D2J+676z9MsoQ5P/vEQkMmFnIv6NVaIIJHgSIgQl+0YVvOtYN/kXvfxwsooute50mOfzEq7NEVa63PR9B9xtGZMp0EAPL06DBuQLj1HIgRJcCREiMu2qT1H4YX0HNnFRZXhzb4P6NkkUcp80e9tPvh7Lv/rOsKxzUg4NuBCtgRHIvRIcCREiLPY1JyjcJNvwZEQebWsUodPBj7hts2Ym8OWYfG+sLEQpZn0kQsRYOcy0pmyeg6n0lMDcr0ce8+RBEdCQybUn6eMAPYc2Wy2gF1LXNokOBIiwG6d9yRf7n+Bwd8/FJDrSc+R0IPZkBscWQKTkD1s7rO0mtmKzjPuIFnKBwidybCaEDqy2WxuScwvr5zFcesfAJxjU0DaYFFygyMfc46E8IUp9+cpMycww2rbL/wAwHm2cMf8caRaTnFlfBfev+6RgFxfXFokOBJCJ9fOHM2J7D2sHLqQ9Owsnv71PbZf+D7g7bAvDhphluBIaCfMEA4KZAao58hVsu1PMMLvZ/YAEhwJ7UlwJIROjtv+BDN8vH4Rsw6+FLR2WBULGCDSJMt9CO2YjeFgdVZgFyKUSHAkhA5cE0fTstKD2BKwKtlqcCQ9R0JD4cYIsMLFAMxWKygRe13SXmqXr8SP//zNnH9+wKLk8FDMAN3bJEKbBEdCaOyi1cKCf/52PP/lyFwwBa89NsUCQKRZeo6EdsJzFx7Osuo/rJZtteS77+4Vgzy2bc+4kuv0bJAIeTJbTQiNvXHqW17ccr/jeY7pSBBbAzbUhGzpORJass9+tC9Po6ccm9Wv40/npPPJhp9l6r8oMuk5EkJjmZG7g90EN7bc2WpR0nMkNBRhigQg26b/sFpBPUferDDMYMUeSMlKZ+QVffllz0Zub90dsymIXbiiVJHgSIgCpFzMIMJkZvn+7UzdOpdr63bhniv7AtBp+m2kGLYx+erp1C1fmRdXfc6ulNUl7rfKhvqHJSpMgiOhHfvsR3uRUT3l+Bkc2c0+9Co/7P+GLNNBtp0cLcviCJ+VsLdxIUqOMxlpdJvdE0wZjm3/7vqJXaf30yK+ASmGbQA8/Vei80Ul8DdKMah/WKLDIoPcEhFKInN7jnJKYM+RqyzTQQCWnfyYVQe6AfDZpu/pXvtqhrTqSnQRPjSkZWVSJixCFmIOYSXwrVyIkuG7HavdAiO7305+zG8ng9CgIlKwB0fScyS0E2XODY6UQPQc+ZdzlJ8HViSCSU0g37JzDtN3tmHV8C/djunz1QNk2TL47fYvvAY/+8+e4PoF11HR2JyVw6dp0i5R8kjYK0LOxRzf3qxnb1tFyy+6MGnVt6w/so+NR/9jy/GDpGWpa0WdunBWz2aCNUbf89vZe47CJTgS2rEP01oDMKxWnJ4jNyb3mXXn2Oz2PC0rk6PWVZxWNvDD7r88Xp50/hTX/9gTjBc5wwZt2iRKJAmOREj54K8faftVO577bYbHPpvNRu+v7qfbjER+3L2elzc/gGI+x9cHXmLEbzeS+OsN3LF0AD2+HgYUPc/BV0YlMLPHlNzZajKsJrQUndtzZAlEz5FN/V1UFO0Tqt/443tOpKcAsPhfZ8Dzwl/PcCz1LL1mjuaV378B4NFfXvd4/Sd/L6bT9NvYlnzQY1/S+VNkFLC8SnLaOR5e9B67TwZ3RqvwJMGRCCkf//sMBqOFeUde53zmBa6edjO3fDcegPVH/uOYdTVn2Mgzf4/I9xyZpn1k5GRhU/SdBqygzVBBQbItFgxG9TqxEVG6X09cOhw9RwSg58iS+0FF0f5P1vT/JtLzu37M2PQbL212luCwmc/Q+4euJNv+5JuDrwCQkuPZm/z+7qdJMWzj/l/U95kHf3qHt/78gTWH/qHf/J70/Gq4x2u+2LCE/rMepte8Lqw4/SlDfryTaRuXYdFo+FAUnwRHQjMLdq1j6oalbttWH9hFixktGDl/UoGvTbmYUeSaJP+cOsKO5CQW7Frntv3rrcu5YPyH3ZkLSTp/ih/3/OHzORfuXkd27mr2ujEo+p4fOJ2R6nhcqUys7tcTl44yYWqwbS8VoSeLo86R809WrbDubsdUM3Uu+gVMqXyx3bO32dVrq77jpGWL2zbX96wL1pPM3f4nv5/5nKn7nmXM8gkYDDbSjDvZf/aE47j9Z0/w9s4nSMpZ4TyP+RRv7hjDrXPHM2PTb16vn5GTRb+vH+LllbOKcIOq6Rt/ZeX+HWw+doCeM+9hyuq5RT5XqJPgSGhmwvq7eWvn4+xITnJsu3/VrQD8nfI1Y3/9nEVndnEhS+1mfm/tAtpOHchXW1bQaVY3enw1kk/+Xszgb8c68n4K8ueh3Uz4dRo3L+7L0CX9+WnvKrf9/51ztmPhP39xPN33LOp3Nr5PlqXon4ibRA7gf5d/VOAxCvoXqLMHR4piIiZchtWEdsqE5wZHgeg5yh3iNrj0HMWGxdEosr/j+ZLbP2Ri20+KfI1IU5kC98888CIY3XOWBn33tOOxxZzMP2cOOZ5fMP7rePz40jccjxf965nLZLfn4iKmbHuMZXu3cMf3L7Iuaa9jyO3Z36Zx2LKS2YdexWK18l/GWZ8/UK7Yv52WX3TmjR2P8dDqoTy27HlO2NYyc897gNoz9/LKWWw+doAP1/3E/F35t/FSIbPVSqFsi4XtJw5xRfX6mp1z/LKpNKxQi8QrejqukXIxg/iy3nsbEn94ma1nf+fRNk/zybbPuanBzY59W0/sp3mVWh6vWXryQzDBg79k88I1o/l0zwQwweStD4MJTisbeH+3OuY/dlkVPrjuUaZuWMpbOx/n5lpP82z3293ON/q3EWByrlv213n3WSfLTn7sePzJv8/49fVIN+4mx3a127a/hmzg6tltC3zdI01fJ/74Rfr168f5rExe3OTcd0XsEDamzqZRZH/2XFwEGg2rLdm7mZjwKMpGRNKySh23facvqMGRwSbTjoW27Dls9lIRvtpy/CAx4ZHUr1jF6/4dyUnM2bmC/3W73VG00dlzZKBzhRGsO/Urk3s95JEDZDYUPSfJqvifY/hf1i9uz7899KrX49JyzgPw4+71rDq8zusxdgaDwuOrHkExn+XuFd8BUMPclZiwco5jbpg7hmPW1RxZnsmbfe/n4NmT/HvmKL0btgHgfOYFwoxmykSoQ5+PrXgUxXze8fozbARAMZ9l2d4tvLL2HU4rG5jtjO24odl2vtqyAoPBwG2tuhX6tQg1EhyVAtM3/kq7mk1omlADm83GXQteYlv693SvdA/v9n/I7/PtPnmEb3cs5/uDH4Apg+urj2HhsbfgGLStvoj/rXyffVk/AzCw2mO83GsEE36dxn/nDjDthglEhoWzIWUOBrOV17c/CgaY9t8Ox/nf3Pg6Peq1okpMea/X33phLtf/WHB37qozXzBs7nm2X/gegDlJk2m39zKeWHMnAAsG/OoWGOkh77IIZSIi2HjbZq74uk2+r4kKCwfUT5fxZWPpU+VBtp3aSs/a1/Bk55tIyxrD5mP7eWDVIqD4w2q7Tx5xfE0AJl89nX6Nr3A8X3NY/b4YFck3EtqKyc1hU3J7jixWa6EVqI+knOWOpeqisNuHb2fDkX3cvWQ0PavfxOt9RgMwdInaGxT3VyyPdbwRcJ2tZuLDAY8BjwHQrVYH9u5d7Dh/fBlnADG01jPMOvgaBqNvQY9Vx2H0E7a17D19vMBcR1eK2T236Yjld3C5jWPW1QAsO/kR65J6MfK3oRiMWew88Twz//0Ui/ko4daavNHtNbrUaYbFdBpDPtcas+YOr9tnbPpNfX8H+jf6i7gotWftRHoKN33/IOet/zG4zmgmXnOn2+vOZ14gNiLK8WHs222rmbrtG97sNY7LKtd0O3b3ySNUjSnvOHdJIh8lS5hFZ3bRfuZg1iXtBdTZV2/seIyhP94FQMcZQ9iWrgYMK05/6vf51yXt5Zaf+/L94SmOGj4Ljr7p2D/k5+sdgRHAwmNv8f3ONSw4+iY7Mn7gqpnXcMt34zEY8u/1yDYdote8LkxZPcfv9rmyB0Z2rkHA9T/2LNa5fZGWneZ4bLJUBiDcbKZ+RB+34z7vPs8xLb973ZZu+6b0vpclt3/Ik51vAtQ/KOEm9TOJYii8Szw57RwzNv3GPQunOLrQ5+1cS/9Zj/DfmWT+PvKv2/Hvrp/Koz9/wJbjB/l222rHJ9kyxso+37cQvigbbu85ymH6xl9p/WU7nl7yGTabLd8ZWkv3OmeDZeRkMea3F7CaT7DkxAeAew7P1H3P0mJGCxJ/eJml/6m9LYY8f7IevHoAoxu/wsxrfwSgQ+0mtC57C02yr+PJTjcxts2b+CrL5lnTTEuDFl2ry3nvXjEIg1H9ek/dNxGL+SgA2abDPLR6KK1mtsLgw3tNXvbACGDnySTHjL4h8x7jPFvAlMb3h6ew88Rhx3HD571M5++upv83DwPqTMCXNt/PMetqhvzSz5lYj/q36ObF/bn2mzvcvu82m41f9m7GZtM/J7Mg0nNUgnyzfRVrTWqy3RMrXuD3O2bw7b9qD4vVnMySvZtJN/q+bte25IM8//vHPNV+JO1qNQRgxtafCnyNt09ZEzfc63ismFLYnbnQp+t/uf8Fn9saLAnGq3nq6vt5++8v1E9nLlzvc9yVzzkez715Ev2/ucAx62qebvUu7Wo15I9hv3LRkkOFiOhCr2k22j9d2/jn1BG+3b6CcV2GEm5Wfx2fWvIpVsXKsbTjbL8wH0Nu4vZLv1dl2aFfOG/YCkDij2cIN7n3CB21ruLoyVX8tvRj4g3tHNtjwir6/kURwgd1K1RGUUwYjBbe2PEYBiMsTn6XZdPnoSgWVt62gHKRzt+HpPOneGvn447n0zYuJdOaAi6dTTO3rCCvjamzwT6vIM9sNaPRyANXD3DbNnXgWBYvVnuTmlRy76kANXHb3vPiytt7a4OIvnSofmWpeC8DHO8VWhu98hYUxUCbmJs5rax32zfkl34A/O/yj9iUNhvA8V46/b+JbsdeNaM3VvNJsEahGLMwGGxkmvbSamYrR+rEj/+sZ8L6uzFmV6OPtQ9hYWG63FNhJDgqQaa4ROrn2UKbadcQaazo6N9z7Tmxu3xqX8a3+x+zdiykc82rqRETz4I9y3m43VDuWnYLBmMOd69YRBVjRzKtaTSveHmA7qZ0+O2OzwDo3fB9AJbt3eLRzWy0xHNrS+dMGLPJxJLbP3Q7plxkNOWAnJzCu+btQZDBmMPNi9V12v745g8al29GVFgkvyS/7zjW4NIXPidpMq594+cNWykopztHcX56jzTJsJrQVsXoGEzWCtjMp9y255jUBOJXV33N6LbX88Svb/Fv5k8YLZXc/uJ8/O8zhCk1HM9fWPGV+jNegLw9R4VpW6MBoxu/QtWYSpzLTGXW7rl81O85Bi7sVWAg8XXvHx35eztPHObL/e774w3tOKUUnDsUagwGhS3p3+W7//X1b7gFupNWfetxjNWcOynGlOkxzDcnaTJjLUOYs1vN44q2VQzqQsESHJUQqw7s9NhmM58hgzMFvi7HdMTRs7Nn7yLH9hG/fYfB5X0k2fYnGODPs9u0aXAxtCpzE1sveM85ilGak2bY4XWfVmKV5qQadlAez0CxV8PWGFdVxGZ2ft0fbPm0x3HFEWb0/LVLtq0h+cwaTa9zni2Ox5FmCY6E9kyGiHzj80XH32XR/M/ApM48tZlPexxjwTmUVVhgVFSuPUsj2/YG4P0us/jryE62ndztMXxfw9zNbWJDgksek53BYPApZTDSWo+Lpv2FHxgCMk373J5/feAlv8/hms+ZYKxW7DYVh+QclRDH03ReqsKLL3stLHbF2bvqP+/3ax6/+g4Um+dSFq9c9QUrb5+JYvM/Zo+yqsOGZWyN3bb3reKZsL7stunc33Qy3w9+z+u5lDzvetfUa+V3ewpizzkKpGhz4cN9QvjLqhSy6Kyp4JIceROPC+P6oaU4utVrztgutzLrpoke7zdKnuKvFaPLerw+wugsi9GhvHuRxy4VRzoe31h/iBbNzW2Xga13bKVp1EBNzme0xJNgvLrwA4OkvNEzKA0kCY5KiEaVahR+kJasZWhTrW6BidXXxN+b7z67MZ0GcX31MT5fNupiU5pXrsmCgT+x5EZnjo+iGBnQ9CrCzWaur+H/DLyPek/h3c6zWHXHbOdGaxSTet3tcWx0WAT3XdUv3zIFrgZUezTfKcdFVTYIlaqjwyQ4EtqzGdMKP0hD/rzX+CpCqer2/JYm17s9dy2BUdXUiaF1nmFKz6cwWRLoXGEEnwx8wu34Sb3upVbYNdxV/3keuXoQEda6Xq/bquxNTGnvLDw5uOaTjsRyb8KsVTAajWqvlQ/Mlvx7XhLrT2TryOX8dsdnDKszwW1f3gknwRIfFqC1J/Mhw2olROP4wHYhGpTCFyF9p9+DtJhReFG1l3rexY9fzHB8qutX5WEWJ7/r9dhbYtVfPHvAYU+ObBrtLOb2cq8RLJzxlsdr28YOpUxYGX4/87nb9qdavpNvzSej0cj24dvZffIIw368m+7Vrvd6nKswQwzZqJ9oX+k1spCj/Ve2mGuc1TR347BlpV+viTTLorNCewpKvlPE9TCkeQ/Nz/lK55d5ec3b3Nd6BOWjYujTyHO4/fPu80hOP8v1zZyTHLaMdFayfqLF2yzZ/zufXz+e6LAIFg17x7Fvw4iFrDn0D/eudNaCC7PW4KvB6iSP42lvciHnIg9ePSDfRbPjlFbce4X6XvTIVbdz78oFBd7TskGrqBJTnpSLGXT6tp3bvrc6fkXPBs7e8ByXEgbdKo1iQtfh9Pr27wJ79epH9OFIxr9kmQ4U2I7iqBomPUcCtTfj1ppjaZFzA7fWHIvZom1vRV5VwpsC0CZGrWA9sNpjbvvzdt2GW2tRTmmJweK9dlGFsHqOx5N7j2LR9cs9PjHVMl9Dw2j3WVPfDp7CvY1f4bMB4922x9gu87jGM53v4v3rHqFFmcFu2zvW9jxW5Rwea5pQg80jf+HNvvflc6zTy51eAFskjaOuK/TYoogq5uyLyyu7v3kPqvGE2/BhFWNHj9dYdV4nTlyaDPmtdWbN/1P/tZXv55WrvnBusHl+WBhQ9VFuruWZ61cuUvt6OL0btmHV8BkMbdXVa2AE0K5WQ7fAKK/hl/dg1k0vEB3m/UNIh9pN3J6vvm2+4/FdV/Tiwdy8qMiwcP4asoGve/+oJrADjSL7szrxK25v3d1xrnn9lvBszPM0iOjrca0xzd901JgrFxnNWx2/ctvfOM8oxb1XDsBsqUajyP681/9hKpctx7JbF7L4+pX53m9MWCzzB08nVmnOgGqPUtbW1LHPW49VvyoP53uu/FSLCG7PkQRHJcjTnW/h1vi2PN35FjaPXEa4tbZjX+cKvhUPs7ur/vPqeLLV+5vJx/3VXKEvB03gryEbeLnXCLcf6hGtBzuua7JU4avrPuGPxK/ZlLgCg6UC4L5C9uf9X6F2WA9evFKd/VUrLp5Vd8whzOqcSnt5QmuPdsRFleHBqwd4FAH7uO8koqwNGFrnGRYM+JWpPX6gYSW1+/u9fo872gBQJy7e56+LL/o0upz1t//J3Fu8V7stLm+VqsvThhrmrlQxdmB041e8vi7K2oBGkf0Z3Kyb2/a72vTluW7DKU8bmkffyJCmN3q8tk/99pq0XQh37v1GcbTm+bafsn1E/pML3uhzH/0bOyvNxxkauwVCVYwdeOXakUzoOoy76j9P3fBezmOjSu/w8ICqjwLq8Jm9crU3ZSIiaFmlDrMHzKR/1Yf5YuD/PI6pExdPuMlE4/KNPPZF5QnQejZoxaqb19Kh/HAGVnuMmnHuH1Arly3H5pFL+P7WSW7basZVxGhxHmu0xDve84c070uNchX4M/EbXuk1kiZxrR3HNS3XnmhbQ7drJJSpgL+iTMGZwm8nw2olWJuKnVl3Xq3n/n7/R1j2XzcAXl3zDmPbP8yTaz1Xewa4s96zjOk0iDGdBgFwMSebq77s5dZNWq+Csyig/Rd19sBpjFz0JJdVaOP4BOVajRbUaexvd3uP8ate4sHLnStY169YhZ+Gve3WjuiwCDYk/sTPezfx2/71TOgyjF9+cS+3n5+WVerw94gfvLa3YnQMmxKXM3z+i1xdrY1HsFE7rAeHcn6jR9VEn67lTWRYeJFf6y+jJZ5VI92XPvk96S+PelL2r4drIbXZfRZTp0ICAKuGq+c4fP4Mb+dOfpzecz6Hzp/M9xOxEMXj/rv3Ue+XPZYOqmrsyHHbn+6vcvmdVbBxbf0rmZO7FGKUuYzjmDGdBnFg0REO5E50K5NPz0xp8Mq1I3kk/SYql/VtuKhpQg0mXTuqwGNcQ9MYWzMybGcY0Nizh6t8dFmP3ChfTO87jQ/Wf8dzXe+mZlxF9p89wT+njrhV4Qd4q88jdPp2NgaDwthOiZzNSOeh1UMd+xtVrAV7osCUyaiGL/HPmf2sPjvV/X6jBzKocW9e2vgwg2o8CvrW5CyUBEcl2GNXDyNx0Rp617oBo9HoWDend8PpADy51nnsr4P/YMTCZ2lb+XKe7Hyz23kiw8JpGXcNW9PV6fMjG77o9XqN46vxR+LXhbbrmvotWVs//3oXroxGI/0bt6V/47Y+1QDyldlk4uvBE73um3/rG6xN+peOebqyS6J4w1XMGPyax/YXuz/AxJUmYiJiWHvuS7A6PzGHm81M7fEDF7IvepTjB6gZV5F3O88i3GTmiur1NV2DTwh37j1HVWM9h90HNOjLJ//8jcHo/vuv2MwYjBYaxbXgqhrOnobUbPdcl0FNu7Ni1VQqm64s9esD+hoY+co1OfuP4d9gUxRNawO1qVaXz6939urVq1DZ7YOqXVxUGbbduYULOVnERESRctE9smkSX4Nv+s0lzGSmcXw1LFYrX26+jHBzmLq2JvDdzS8DMKTlFnJychyFPINFgqMS7LLKNVk/Iv/EuyZRA/gn80cS60+kctlybkmAeb3QfTTXz19ClbCWPNrhBh1aW3KYTSY6120W7Gb4pFmFlh7d3KAGqt/c/AI2m41Z29rSvmZTt/1X1mhQ4Hm712uhaTuF8MaA0a3wRXmXnKCPu33HmqQdPNT+ej7d/TLgHhx9cs0sZmz9iVd7jnYLeqqVqeN2XPd6LViRsMrrlPpLncmlmJ3RaAxqnozRaHSst1cuMpolN/7O0r2byLJmO1Ii7MwmEyPaqsupnEifSN3ywa1p5I0ER6XYtze9xL+n76dpQuFlAOpVqMzGO1dhLuWfvEJFrbBrOHxxI2M7e1/00c5oNDoSMYUoaaIMCWSgrrl1RewQtyCnY+2mdKytBvWPtnyRd7a9xKimT3jdD/B820/5ZuePvNXHfXII4FPZjUvRVdUvY/6xYLfCu2qxFUi8ovA1MB/vNLjQY4JBgqNSzGg0+hQY2dmXrRDBt2jYOz6tYi5ESfbhtVN49NeJ3NPyLu5oc02+x41s29tRnTo/gy5rz6DLZOKAP/o0bENS6is0rlSr8IOFX+SvpRBBIoGRKO2uqF6f1cNnBrsZl7S8C+8KbcgYixBCCCGECwmOhBBCCCFcSHAkhBBCCOFCgiMhhBBCCBcSHAkhhBBCuJDgSAghhBDChQRHQgghhBAuJDgSQgghhHAhwZEQQgghhAsJjoQQQgghXEhwJIQQQgjhQoIjIYQQQggXpSY4evnll+nQoQPR0dHExcV5PSYpKYn+/fsTHR1NQkICTz75JBaLxeuxf/75J2azmdatW+vXaCGEEEKUOqUmOMrOzubmm2/mvvvu87rfarXSv39/srOzWbNmDTNmzGD69Ok8++yzHseeP3+eO++8kx49eujdbCGEEEKUMqUmOHr++ed57LHHaNGihdf9S5cuZdeuXXz11Ve0bt2avn378uKLL/LBBx+QnZ3tduzo0aMZNmwY7du3D0TThRBCCFGKmIPdAK2sXbuWFi1aULlyZce23r17c99997Fz507atGkDwLRp09i/fz9fffUVL730UqHnzcrKIisry/E8JSUFgLNnz5KTk6PpPeTk5JCRkcGZM2cICwvT9NwlQajfH4T+Pcr9lX6hfo+hfn8Q+veo1/2lpaUBoChKoceGTHCUnJzsFhgBjufJyckA7N27l7Fjx7J69WrMZt9u/dVXX+X555/32F63bt1itlgIIYQQgZaWlka5cuUKPCaowdHYsWOZPHlygcfs3r2bJk2aFPtaVquVYcOG8fzzz9OoUSOfXzdu3DjGjBnjeG6z2Th79iwVK1bEYDAUu12uUlNTqVmzJocPHyY2NlbTc5cEoX5/EPr3KPdX+oX6PYb6/UHo36Ne96coCmlpaVSrVq3QY4MaHD3++OMkJiYWeEy9evV8OleVKlX4+++/3badOHHCsS8tLY0NGzawefNmHnzwQUANdBRFwWw2s3TpUq655hqP80ZERBAREeG2Lb/ZclqJjY0NyR94u1C/Pwj9e5T7K/1C/R5D/f4g9O9Rj/srrMfILqjBUXx8PPHx8Zqcq3379rz88sucPHmShIQEAJYtW0ZsbCzNmjUjLCyM7du3u73mww8/ZPny5cydO1eGyYQQQggBlKKco6SkJM6ePUtSUhJWq5UtW7YA0KBBA8qWLcu1115Ls2bNuOOOO3jttddITk5mwoQJPPDAA46en+bNm7udMyEhgcjISI/tQgghhLh0lZrg6Nlnn2XGjBmO5/bZZytWrKBbt26YTCZ++ukn7rvvPtq3b0+ZMmUYPnw4L7zwQrCa7LeIiAiee+45j2G8UBHq9wehf49yf6VfqN9jqN8fhP49loT7Myi+zGkTQgghhLhElJoikEIIIYQQgSDBkRBCCCGECwmOhBBCCCFcSHAkhBBCCOFCgqMAevnll+nQoQPR0dE+F5JUFIVnn32WqlWrEhUVRc+ePdm7d6/bMWfPnuW2224jNjaWuLg4Ro4cSXp6ug53UDh/23Lw4EEMBoPXf3PmzHEc523/7NmzA3FLboryte7WrZtH20ePHu12TFJSEv379yc6OpqEhASefPJJLBaLnrfilb/3d/bsWR566CEaN25MVFQUtWrV4uGHH3asQWgXzO/fBx98QJ06dYiMjKRdu3YexWLzmjNnDk2aNCEyMpIWLVqwePFit/2+/E4Gkj/399lnn9G5c2fKly9P+fLl6dmzp8fxiYmJHt+rPn366H0bBfLnHqdPn+7R/sjISLdjSvP30Nv7icFgoH///o5jStL3cNWqVQwYMIBq1aphMBiYP39+oa9ZuXIll19+ORERETRo0IDp06d7HOPv77XfFBEwzz77rPLmm28qY8aMUcqVK+fTayZNmqSUK1dOmT9/vrJ161Zl4MCBSt26dZXMzEzHMX369FFatWql/PXXX8rq1auVBg0aKEOHDtXpLgrmb1ssFoty/Phxt3/PP/+8UrZsWSUtLc1xHKBMmzbN7TjXr0GgFOVr3bVrV2XUqFFubU9JSXHst1gsSvPmzZWePXsqmzdvVhYvXqxUqlRJGTdunN6348Hf+9u+fbsyaNAgZeHChcq+ffuU3377TWnYsKEyePBgt+OC9f2bPXu2Eh4erkydOlXZuXOnMmrUKCUuLk45ceKE1+P//PNPxWQyKa+99pqya9cuZcKECUpYWJiyfft2xzG+/E4Gir/3N2zYMOWDDz5QNm/erOzevVtJTExUypUrpxw5csRxzPDhw5U+ffq4fa/Onj0bqFvy4O89Tps2TYmNjXVrf3Jystsxpfl7eObMGbd727Fjh2IymZRp06Y5jilJ38PFixcr48ePV+bNm6cAyg8//FDg8fv371eio6OVMWPGKLt27VLee+89xWQyKb/88ovjGH+/ZkUhwVEQTJs2zafgyGazKVWqVFGmTJni2Hb+/HklIiJC+eabbxRFUZRdu3YpgLJ+/XrHMT///LNiMBiUo0ePat72gmjVltatWysjRoxw2+bLL5Xeinp/Xbt2VR555JF89y9evFgxGo1ub+AfffSREhsbq2RlZWnSdl9o9f377rvvlPDwcCUnJ8exLVjfv6uuukp54IEHHM+tVqtSrVo15dVXX/V6/C233KL079/fbVu7du2Ue++9V1EU334nA8nf+8vLYrEoMTExyowZMxzbhg8frlx//fVaN7XI/L3Hwt5fQ+17+NZbbykxMTFKenq6Y1tJ+x7a+fI+8NRTTymXXXaZ27Zbb71V6d27t+N5cb9mvpBhtRLswIEDJCcn07NnT8e2cuXK0a5dO9auXQvA2rVriYuLo23bto5jevbsidFoZN26dQFtrxZt2bhxI1u2bGHkyJEe+x544AEqVarEVVddxdSpU1ECXKKrOPf39ddfU6lSJZo3b864cePIyMhwO2+LFi2oXLmyY1vv3r1JTU1l586d2t9IPrT6WUpJSSE2Nhaz2b3GbKC/f9nZ2WzcuNHt98doNNKzZ0/H709ea9eudTse1O+F/XhfficDpSj3l1dGRgY5OTlUqFDBbfvKlStJSEigcePG3HfffZw5c0bTtvuqqPeYnp5O7dq1qVmzJtdff73b71GofQ+/+OILhgwZQpkyZdy2l5Tvob8K+x3U4mvmi1JTIftSlJycDOD2R9P+3L4vOTnZsZacndlspkKFCo5jAkWLtnzxxRc0bdqUDh06uG1/4YUXuOaaa4iOjmbp0qXcf//9pKen8/DDD2vW/sIU9f6GDRtG7dq1qVatGtu2bePpp5/m33//Zd68eY7zevse2/cFihbfv9OnT/Piiy9yzz33uG3/f3t3HxRV9cYB/Lut7Aa7ENESLAUYL61mS6AzEI6y5joImkPjiEgNb5JNk07RKCM2Y1r0B+RaTW/INAhOUxJjKTWNYE6gyBBFIokhsTto2DQUviDyKvD8/ujH/e1tEXaXdRf9PZ+ZneGee+6957ln795n7p6zuKL/enp6MDY2Num5PX/+/KTb3KovzK+3ibJb1XEWe+L7t+3btyMgIEB0o0lISMDatWvxyCOPwGQy4bXXXkNiYiIaGhoglUodGsN07IlRo9Fg//79iIiIQG9vLwwGAxYvXoxz587h4Ycfvqv68Mcff0RraytKSkpE5bOpD211q2vw+vXrGBwcxNWrV2f8vrcGJ0czlJeXh8LCwinrtLW1Yd68eU5qkeNZG+NMDQ4O4vPPP8fOnTst1pmXRUVFob+/H3v27HHIzfV2x2eeKGi1WqjVauj1ephMJoSGhtq9X2s5q/+uX7+O1atX47HHHsPu3btF625n/zH7FBQUoLy8HLW1taIByxs2bBD+1mq1iIiIQGhoKGpra6HX613RVJvExsYiNjZWWF68eDHmz5+P4uJi5Ofnu7BljldSUgKtVovo6GhR+Z3eh7MBJ0cztHXrVmRmZk5ZJyQkxK59+/v7AwC6u7uhVquF8u7ubkRGRgp1/vrrL9F2o6OjuHLlirD9TFkb40zbcujQIQwMDCA9PX3aujExMcjPz8fw8PCM//+Os+KbEBMTAwAwGo0IDQ2Fv7+/xUyL7u5uAHBIHzojvr6+PiQkJMDT0xOHDx+Gm5vblPUd2X+3olKpIJVKhXM5obu7+5bx+Pv7T1nfmmvSWeyJb4LBYEBBQQGOHz+OiIiIKeuGhIRApVLBaDQ6/cY6kxgnuLm5ISoqCkajEcDd04f9/f0oLy+36v+HurIPbXWra9DLywvu7u6QSqUzfk9YxWGjl5jVbB2QbTAYhLLe3t5JB2Q3NTUJdaqrq106INvetuh0OotZTrfy1ltv0f333293W+3hqHN96tQpAkAtLS1E9L8B2eYzLYqLi8nLy4uGhoYcF8A07I2vt7eXnnzySdLpdNTf32/VsZzVf9HR0bRlyxZheWxsjB566KEpB2Q//fTTorLY2FiLAdlTXZPOZGt8RESFhYXk5eVFDQ0NVh2jq6uLJBIJVVZWzri99rAnRnOjo6Ok0Wjo1VdfJaK7ow+J/rmPyOVy6unpmfYYru7DCbByQPbjjz8uKktNTbUYkD2T94RVbXXYnti0Ll68SM3NzcJU9ebmZmpubhZNWddoNPTVV18JywUFBeTt7U2VlZX0yy+/UFJS0qRT+aOioqixsZFOnTpF4eHhLp3KP1VbLl26RBqNhhobG0XbdXR0kEQioaNHj1rs8+uvv6ZPPvmEzp49Sx0dHfTxxx+Th4cHvf7667c9nn+zNT6j0UhvvvkmNTU1UWdnJ1VWVlJISAjFxcUJ20xM5Y+Pj6czZ85QVVUV+fr6umwqvy3x9fb2UkxMDGm1WjIajaKpw6Ojo0Tk2v4rLy8nuVxOZWVl9Ouvv9ILL7xA3t7ewszAtLQ0ysvLE+rX19fTnDlzyGAwUFtbG+3atWvSqfzTXZPOYmt8BQUFJJPJ6NChQ6K+mvgM6uvro23btlFDQwN1dnbS8ePHaeHChRQeHu7URH0mMb7xxhtUXV1NJpOJfv75Z9qwYQPde++9dO7cOaHOndyHE5YsWUIpKSkW5bOtD/v6+oR7HQB65513qLm5mS5evEhERHl5eZSWlibUn5jKn5ubS21tbfTRRx9NOpV/qnPmCJwcOVFGRgYBsHjV1NQIdfDf34OZMD4+Tjt37iQ/Pz+Sy+Wk1+upvb1dtN/Lly9TamoqKZVK8vLyoqysLFHC5UzTtaWzs9MiZiKiHTt2UGBgII2NjVns8+jRoxQZGUlKpZIUCgU98cQTtG/fvknr3m62xvf7779TXFwc+fj4kFwup7CwMMrNzRX9zhER0YULFygxMZHc3d1JpVLR1q1bRVPhncXW+GpqaiZ9TwOgzs5OInJ9/33wwQcUFBREMpmMoqOj6YcffhDW6XQ6ysjIENWvqKigRx99lGQyGS1YsIC+/fZb0XprrklnsiW+4ODgSftq165dREQ0MDBA8fHx5OvrS25ubhQcHEybNm1y6E3HHrbEmJOTI9T18/OjVatW0enTp0X7u5P7kIjo/PnzBICOHTtmsa/Z1oe3+oyYiCkjI4N0Op3FNpGRkSSTySgkJER0T5ww1TlzBAmRk+dDM8YYY4zNYvw7R4wxxhhjZjg5Yowxxhgzw8kRY4wxxpgZTo4YY4wxxsxwcsQYY4wxZoaTI8YYY4wxM5wcMcYYY4yZ4eSIMcYYY8wMJ0eMMcYYY2Y4OWKMzQqZmZmQSCQWr4n/ps4YY84yx9UNYIyxCQkJCSgtLRWV+fr6ipZHRkYgk8mc2SzG2P8ZfnLEGJs15HI5/P39RS+9Xo8tW7YgJycHKpUKK1euBAC0trYiMTERSqUSfn5+SEtLQ09Pj7Cv/v5+pKenQ6lUQq1WY+/evVi2bBlycnKEOhKJBEeOHBG1wdvbG2VlZcJyV1cX1q9fD29vb/j4+CApKQkXLlwQ1mdmZuKZZ56BwWCAWq3GAw88gM2bN+PmzZtCneHhYWzfvh2BgYGQy+UICwtDSUkJiAhhYWEwGAyiNpw5c4afmjHmQpwcMcZmvQMHDkAmk6G+vh779u3DtWvXsHz5ckRFRaGpqQlVVVXo7u7G+vXrhW1yc3Nx4sQJVFZW4tixY6itrcXp06dtOu7NmzexcuVKeHp6oq6uDvX19VAqlUhISMDIyIhQr6amBiaTCTU1NThw4ADKyspECVZ6ejoOHjyI999/H21tbSguLoZSqYREIsHGjRstnpaVlpYiLi4OYWFh9p0wxtjMEGOMzQIZGRkklUpJoVAIr3Xr1pFOp6OoqChR3fz8fIqPjxeVdXV1EQBqb2+nvr4+kslkVFFRIay/fPkyubu70yuvvCKUAaDDhw+L9nPfffdRaWkpERF9+umnpNFoaHx8XFg/PDxM7u7uVF1dLbQ7ODiYRkdHhTrJycmUkpJCRETt7e0EgL777rtJ4/7jjz9IKpVSY2MjERGNjIyQSqWisrIyK84aY+x24DFHjLFZ46mnnkJRUZGwrFAokJqaikWLFonqtbS0oKamBkql0mIfJpMJg4ODGBkZQUxMjFDu4+MDjUZjU3taWlpgNBrh6ekpKh8aGoLJZBKWFyxYAKlUKiyr1WqcPXsWwD9fkUmlUuh0ukmPERAQgNWrV2P//v2Ijo7GN998g+HhYSQnJ9vUVsaY43ByxBibNRQKxaRfJSkUCtHyjRs3sGbNGhQWFlrUVavVVo/VkUgkICJRmflYoRs3bmDRokX47LPPLLY1Hyju5uZmsd/x8XEAgLu7+7TteP7555GWloZ3330XpaWlSElJgYeHh1UxMMYcj5MjxtgdZ+HChfjyyy8xd+5czJlj+TEWGhoKNzc3NDY2IigoCABw9epV/Pbbb6InOL6+vvjzzz+F5Y6ODgwMDIiO88UXX+DBBx+El5eXXW3VarUYHx/HiRMnsGLFiknrrFq1CgqFAkVFRaiqqsLJkyftOhZjzDF4QDZj7I6zefNmXLlyBampqfjpp59gMplQXV2NrKwsjI2NQalUIjs7G7m5ufj+++/R2tqKzMxM3HOP+CNv+fLl+PDDD9Hc3Iympia8+OKLoqdAzz33HFQqFZKSklBXV4fOzk7U1tbi5ZdfxqVLl6xq69y5c5GRkYGNGzfiyJEjwj4qKiqEOlKpFJmZmdixYwfCw8MRGxvrmBPFGLMLJ0eMsTtOQEAA6uvrMTY2hvj4eGi1WuTk5MDb21tIgPbs2YOlS5dizZo1WLFiBZYsWWIxdmnv3r0IDAzE0qVL8eyzz2Lbtm2ir7M8PDxw8uRJBAUFYe3atZg/fz6ys7MxNDRk05OkoqIirFu3Di+99BLmzZuHTZs2ob+/X1QnOzsbIyMjyMrKmsGZYYw5goT+/YU7Y4zdpZYtW4bIyEi89957rm6Khbq6Ouj1enR1dcHPz8/VzWHs/xqPOWKMMRcaHh7G33//jd27dyM5OZkTI8ZmAf5ajTHGXOjgwYMIDg7GtWvX8Pbbb7u6OYwx8NdqjDHGGGMi/OSIMcYYY8wMJ0eMMcYYY2Y4OWKMMcYYM8PJEWOMMcaYGU6OGGOMMcbMcHLEGGOMMWaGkyPGGGOMMTOcHDHGGGOMmfkP44n4bVo3p80AAAAASUVORK5CYII=","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.psd(X.detach().cpu()[:,0,0]+1j*X.detach().cpu()[:,1,0],NFFT=2048, label = \"X\")\n","plt.psd(d.reshape(-1,),NFFT=2048, label = \"Y\")\n","plt.psd(x.reshape(-1,),NFFT=2048, label = \"x_small\")\n","plt.legend()\n","# plt.psd(x.reshape(-1,)*x.reshape(-1,),NFFT=2048)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"b20jyT09f8mH"},"source":["## Loss function"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666969869487,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"V_dHc4pZf8mL"},"outputs":[],"source":["loss_fn = nn.MSELoss()\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["from statistics import mode\n","\n","class Layerr(torch.nn.ModuleList):\n","    def __init__(self):\n","        super(Layerr,self).__init__()\n","        self.L = nn.ModuleList()\n","\n","    def ap_elem(self, elem : nn.Module):\n","        self.L.append(elem)\n","\n","    def forward(self, x):\n","        #summ = 0\n","        #for modul in self.L:\n","        #    summ = summ + modul(x)\n","        return sum(list(map( lambda m: m(x),  self.L)))\n","        #return summ\n","\n","\n","# 2 layer NN\n","class NN_2_layer(nn.Module):\n","    def __init__(self, l1, l2):\n","        super(NN_2_layer, self).__init__()\n","        self.layer_1 = l1\n","        self.layer_2 = l2\n","        #self.model = nn.Sequential(self.layer_1, self.layer_2)\n","    def forward(self, x):\n","        return self.layer_2.forward(self.layer_1.forward(x))\n","        #return self.model(x)\n","\n","class NN_simple_1(nn.Module):\n","    def __init__(self):\n","        super(NN_simple_1, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 1, kernel_size=3, stride=1, padding=1)\n","    def forward(self, x):\n","        #return self.layer_2.forward(self.layer_1.forward(x))\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = double(self.conv2(x))\n","        return x\n","\n","class NN_simple_2(nn.Module):\n","    def __init__(self, l1, l2):\n","        super(NN_simple_2, self).__init__()\n","        self.layer_1 = l1\n","        self.layer_2 = l2\n","        self.model = nn.Sequential(self.layer_1, self.layer_2)\n","    def forward(self, x):\n","        #return self.layer_2.forward(self.layer_1.forward(x))\n","        return self.model(x)\n","\n","class Cell_try_2(nn.Module):\n","    def __init__(self,M=15,D=0,Poly_order=8,Passthrough=False):\n","        super(Cell_try_2,self).__init__()\n","        self.f = AFIR(M,0)\n","        self.pol = Polynomial(Poly_order,Passthrough)\n","        self.prod = Prod_cmp()\n","        self.delay = Delay(D)\n","    def forward(self,x):\n","        return self.prod( self.f(self.delay(x)), self.f(self.pol(self.delay(x))) )\n","\n","\n","class NN_2_row(nn.Module):\n","    def __init__(self, l1, l2):\n","        super(NN_2_row, self).__init__()\n","        self.conv_block1 = l1\n","        \n","        self.conv_block2 = l2\n","\n","        \n","    def forward(self, x):\n","        #x0 = self.conv_block1(x)\n","        #x1 = self.conv_block2(x0)\n","        \n","        return self.conv_block2(self.conv_block1(x))\n","\n","\n","    def forward_q(self, x):\n","        x0 = self.conv_block1(x)\n","\n","        return x0\n","\n","class Layerr_2(torch.nn.ModuleList):\n","    def __init__(self, n_row):\n","        super(Layerr_2,self).__init__()\n","        self.L = nn.ModuleList(2)\n","\n","\n","    def ap_elem(self, i_row, elem : nn.Module):\n","        self.L[i_row].append(elem)\n","\n","\n","    def forward(self, x):\n","        x0 = sum(list(map( lambda m: m(x),  self.L[0])))\n","        x1 = sum(list(map( lambda m: m(x0),  self.L[1])))\n","\n","        return x1\n","    \n","\n","\n","class Layerr_3(torch.nn.ModuleList):\n","    def __init__(self, n_row):\n","        super(Layerr_3, self).__init__()\n","        self.L = nn.ModuleList()\n","        for i in range(n_row):\n","            self.L.append(nn.ModuleList())\n","        \n","    def append_L(self,M=15,D=0,Poly_order=8,Passthrough=False):\n","        self.f = AFIR(M,0)\n","        self.pol = Polynomial(Poly_order,Passthrough)\n","        self.prod = Prod_cmp()\n","        self.delay = Delay(D)\n","    def forward(self,x):\n","        return self.prod( self.f(self.delay(x)), self.f(self.pol(self.delay(x))) )\n","        \n","class Layerr_4(torch.nn.Module):\n","    def __init__(self, NN):\n","        super(Layerr_4,self).__init__()\n","        self.L = nn.ModuleList()\n","        self.NN = NN\n","\n","    def forward(self, x):\n","        #summ = 0\n","        #for modul in self.L:\n","        #    summ = summ + modul(x)\n","        return sum(list(map( lambda m: m(x),  sum(list(map( lambda n: n(x),  self.NN))))))\n","        #return summ\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  5%|▌         | 1/20 [00:07<02:17,  7.22s/it]"]},{"name":"stdout","output_type":"stream","text":["Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 2/20 [00:14<02:11,  7.29s/it]"]},{"name":"stdout","output_type":"stream","text":["Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 2/20 [00:17<02:33,  8.50s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [23], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raww\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m     11\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m---> 12\u001b[0m train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [12], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(n_epoch)):\n\u001b[0;32m      7\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m     train_of_epoch(train_queue, model, criterion, optimizer)\n\u001b[0;32m      9\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n","Cell \u001b[1;32mIn [11], line 5\u001b[0m, in \u001b[0;36mtrain_of_epoch\u001b[1;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_of_epoch\u001b[39m(train_queue, model, criterion, optimizer):\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m step, (train) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_queue):\n\u001b[0;32m      7\u001b[0m         input_batch \u001b[39m=\u001b[39m Variable(train[:,:,:\u001b[39m1\u001b[39m],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      8\u001b[0m         desired \u001b[39m=\u001b[39m Variable(train[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["l0 = Layerr()\n","l1 = Layerr()\n","for i in range(5):\n","# det hyperparams \n","    l0.ap_elem(Cell_try_2(M=9, D=(-2 + 1*i), Poly_order=9))\n","    l1.ap_elem(Cell_try_2(M=9, D=(-2 + 1*i), Poly_order=9))\n","  \n","NN_raww = NN_2_row(l0,l1)\n","NN_raww = NN_raww.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raww.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, 20, scheduler, save_flag=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["l1 = Layerr()\n","l2 = Layerr()\n","\n","l1.ap_elem(Cell_try_2())\n","l1.ap_elem(Cell_try_2())\n","\n","\n","l2.ap_elem(Cell_try_2())\n","l2.ap_elem(Cell_try_2())\n","l2.ap_elem(Cell_try_2())\n","l2.ap_elem(Cell_try_2())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b4a08e2e05e4319a5ae363f288804c3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [176], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raww\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m      4\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 5\u001b[0m train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [149], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39mrange\u001b[39m(n_epoch)):\n\u001b[0;32m      7\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m     train_of_epoch(train_queue, model, criterion, optimizer)\n\u001b[0;32m      9\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n","Cell \u001b[1;32mIn [167], line 7\u001b[0m, in \u001b[0;36mtrain_of_epoch\u001b[1;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m desired \u001b[39m=\u001b[39m Variable(train[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(input_batch)\n\u001b[0;32m      8\u001b[0m \u001b[39m#out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#out = sum(list(map( lambda n: n(out_0),  model[1])))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, desired)\n","Cell \u001b[1;32mIn [169], line 70\u001b[0m, in \u001b[0;36mNN_2_row.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     69\u001b[0m     x0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_block1(x)\n\u001b[1;32m---> 70\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_block2(x0)\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m x1\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [169], line 12\u001b[0m, in \u001b[0;36mLayerr.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m( \u001b[39mlambda\u001b[39;49;00m m: m(x),  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL)))\n","Cell \u001b[1;32mIn [169], line 12\u001b[0m, in \u001b[0;36mLayerr.forward.<locals>.<lambda>\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m( \u001b[39mlambda\u001b[39;00m m: m(x),  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)))\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [169], line 57\u001b[0m, in \u001b[0;36mCell_try_2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprod( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay(x)), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpol(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelay(x))) )\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32m~\\Desktop\\NNForDPD\\huawei\\DPDBlocks\\blocks.py:78\u001b[0m, in \u001b[0;36mPolynomial.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morder):\n\u001b[0;32m     77\u001b[0m     out[:, \u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m0\u001b[39m, i]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mpow(x,i)\n\u001b[1;32m---> 78\u001b[0m     out[:, \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[\u001b[39m1\u001b[39m, i]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mpow(x,i)\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m out\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1252\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_is_full_backward_hook\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m   1250\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_full_backward_hook \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m   1254\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","NN_raww = NN_2_row(l1,l2)\n","NN_raww = NN_raww.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raww.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, 20, scheduler, save_flag=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_16292\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efffc4410c584559882f22335cdc69c4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss =  0.00010456197910466027 Accuracy =  -24.8516621834706 dbs\n","Loss =  9.448935912035815e-05 Accuracy =  -25.291571097669873 dbs\n","Loss =  9.048510806713103e-05 Accuracy =  -25.479629037283303 dbs\n","Loss =  8.90595216537008e-05 Accuracy =  -25.548596549698445 dbs\n","Loss =  8.820588354641237e-05 Accuracy =  -25.590424585450478 dbs\n","Loss =  8.757277312330857e-05 Accuracy =  -25.621709106264696 dbs\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(l1\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m      3\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 4\u001b[0m train(train_queue, valid_queue, l1, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [12], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m it\u001b[39m%\u001b[39mlog_every\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m         loss_v,accuracy_v\u001b[39m=\u001b[39meval_model(valid_queue, model, loss_fn)\n\u001b[0;32m     16\u001b[0m         update_history(hist,it, accuracy_v, loss_v, timer() \u001b[39m-\u001b[39m t0,)\n\u001b[0;32m     17\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoss = \u001b[39m\u001b[39m'\u001b[39m,loss_v\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39mAccuracy = \u001b[39m\u001b[39m'\u001b[39m, accuracy_v\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39mdbs\u001b[39m\u001b[39m'\u001b[39m)\n","Cell \u001b[1;32mIn [10], line 2\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m(valid_queue, model, criterion)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_model\u001b[39m(valid_queue, model, criterion):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mfor\u001b[39;00m step, (valid) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(valid_queue):\n\u001b[0;32m      3\u001b[0m         model\u001b[39m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m         input_batch \u001b[39m=\u001b[39m Variable(valid[:,:,:\u001b[39m1\u001b[39m],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","l1 = l1.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(l1.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, l1, loss_fn, optimizer, 20, scheduler, save_flag=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["D = {'p': [4, 5, 6, 7, 8, 9], 'k' : [3, 5, 7, 9], 'z' : [-2, -1, 0, 1, 2]}\n","ex_D = {} # extremum vals of D\n","\n","for key in D.keys():\n","  ex_D[key] = [ min(D[key]), max(D[key])]\n","\n","\n","def objective(trial):\n","  # create and train NN\n","  net = torch.nn.ModuleList()\n","\n","  complex_cur = 0\n","  l0 = Layerr()\n","  l1 = Layerr()\n","  for i in range(5):\n","    # det hyperparams \n","    poly_ord0 = trial.suggest_int('p0'+str(i), ex_D['p'][0], ex_D['p'][1])\n","    conv_ord0 = trial.suggest_int('k0'+str(i), ex_D['k'][0], ex_D['k'][1], step=2)\n","    l0.ap_elem(Cell_try_2(M=conv_ord0, D=(ex_D['z'][0] + 1*i), Poly_order=poly_ord0))\n","    poly_ord1 = trial.suggest_int('p1'+str(i), ex_D['p'][0], ex_D['p'][1])\n","    conv_ord1 = trial.suggest_int('k1'+str(i), ex_D['k'][0], ex_D['k'][1], step=2)\n","    l1.ap_elem(Cell_try_2(M=conv_ord1, D=(ex_D['z'][0] + 1*i), Poly_order=poly_ord1))\n","  \n","\n","\n","  NN_raww = NN_2_row(l0,l1)\n","  NN_raww = NN_raww.to(torch.device('cpu'))\n","  optimizer = torch.optim.Adam(NN_raww.parameters(), lr=1e-2)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","  train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","  loss_cur, accuracy_cur = eval_model(valid_queue, NN_raww, loss_fn)\n","  score_cur = accuracy_cur.item()\n","\n","  return score_cur"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-10-31 13:58:19,767]\u001b[0m A new study created in memory with name: no-name-bc422455-2045-4891-a1cf-07a63e89eb14\u001b[0m\n","C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbfd6478bfd84a18981df40d1799b7d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n","Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n","Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[33m[W 2022-10-31 13:58:47,728]\u001b[0m Trial 0 failed because of the following error: KeyboardInterrupt()\u001b[0m\n","Traceback (most recent call last):\n","  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n","    value_or_values = func(trial)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\737231000.py\", line 30, in objective\n","    train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py\", line 15, in train\n","    loss_v,accuracy_v=eval_model(valid_queue, model, loss_fn)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\2749143958.py\", line 6, in eval_model\n","    out = model.forward(input_batch)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\4164055926.py\", line 69, in forward\n","    x0 = self.conv_block1(x)\n","  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\4164055926.py\", line 12, in forward\n","    return sum(list(map( lambda m: m(x),  self.L)))\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\4164055926.py\", line 12, in <lambda>\n","    return sum(list(map( lambda m: m(x),  self.L)))\n","  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\4164055926.py\", line 57, in forward\n","    return self.prod( self.f(self.delay(x)), self.f(self.pol(self.delay(x))) )\n","  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1190, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"C:\\Users\\Student\\Desktop\\NNForDPD\\huawei\\DPDBlocks\\blocks.py\", line 18, in forward\n","    return torch.cat((r1-r2, i1+i2), dim=1)\n","KeyboardInterrupt\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [163], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(study\u001b[39m.\u001b[39mbest_params)\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","Cell \u001b[1;32mIn [162], line 30\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raww\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m     29\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m---> 30\u001b[0m train(train_queue, valid_queue, NN_raww, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     32\u001b[0m loss_cur, accuracy_cur \u001b[39m=\u001b[39m eval_model(valid_queue, NN_raww, loss_fn)\n\u001b[0;32m     33\u001b[0m score_cur \u001b[39m=\u001b[39m accuracy_cur\u001b[39m.\u001b[39mitem()\n","Cell \u001b[1;32mIn [149], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m it\u001b[39m%\u001b[39mlog_every\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m         loss_v,accuracy_v\u001b[39m=\u001b[39meval_model(valid_queue, model, loss_fn)\n\u001b[0;32m     16\u001b[0m         update_history(hist,it, accuracy_v, loss_v, timer() \u001b[39m-\u001b[39m t0,)\n\u001b[0;32m     17\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoss = \u001b[39m\u001b[39m'\u001b[39m,loss_v\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39mAccuracy = \u001b[39m\u001b[39m'\u001b[39m, accuracy_v\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m'\u001b[39m\u001b[39mdbs\u001b[39m\u001b[39m'\u001b[39m)\n","Cell \u001b[1;32mIn [147], line 6\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m(valid_queue, model, criterion)\u001b[0m\n\u001b[0;32m      4\u001b[0m input_batch \u001b[39m=\u001b[39m Variable(valid[:,:,:\u001b[39m1\u001b[39m],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      5\u001b[0m desired \u001b[39m=\u001b[39m Variable(valid[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m----> 6\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(input_batch)\n\u001b[0;32m      7\u001b[0m \u001b[39m#out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m#out = sum(list(map( lambda n: n(out_0),  model[1])))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m loss\u001b[39m=\u001b[39mcriterion(out,desired)\n","Cell \u001b[1;32mIn [161], line 69\u001b[0m, in \u001b[0;36mNN_2_row.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 69\u001b[0m     x0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_block1(x)\n\u001b[0;32m     70\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_block2(x0)\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m x1\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [161], line 12\u001b[0m, in \u001b[0;36mLayerr.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m( \u001b[39mlambda\u001b[39;49;00m m: m(x),  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL)))\n","Cell \u001b[1;32mIn [161], line 12\u001b[0m, in \u001b[0;36mLayerr.forward.<locals>.<lambda>\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m( \u001b[39mlambda\u001b[39;00m m: m(x),  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)))\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [161], line 57\u001b[0m, in \u001b[0;36mCell_try_2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprod( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay(x)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpol(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelay(x))) )\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32m~\\Desktop\\NNForDPD\\huawei\\DPDBlocks\\blocks.py:18\u001b[0m, in \u001b[0;36mAFIR.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m i1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreal(x[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     17\u001b[0m i2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimag(x[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m---> 18\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mcat((r1\u001b[39m-\u001b[39;49mr2, i1\u001b[39m+\u001b[39;49mi2), dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=200)\n","print(study.best_params)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"625270286b994bf4b82a94d4aacdc46d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n","Loss =  0.0013047017710733303 Accuracy =  -13.89028761218138 dbs\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [171], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raw\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m      4\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 5\u001b[0m train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [149], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39mrange\u001b[39m(n_epoch)):\n\u001b[0;32m      7\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m     train_of_epoch(train_queue, model, criterion, optimizer)\n\u001b[0;32m      9\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n","Cell \u001b[1;32mIn [167], line 7\u001b[0m, in \u001b[0;36mtrain_of_epoch\u001b[1;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m desired \u001b[39m=\u001b[39m Variable(train[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(input_batch)\n\u001b[0;32m      8\u001b[0m \u001b[39m#out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#out = sum(list(map( lambda n: n(out_0),  model[1])))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, desired)\n","Cell \u001b[1;32mIn [169], line 23\u001b[0m, in \u001b[0;36mNN_2_layer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_2\u001b[39m.\u001b[39mforward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer_1\u001b[39m.\u001b[39;49mforward(x))\n","Cell \u001b[1;32mIn [169], line 12\u001b[0m, in \u001b[0;36mLayerr.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m( \u001b[39mlambda\u001b[39;49;00m m: m(x),  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mL)))\n","Cell \u001b[1;32mIn [169], line 12\u001b[0m, in \u001b[0;36mLayerr.forward.<locals>.<lambda>\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m( \u001b[39mlambda\u001b[39;00m m: m(x),  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL)))\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn [169], line 57\u001b[0m, in \u001b[0;36mCell_try_2.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprod( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay(x)), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpol(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdelay(x))) )\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32m~\\Desktop\\NNForDPD\\huawei\\DPDBlocks\\blocks.py:77\u001b[0m, in \u001b[0;36mPolynomial.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     75\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mAbs(x)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morder):\n\u001b[1;32m---> 77\u001b[0m     out[:, \u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m0\u001b[39m, i]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39;49mpow(x,i)\n\u001b[0;32m     78\u001b[0m     out[:, \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m1\u001b[39m, i]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mpow(x,i)\n\u001b[0;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m out\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","NN_raw = NN_2_layer(l2, l1)\n","NN_raw = NN_raw.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raw.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_8264\\3776313767.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for it in tqdm_notebook(range(n_epoch)):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"736939e79ecf419aa7d748b35f313345","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"Input type (double) and bias type (float) should be the same","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn [172], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(NN_raw\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n\u001b[0;32m      4\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39mstep_size, gamma\u001b[39m=\u001b[39mgamma)\n\u001b[1;32m----> 5\u001b[0m train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, \u001b[39m20\u001b[39;49m, scheduler, save_flag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n","Cell \u001b[1;32mIn [149], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m tqdm_notebook(\u001b[39mrange\u001b[39m(n_epoch)):\n\u001b[0;32m      7\u001b[0m     model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m     train_of_epoch(train_queue, model, criterion, optimizer)\n\u001b[0;32m      9\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[39m#     if return_history and it % log_every == 0:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#         model.init_for_batch(train)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#         train_loss = complex_mse(model.forward(train.x), train.y)\u001b[39;00m\n","Cell \u001b[1;32mIn [167], line 7\u001b[0m, in \u001b[0;36mtrain_of_epoch\u001b[1;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m desired \u001b[39m=\u001b[39m Variable(train[:,:,\u001b[39m1\u001b[39m:],requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(input_batch)\n\u001b[0;32m      8\u001b[0m \u001b[39m#out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#out = sum(list(map( lambda n: n(out_0),  model[1])))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, desired)\n","Cell \u001b[1;32mIn [169], line 34\u001b[0m, in \u001b[0;36mNN_simple_1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     33\u001b[0m     \u001b[39m#return self.layer_2.forward(self.layer_1.forward(x))\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m     35\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[0;32m     36\u001b[0m     x \u001b[39m=\u001b[39m double(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n","File \u001b[1;32mc:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n","\u001b[1;31mRuntimeError\u001b[0m: Input type (double) and bias type (float) should be the same"]}],"source":["NN_raw = NN_simple_1()\n","NN_raw = NN_raw.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raw.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, 20, scheduler, save_flag=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","NN_raw = NN_2_layer(l2, l1)\n","NN_raw = NN_raw.to(torch.device('cpu'))\n","optimizer = torch.optim.Adam(NN_raw.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, NN_raw, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Q-cZr6YFf8mg"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"vAcOp02dx4uY"},"source":["# Ensemble of small NN\n","(as nn.ModuleList with Optuna)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":684,"referenced_widgets":["3b30b65099f64b1ab763a6ac7cb7a187","2b45d052f23a410fa5484c50ac9d752c","0f41361be62b4f2e906ef07f2f692121","1d21f747016e410fbf6d01091beaebb7","3e576a7f44e84632b4b988639109bd40","a271e473b164475f9fb1f62fef16955a","eff2cbbc8395491881be7fe6dce6e160","16cf283945ce45b1a9c6560656cb01d0","cf878e3f1497456e9883a8bf623b5517","cbfa16e6d0cd4794a004299a87add101","7b0dd06176cc4413bde50d2d6ecfd330"]},"executionInfo":{"elapsed":8,"status":"error","timestamp":1666969869488,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"zV0Fah_yydzY","outputId":"016e5a4a-807e-490d-c88a-8a2689ff40d2"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2022-10-28 14:59:03,427]\u001b[0m A new study created in memory with name: no-name-bbdcbe0b-1894-4c03-8e91-7b73169ad285\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b30b65099f64b1ab763a6ac7cb7a187","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[33m[W 2022-10-28 14:59:03,504]\u001b[0m Trial 0 failed because of the following error: TypeError(\"'Cell_try_2' object is not iterable\")\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n","    value_or_values = func(trial)\n","  File \"<ipython-input-21-fe34253913b2>\", line 46, in objective\n","    train(train_queue, valid_queue, net, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","  File \"<ipython-input-13-2112ca6e0cf5>\", line 8, in train\n","    train_of_epoch(train_queue, model, criterion, optimizer)\n","  File \"<ipython-input-12-6294c9575d39>\", line 8, in train_of_epoch\n","    out_0 = sum(list(map( lambda m: m(input_batch),  model[0])))\n","TypeError: 'Cell_try_2' object is not iterable\n"]},{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-fe34253913b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-fe34253913b2>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mloss_cur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-2112ca6e0cf5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_queue, valid_queue, model, criterion, optimizer, n_epoch, scheduler, log_every, save_flag, path_to_experiment)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_of_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-6294c9575d39>\u001b[0m in \u001b[0;36mtrain_of_epoch\u001b[0;34m(train_queue, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#out = model.forward(input_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mout_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'Cell_try_2' object is not iterable"]}],"source":["class Cell_try_2(nn.Module):\n","    def __init__(self,M=15,D=0,Poly_order=8,Passthrough=False):\n","        super(Cell_try_2,self).__init__()\n","        self.f = AFIR(M,0)\n","        self.pol = Polynomial(Poly_order,Passthrough)\n","        self.prod = Prod_cmp()\n","        self.delay = Delay(D)\n","    def forward(self,x):\n","        #return self.prod(self.f(self.delay(x)), self.pol(self.delay(x)))\n","        return self.prod( self.f(self.delay(x)), self.f(self.pol(self.delay(x))) )\n","\n","D = {'p': [4, 5, 6, 7, 8, 9], 'k' : [3, 5, 7, 9], 'z' : [-2, -1, 0, 1, 2]}\n","ex_D = {} # extremum vals of D\n","\n","for key in D.keys():\n","  ex_D[key] = [ min(D[key]), max(D[key])]\n","\n","# complex reference model\n","ref_model = {'k': [9,5,9,7,9],'p': [9,8,6,9,6]}\n","\n","### params of the functional\n","score_huge = -37\n","score_min = -20.0\n","complex_huge = 2 * ( sum(ref_model['k']) + sum(ref_model['p']) )\n","complex_min = 2 * (4 * 5 + 3 * 5)\n","trtr_coef = 0.4\n","\n","\n","\n","def objective(trial):\n","  # create and train NN\n","  net = torch.nn.ModuleList()\n","\n","  complex_cur = 0\n","\n","  for i in range(2):\n","    # det hyperparams \n","    poly_ord = trial.suggest_int('p'+str(i), ex_D['p'][0], ex_D['p'][1])\n","    conv_ord = trial.suggest_int('k'+str(i), ex_D['k'][0], ex_D['k'][1], step=2)\n","    net.append(Cell_try_2(M=conv_ord, D=(ex_D['z'][0] + 1*i), Poly_order=poly_ord))\n","    complex_cur = complex_cur + poly_ord + conv_ord\n","\n","  net = net.to(torch.device('cpu'))\n","  optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","  train(train_queue, valid_queue, net, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","  loss_cur, accuracy_cur = eval_model(valid_queue, net, loss_fn)\n","  score_cur = accuracy_cur.item()\n","\n","  return score_cur\n","  #return  (complex_cur - complex_min) / (complex_huge - complex_min) + trtr_coef * (score_huge - score_cur) / (score_huge - score_min)\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=200)\n","print(study.best_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1666969869488,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"uJrBEkE65qC1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1666969869488,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"9FrpFBtO5OlW"},"outputs":[],"source":["print(study.best_params)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1666969869489,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"s-ziMOPR1L2r"},"outputs":[],"source":["\n","D = {'p': [3, 4, 5, 6, 7, 8, 9], 'k' : [1, 3, 5, 9], 'z' : [-2, -1, 0, 1, 2]}\n","ex_D = {} # extremum vals of D\n","\n","for key in D.keys():\n","  ex_D[key] = [ min(D[key]), max(D[key])]\n","\n","# huge model\n","huge_model = Cell_try_2(M=ex_D['k'][1], Poly_order=ex_D['p'][1])\n","huge_model = huge_model.to(\"cpu\")\n","#huge_model = huge_model.to(\"cuda:0\")\n","optimizer = torch.optim.Adam(huge_model.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, huge_model, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","\n","loss_huge, accuracy_huge = eval_model(valid_queue, huge_model, loss_fn)\n","score_huge = accuracy_huge.item()\n","complex_huge = ex_D['k'][1] + ex_D['p'][1]\n","\n","\n","# small model\n","small_model = Cell_try_2(M=ex_D['k'][0], Poly_order=ex_D['p'][0])\n","#small_model = small_model.to(\"cuda:0\")\n","small_model = small_model.to(\"cpu\")\n","optimizer = torch.optim.Adam(small_model.parameters(), lr=1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","train(train_queue, valid_queue, small_model, loss_fn, optimizer, 20, scheduler, save_flag=False)\n","\n","\n","loss_small, accuracy_small = eval_model(valid_queue, small_model, loss_fn)\n","score_small = -13\n","complex_small = ex_D['k'][0] + ex_D['p'][0]\n","trtr_coef = 0.1\n","def objective(trial):\n","  # det hyperparams \n","  poly_ord = trial.suggest_int('p', ex_D['p'][0], ex_D['p'][1])\n","  del_val = trial.suggest_int('z', ex_D['z'][0], ex_D['z'][1])\n","  conv_ord = trial.suggest_int('k', ex_D['k'][0], ex_D['k'][1], step=2)\n","\n","  # create and train NN\n","  net = Cell_try_2(M=conv_ord, D=del_val, Poly_order=poly_ord)\n","  net = net.to(\"cpu\")\n","  optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","  train(train_queue, valid_queue, net, loss_fn, optimizer,20,scheduler,save_flag=False)\n","\n","  loss_cur, accuracy_cur = eval_model(valid_queue, net, loss_fn)\n","  score_cur = accuracy_cur.item()\n","  complex_cur = poly_ord + conv_ord\n","\n","  # check if val of score is positive or not and then fix it\n","  #return (score_huge - score_cur) / score_huge + (complex_cur - complex_huge) / complex_huge\n","  return trtr_coef * (complex_cur - complex_small) / (complex_huge - complex_small) - (score_cur - score_small) / (score_huge - score_small)\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1666969869489,"user":{"displayName":"Дарт Вейдар","userId":"11620898834661069925"},"user_tz":-180},"id":"Gtsor6JFBpPo"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1hDGDFmI3y1A8BSQRa_1APBSrxUVOazku","timestamp":1666965206798},{"file_id":"1HcKoksGhyK1Sbo1XJGFUh0llgniyCtvU","timestamp":1666941560441}],"toc_visible":true},"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"5c96f01ceb864e4f314488f796d7ad3ed3c5d7e2e6828b71e2c816343e6bed5e"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0f41361be62b4f2e906ef07f2f692121":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_16cf283945ce45b1a9c6560656cb01d0","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf878e3f1497456e9883a8bf623b5517","value":0}},"16cf283945ce45b1a9c6560656cb01d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d21f747016e410fbf6d01091beaebb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbfa16e6d0cd4794a004299a87add101","placeholder":"​","style":"IPY_MODEL_7b0dd06176cc4413bde50d2d6ecfd330","value":" 0/20 [00:00&lt;?, ?it/s]"}},"2b45d052f23a410fa5484c50ac9d752c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a271e473b164475f9fb1f62fef16955a","placeholder":"​","style":"IPY_MODEL_eff2cbbc8395491881be7fe6dce6e160","value":"  0%"}},"3b30b65099f64b1ab763a6ac7cb7a187":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b45d052f23a410fa5484c50ac9d752c","IPY_MODEL_0f41361be62b4f2e906ef07f2f692121","IPY_MODEL_1d21f747016e410fbf6d01091beaebb7"],"layout":"IPY_MODEL_3e576a7f44e84632b4b988639109bd40"}},"3e576a7f44e84632b4b988639109bd40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b0dd06176cc4413bde50d2d6ecfd330":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a271e473b164475f9fb1f62fef16955a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbfa16e6d0cd4794a004299a87add101":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf878e3f1497456e9883a8bf623b5517":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eff2cbbc8395491881be7fe6dce6e160":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
